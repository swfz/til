{
  "results": [
    {
      "hits": [
        {
          "date": "March 25, 2022",
          "title": "BigQueryの日付を扱う際のメモ",
          "slug": "/entries/bigquery_date_function/",
          "rawMarkdownBody": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
          "timeToRead": 1,
          "objectID": "68f46908-591f-5bb4-82bd-f2fc099406d2",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "March 25, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryの日付を扱う際のメモ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 08, 2021",
          "title": "BigQueryのbq load時にautodetectを使えない場合",
          "slug": "/entries/bigquery_cant_use_autodetect/",
          "rawMarkdownBody": "\nPocketのデータをAPIで取得してBigQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\nBigQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/bigquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、BigQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。BigQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
          "timeToRead": 3,
          "objectID": "511a0a9b-6cec-55d0-a965-148667fcf789",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "タは次の3つ（__ais-highlight__b__/ais-highlight__ucket名はサンプル）\n\n```\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 08, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryの__ais-highlight__b__/ais-highlight__q load時にautodetectを使えない場合",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__B__/ais-highlight__igQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`__ais-highlight__b__/ais-highlight__q load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\n__ais-highlight__B__/ais-highlight__igQuery error in load operation: Error processing job\n'project-111111:__ais-highlight__b__/ais-highlight__qjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\n__ais-highlight__b__/ais-highlight__ad: 0; error percent: 0\n- gs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（__ais-highlight__b__/ais-highlight__ucket名はサンプル）\n\n```\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/__ais-highlight__b__/ais-highlight__igquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、__ais-highlight__B__/ais-highlight__igQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。__ais-highlight__B__/ais-highlight__igQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\n__ais-highlight__b__/ais-highlight__q show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\n__ais-highlight__b__/ais-highlight__q mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\n__ais-highlight__b__/ais-highlight__q load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`__ais-highlight__b__/ais-highlight__q load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "December 09, 2020",
          "title": "BigQueryでサンプルデータをサクッと作る",
          "slug": "/entries/bigquery_sample_data/",
          "rawMarkdownBody": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
          "timeToRead": 1,
          "objectID": "28192504-51b0-5f94-9f12-c62f278c23cc",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "December 09, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryでサンプルデータをサクッと作る",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 21, 2021",
          "title": "BigQueryで日付を扱うときはTimezoneを意識する",
          "slug": "/entries/bigquery_date_timezone/",
          "rawMarkdownBody": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\nBigQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
          "timeToRead": 1,
          "objectID": "1d531f2a-2c16-5859-96ce-a8cf37a230b8",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "SELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) __ais-highlight__B__/ais-highlight__ETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXな",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 21, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryで日付を扱うときはTimezoneを意識する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) __ais-highlight__B__/ais-highlight__ETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__B__/ais-highlight__igQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 25, 2021",
          "title": "gcloud buildsでログが見れない時",
          "slug": "/entries/gcloud_project_iam/",
          "rawMarkdownBody": "\nCloudRunでCDやろうと思ったらつまずいた\n\nサービスアカウントにコンテナのイメージをビルドさせたいときの話\n\n```\n$ gcloud builds submit --tag gcr.io/${project-id}/${name}\nCheck the gcloud log [/home/circleci/.config/gcloud/logs/2020.12.10/18.23.37.852071.log] to see which files and the contents of the default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn                                                                           more).\n.....\n.....\n.....\nERROR: (gcloud.builds.submit) HTTPError 403: <?xml version='1.0' encoding='UTF-8'?><Error><Code>AccessDenied</Code><Message>Access denied.</Message><Details>name-run-invoker@project-id.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.</Details></Error>\n```\n\nサービスアカウントには`storage.objects.get`は付いているのに…\n\n[ビルド結果の表示  |  Cloud Build のドキュメント  |  Google Cloud](https://cloud.google.com/cloud-build/docs/view-build-results#gcloud)\n\n特にログのバケットを指定してないため、ログを表示するにはプロジェクト＞閲覧者の権限も必要なよう\n\nいわゆる`roles/viewer`\n\n## projectの閲覧者権限の追加\n\n[個人的によく使うgcloudコマンドまとめ ~ IAM・サービスアカウント関連 ~](https://qiita.com/rodotan/items/9a97dbffd8cd0bbd3ae9)\n\n```shell\ngcloud projects add-iam-policy-binding ${project-id} --member=serviceAccount:${name}-run-invoker@${project-id}.iam.gserviceaccount.com --role=roles/viewer\n```\n\nこれで解決した\n\nなんとなくプロジェクトにまつわる権限の話がわかってきた気がするがはっきり説明できるほどにはなっていない…",
          "timeToRead": 1,
          "objectID": "67875ce1-4ae7-5251-9b9a-4e147102d386",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "__ais-highlight__B__/ais-highlight__uild のドキュメント  |  Google Cloud](https://cloud.google.com/cloud-__ais-highlight__b__/ais-highlight__uild/docs/view-__ais-highlight__b__/ais-highlight__uild-results#gcloud)\n\n特にログのバケット",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 25, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "gcloud __ais-highlight__b__/ais-highlight__uildsでログが見れない時",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/gcloud_project_iam/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nCloudRunでCDやろうと思ったらつまずいた\n\nサービスアカウントにコンテナのイメージをビルドさせたいときの話\n\n```\n$ gcloud __ais-highlight__b__/ais-highlight__uilds submit --tag gcr.io/${project-id}/${name}\nCheck the gcloud log [/home/circleci/.config/gcloud/logs/2020.12.10/18.23.37.852071.log] to see which files and the contents of the default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn                                                                           more).\n.....\n.....\n.....\nERROR: (gcloud.__ais-highlight__b__/ais-highlight__uilds.submit) HTTPError 403: <?xml version='1.0' encoding='UTF-8'?><Error><Code>AccessDenied</Code><Message>Access denied.</Message><Details>name-run-invoker@project-id.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.</Details></Error>\n```\n\nサービスアカウントには`storage.objects.get`は付いているのに…\n\n[ビルド結果の表示  |  Cloud __ais-highlight__B__/ais-highlight__uild のドキュメント  |  Google Cloud](https://cloud.google.com/cloud-__ais-highlight__b__/ais-highlight__uild/docs/view-__ais-highlight__b__/ais-highlight__uild-results#gcloud)\n\n特にログのバケットを指定してないため、ログを表示するにはプロジェクト＞閲覧者の権限も必要なよう\n\nいわゆる`roles/viewer`\n\n## projectの閲覧者権限の追加\n\n[個人的によく使うgcloudコマンドまとめ ~ IAM・サービスアカウント関連 ~](https://qiita.com/rodotan/items/9a97dbffd8cd0bbd3ae9)\n\n```shell\ngcloud projects add-iam-policy-__ais-highlight__b__/ais-highlight__inding ${project-id} --member=serviceAccount:${name}-run-invoker@${project-id}.iam.gserviceaccount.com --role=roles/viewer\n```\n\nこれで解決した\n\nなんとなくプロジェクトにまつわる権限の話がわかってきた気がするがはっきり説明できるほどにはなっていない…",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 21, 2022",
          "title": "GitHub Projects(beta)のデータを収集する",
          "slug": "/entries/github_projects_data_from_graphql/",
          "rawMarkdownBody": "\nGitHubのProjects（Beta）を使って自動化や集計をするなどしたい場合のメモ\n\nAPIの基本的な使い方に関しては下記を参照し、1つずつ実行していけばイメージはつかめる\n\n[APIを使ったプロジェクト（ベータ）の管理 - GitHub Docs](https://docs.github.com/ja/issues/trying-out-the-new-projects-experience/using-the-api-to-manage-projects)\n\n事前にProjectのIDだけ取得しメモしておく\n\n次のクエリ一発でだいたい必要なデータは取れそう\n\n```graphql\nquery ($project_id: ID!) {\n  node(id: $project_id) {\n    ... on ProjectNext {\n      items(first: 100) {\n        nodes {\n          title\n          createdAt\n          fieldValues(first: 8) {\n            nodes {\n              value\n              createdAt\n              projectField {\n                name\n                settings\n              }\n            }\n          }\n          content {\n            ... on Issue {\n              id\n              number\n              url\n              repository {\n                name\n              }\n              milestone {\n                id\n                title\n              }\n              createdAt\n              closed\n              closedAt\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n            }\n            ... on PullRequest {\n              id\n              number\n              url\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n              repository {\n                name\n              }\n              createdAt\n              closed\n              closedAt\n              merged\n              mergedAt\n              reviewRequests(first: 10) {\n                nodes {\n                  requestedReviewer {\n                    ... on User {\n                      name\n                    }\n                  }\n                }\n              }\n            }\n          }\n          id\n          updatedAt\n        }\n      }\n    }\n  }\n}\n```\n\nproject_idは事前にメモしておいた値\n\nどのカラムが必要かなどは下記で`Explorer`を展開して1つずつ見ていけば把握できる\n\n[Explorer - GitHub Docs](https://docs.github.com/ja/graphql/overview/explorer)\n\nExplorerのiframeの範囲が狭くて見づらいのがちょっと不満ではあるがそれ以外は便利に使える\n\nカードに紐づくIssueやPullRequestなどの情報も取ってこれるのでフラットにして集計する前のデータとして使える\n\nとりあえずプロジェクトのデータ使って云々やりたい場合はこのくらいデータが有れば十分かなと感じる\n\n- 結果（一部抜粋）\n\n```json\n{\n  \"data\": {\n    \"node\": {\n      \"items\": {\n        \"nodes\": [\n          {\n            \"title\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n            \"id\": \"PNI_xxxxxxxxxxxxxxxxxxxx\",\n            \"updatedAt\": \"2022-01-19T06:12:59Z\",\n            \"fieldValues\": {\n              \"nodes\": [\n                {\n                  \"value\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n                  \"projectField\": {\n                    \"name\": \"Title\",\n                    \"settings\": \"{\\\"width\\\":319}\"\n                  }\n                },\n                {\n                  \"value\": \"98236657\",\n                  \"projectField\": {\n                    \"name\": \"Status\",\n                    \"settings\": \"{\\\"width\\\":125,\\\"options\\\":[{\\\"id\\\":\\\"xxxxxxx1\\\",\\\"name\\\":\\\"New\\\",\\\"name_html\\\":\\\"New\\\"},{\\\"id\\\":\\\"xxxxxxx2\\\",\\\"name\\\":\\\"Epic\\\",\\\"name_html\\\":\\\"Epic\\\"},{\\\"id\\\":\\\"xxxxxxx3\\\",\\\"name\\\":\\\"Idea\\\",\\\"name_html\\\":\\\"Idea\\\"},{\\\"id\\\":\\\"xxxxxxx4\\\",\\\"name\\\":\\\"Todo\\\",\\\"name_html\\\":\\\"Todo\\\"},{\\\"id\\\":\\\"xxxxxxx5\\\",\\\"name\\\":\\\"In Progress\\\",\\\"name_html\\\":\\\"In Progress\\\"},{\\\"id\\\":\\\"xxxxxxx6\\\",\\\"name\\\":\\\"Review\\\",\\\"name_html\\\":\\\"Review\\\"},{\\\"id\\\":\\\"xxxxxxx7\\\",\\\"name\\\":\\\"Done\\\",\\\"name_html\\\":\\\"Done\\\"}]}\"\n                  }\n                },\n                {\n                  \"value\": \"2\",\n                  \"projectField\": {\n                    \"name\": \"Point\",\n                    \"settings\": \"{\\\"width\\\":69}\"\n                  }\n                },\n                {\n                  \"value\": \"2022-01-01T00:00:00+00:00\",\n                  \"projectField\": {\n                    \"name\": \"Month\",\n                    \"settings\": \"null\"\n                  }\n                },\n                {\n                  \"value\": \"e9bbecfa\",\n                  \"projectField\": {\n                    \"name\": \"Iteration\",\n                    \"settings\": \"{\\\"configuration\\\":{\\\"duration\\\":14,\\\"start_day\\\":1,\\\"iterations\\\":[{\\\"id\\\":\\\"xxxxxxa\\\",\\\"title\\\":\\\"2022-01_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-17\\\",\\\"title_html\\\":\\\"2022-01_2\\\"},{\\\"id\\\":\\\"xxxxxxb\\\",\\\"title\\\":\\\"2022-02_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-31\\\",\\\"title_html\\\":\\\"2022-02_1\\\"},{\\\"id\\\":\\\"xxxxxxc\\\",\\\"title\\\":\\\"2022-02_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-02-14\\\",\\\"title_html\\\":\\\"2022-02_2\\\"}],\\\"completed_iterations\\\":[{\\\"id\\\":\\\"xxxxxxd\\\",\\\"title\\\":\\\"2022-01_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-03\\\",\\\"title_html\\\":\\\"2022-01_1\\\"},{\\\"id\\\":\\\"xxxxxxe\\\",\\\"title\\\":\\\"Iteration 1\\\",\\\"duration\\\":7,\\\"start_date\\\":\\\"2021-12-27\\\",\\\"title_html\\\":\\\"Iteration 1\\\"}]}}\"\n                  }\n                }\n              ]\n            },\n            \"content\": {\n              \"id\": \"I_xxxxxxxxxxxxxxxx\",\n              \"number\": 56,\n              \"url\": \"https://github.com/swfz/tools/issues/56\",\n              \"closed\": true,\n              \"closedAt\": \"2022-01-20T16:27:38Z\",\n              \"createdAt\": \"2022-01-19T06:12:59Z\",\n              \"repository\": {\n                \"name\": \"tools\"\n              },\n              \"milestone\": null,\n              \"assignees\": {\n                \"nodes\": [\n                  {\n                    \"name\": \"swfz\"\n                  }\n                ]\n              }\n            }\n          },\n          .....\n          .....\n          .....\n          .....\n```\n\nまた、実際にこのデータを用いて何かやるなら100件以上のデータが存在することのほうが多いはずなのでページングにも対応したクエリにする必要があるが今回はここまで\n",
          "timeToRead": 3,
          "objectID": "c5f74971-5cdb-55f9-ab0e-c99b41357a69",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nGitHubのProjects（__ais-highlight__B__/ais-highlight__eta）を使って自動化や集計をするなどしたい場合のメモ\n\nAPIの",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 21, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "GitHub Projects(__ais-highlight__b__/ais-highlight__eta)のデータを収集する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/github_projects_data_from_graphql/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nGitHubのProjects（__ais-highlight__B__/ais-highlight__eta）を使って自動化や集計をするなどしたい場合のメモ\n\nAPIの基本的な使い方に関しては下記を参照し、1つずつ実行していけばイメージはつかめる\n\n[APIを使ったプロジェクト（ベータ）の管理 - GitHub Docs](https://docs.github.com/ja/issues/trying-out-the-new-projects-experience/using-the-api-to-manage-projects)\n\n事前にProjectのIDだけ取得しメモしておく\n\n次のクエリ一発でだいたい必要なデータは取れそう\n\n```graphql\nquery ($project_id: ID!) {\n  node(id: $project_id) {\n    ... on ProjectNext {\n      items(first: 100) {\n        nodes {\n          title\n          createdAt\n          fieldValues(first: 8) {\n            nodes {\n              value\n              createdAt\n              projectField {\n                name\n                settings\n              }\n            }\n          }\n          content {\n            ... on Issue {\n              id\n              number\n              url\n              repository {\n                name\n              }\n              milestone {\n                id\n                title\n              }\n              createdAt\n              closed\n              closedAt\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n            }\n            ... on PullRequest {\n              id\n              number\n              url\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n              repository {\n                name\n              }\n              createdAt\n              closed\n              closedAt\n              merged\n              mergedAt\n              reviewRequests(first: 10) {\n                nodes {\n                  requestedReviewer {\n                    ... on User {\n                      name\n                    }\n                  }\n                }\n              }\n            }\n          }\n          id\n          updatedAt\n        }\n      }\n    }\n  }\n}\n```\n\nproject_idは事前にメモしておいた値\n\nどのカラムが必要かなどは下記で`Explorer`を展開して1つずつ見ていけば把握できる\n\n[Explorer - GitHub Docs](https://docs.github.com/ja/graphql/overview/explorer)\n\nExplorerのiframeの範囲が狭くて見づらいのがちょっと不満ではあるがそれ以外は便利に使える\n\nカードに紐づくIssueやPullRequestなどの情報も取ってこれるのでフラットにして集計する前のデータとして使える\n\nとりあえずプロジェクトのデータ使って云々やりたい場合はこのくらいデータが有れば十分かなと感じる\n\n- 結果（一部抜粋）\n\n```json\n{\n  \"data\": {\n    \"node\": {\n      \"items\": {\n        \"nodes\": [\n          {\n            \"title\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n            \"id\": \"PNI_xxxxxxxxxxxxxxxxxxxx\",\n            \"updatedAt\": \"2022-01-19T06:12:59Z\",\n            \"fieldValues\": {\n              \"nodes\": [\n                {\n                  \"value\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n                  \"projectField\": {\n                    \"name\": \"Title\",\n                    \"settings\": \"{\\\"width\\\":319}\"\n                  }\n                },\n                {\n                  \"value\": \"98236657\",\n                  \"projectField\": {\n                    \"name\": \"Status\",\n                    \"settings\": \"{\\\"width\\\":125,\\\"options\\\":[{\\\"id\\\":\\\"xxxxxxx1\\\",\\\"name\\\":\\\"New\\\",\\\"name_html\\\":\\\"New\\\"},{\\\"id\\\":\\\"xxxxxxx2\\\",\\\"name\\\":\\\"Epic\\\",\\\"name_html\\\":\\\"Epic\\\"},{\\\"id\\\":\\\"xxxxxxx3\\\",\\\"name\\\":\\\"Idea\\\",\\\"name_html\\\":\\\"Idea\\\"},{\\\"id\\\":\\\"xxxxxxx4\\\",\\\"name\\\":\\\"Todo\\\",\\\"name_html\\\":\\\"Todo\\\"},{\\\"id\\\":\\\"xxxxxxx5\\\",\\\"name\\\":\\\"In Progress\\\",\\\"name_html\\\":\\\"In Progress\\\"},{\\\"id\\\":\\\"xxxxxxx6\\\",\\\"name\\\":\\\"Review\\\",\\\"name_html\\\":\\\"Review\\\"},{\\\"id\\\":\\\"xxxxxxx7\\\",\\\"name\\\":\\\"Done\\\",\\\"name_html\\\":\\\"Done\\\"}]}\"\n                  }\n                },\n                {\n                  \"value\": \"2\",\n                  \"projectField\": {\n                    \"name\": \"Point\",\n                    \"settings\": \"{\\\"width\\\":69}\"\n                  }\n                },\n                {\n                  \"value\": \"2022-01-01T00:00:00+00:00\",\n                  \"projectField\": {\n                    \"name\": \"Month\",\n                    \"settings\": \"null\"\n                  }\n                },\n                {\n                  \"value\": \"e9bbecfa\",\n                  \"projectField\": {\n                    \"name\": \"Iteration\",\n                    \"settings\": \"{\\\"configuration\\\":{\\\"duration\\\":14,\\\"start_day\\\":1,\\\"iterations\\\":[{\\\"id\\\":\\\"xxxxxxa\\\",\\\"title\\\":\\\"2022-01_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-17\\\",\\\"title_html\\\":\\\"2022-01_2\\\"},{\\\"id\\\":\\\"xxxxxxb\\\",\\\"title\\\":\\\"2022-02_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-31\\\",\\\"title_html\\\":\\\"2022-02_1\\\"},{\\\"id\\\":\\\"xxxxxxc\\\",\\\"title\\\":\\\"2022-02_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-02-14\\\",\\\"title_html\\\":\\\"2022-02_2\\\"}],\\\"completed_iterations\\\":[{\\\"id\\\":\\\"xxxxxxd\\\",\\\"title\\\":\\\"2022-01_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-03\\\",\\\"title_html\\\":\\\"2022-01_1\\\"},{\\\"id\\\":\\\"xxxxxxe\\\",\\\"title\\\":\\\"Iteration 1\\\",\\\"duration\\\":7,\\\"start_date\\\":\\\"2021-12-27\\\",\\\"title_html\\\":\\\"Iteration 1\\\"}]}}\"\n                  }\n                }\n              ]\n            },\n            \"content\": {\n              \"id\": \"I_xxxxxxxxxxxxxxxx\",\n              \"number\": 56,\n              \"url\": \"https://github.com/swfz/tools/issues/56\",\n              \"closed\": true,\n              \"closedAt\": \"2022-01-20T16:27:38Z\",\n              \"createdAt\": \"2022-01-19T06:12:59Z\",\n              \"repository\": {\n                \"name\": \"tools\"\n              },\n              \"milestone\": null,\n              \"assignees\": {\n                \"nodes\": [\n                  {\n                    \"name\": \"swfz\"\n                  }\n                ]\n              }\n            }\n          },\n          .....\n          .....\n          .....\n          .....\n```\n\nまた、実際にこのデータを用いて何かやるなら100件以上のデータが存在することのほうが多いはずなのでページングにも対応したクエリにする必要があるが今回はここまで\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "June 22, 2021",
          "title": "node-fetchでBasicAuthする",
          "slug": "/entries/basic_auth_in_node_fetch/",
          "rawMarkdownBody": "\n## auth用の文字列の生成\n\n今どきは`new Buffer`ではないらしい\n\n次のようなWarningが出力される\n\n```\n(node:22161) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n```\n\nということで下記のように認証用の文字列を生成する\n\n```javascript\nconst buffer = Buffer.from(`username:token`);\nconst authString = buffer.toString('base64');\n```\n\n## リクエスト\n\n```javascript\nconst request = async () => {\n  const res = await fetch(`https://example.com`, {\n    method: 'GET',\n    headers: {\n      'Accept': 'application/json',\n      'Authorization': `Basic ${authString}`\n    }\n  });\n\n  return await res.json();\n}\n\n(async () => {\n  const json = request();\n  console.log(json);\n})();\n```\n\nheadersの`Authorization`にユーザー名とTOKENやパスワードを`:`でつなげbase64した文字列を入れる\n\nそれだけ",
          "timeToRead": 1,
          "objectID": "2b3a59a9-d2a1-5d40-b7f8-4da4b20870f4",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "22161) [DEP0005] DeprecationWarning: __ais-highlight__B__/ais-highlight__uffer() is deprecated due to security and usability issues. Please use the __ais-highlight__B__/ais-highlight__uffer.alloc(), __ais-highlight__B__/ais-highlight__uffer.allocUnsafe(), or __ais-highlight__B__/ais-highlight__uffer.from() methods instead.\n(Use `node --trace-deprecation ...` to show",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "June 22, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "node-fetchで__ais-highlight__B__/ais-highlight__asicAuthする",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__asic_auth_in_node_fetch/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n## auth用の文字列の生成\n\n今どきは`new __ais-highlight__B__/ais-highlight__uffer`ではないらしい\n\n次のようなWarningが出力される\n\n```\n(node:22161) [DEP0005] DeprecationWarning: __ais-highlight__B__/ais-highlight__uffer() is deprecated due to security and usability issues. Please use the __ais-highlight__B__/ais-highlight__uffer.alloc(), __ais-highlight__B__/ais-highlight__uffer.allocUnsafe(), or __ais-highlight__B__/ais-highlight__uffer.from() methods instead.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n```\n\nということで下記のように認証用の文字列を生成する\n\n```javascript\nconst __ais-highlight__b__/ais-highlight__uffer = __ais-highlight__B__/ais-highlight__uffer.from(`username:token`);\nconst authString = __ais-highlight__b__/ais-highlight__uffer.toString('__ais-highlight__b__/ais-highlight__ase64');\n```\n\n## リクエスト\n\n```javascript\nconst request = async () => {\n  const res = await fetch(`https://example.com`, {\n    method: 'GET',\n    headers: {\n      'Accept': 'application/json',\n      'Authorization': `__ais-highlight__B__/ais-highlight__asic ${authString}`\n    }\n  });\n\n  return await res.json();\n}\n\n(async () => {\n  const json = request();\n  console.log(json);\n})();\n```\n\nheadersの`Authorization`にユーザー名とTOKENやパスワードを`:`でつなげ__ais-highlight__b__/ais-highlight__ase64した文字列を入れる\n\nそれだけ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "December 12, 2020",
          "title": "curl: (3) [globbing] error: bad range specification after pos 3",
          "slug": "/entries/curl_with_grep_color/",
          "rawMarkdownBody": "\ntflintを入れてみようと思いREADMEにしたがいワンライナーで落としてこようと思ったら思わぬところでつまずいた\n\n```shell\n$ curl -L \"$(curl -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\")\" -o tflint.zip && unzip tflint.zip && rm tflint.zip\ncurl: (3) [globbing] error: bad range specification after pos 3\n```\n\nglob…どこかで`[]`や`{}`使っているか?という感じだったが`grep`が悪さをしていた\n\n自分のシェル環境だとデフォルトでgrepの結果に色をつけるようにしていたのでその結果に対して`curl`しようとすることでエスケープシーケンスも含まれてしまっていた\n\n```\n$ curl  -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\" > url.txt\n$ cat -v url.txt\n^[[01;31m^[[Khttps://github.com/terraform-linters/tflint/releases/download/v0.22.0/tflint_linux_amd64.zip^[[m^[[K\n```\n\nもともとURLに`[]`や`{}`が含まれているパターンではないのでこの場合の対応は`--globoff`ではだめだった\n\n`grep --color=no`を追加することでcurl対象のURLがプレーンなテキストになるのでcurlできるようになった\n\nエスケープシーケンスはよくやるので気を付けたい\n",
          "timeToRead": 1,
          "objectID": "cf55191e-5e3e-54f6-8964-be56698fe6ff",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "amd64.zip\")\" -o tflint.zip && unzip tflint.zip && rm tflint.zip\ncurl: (3) [globbing] error: __ais-highlight__b__/ais-highlight__ad range specification after pos 3\n```\n\nglob…どこかで`[]`や`{}`使って",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "December 12, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "curl: (3) [globbing] error: __ais-highlight__b__/ais-highlight__ad range specification after pos 3",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/curl_with_grep_color/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\ntflintを入れてみようと思いREADMEにしたがいワンライナーで落としてこようと思ったら思わぬところでつまずいた\n\n```shell\n$ curl -L \"$(curl -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\")\" -o tflint.zip && unzip tflint.zip && rm tflint.zip\ncurl: (3) [globbing] error: __ais-highlight__b__/ais-highlight__ad range specification after pos 3\n```\n\nglob…どこかで`[]`や`{}`使っているか?という感じだったが`grep`が悪さをしていた\n\n自分のシェル環境だとデフォルトでgrepの結果に色をつけるようにしていたのでその結果に対して`curl`しようとすることでエスケープシーケンスも含まれてしまっていた\n\n```\n$ curl  -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\" > url.txt\n$ cat -v url.txt\n^[[01;31m^[[Khttps://github.com/terraform-linters/tflint/releases/download/v0.22.0/tflint_linux_amd64.zip^[[m^[[K\n```\n\nもともとURLに`[]`や`{}`が含まれているパターンではないのでこの場合の対応は`--globoff`ではだめだった\n\n`grep --color=no`を追加することでcurl対象のURLがプレーンなテキストになるのでcurlできるようになった\n\nエスケープシーケンスはよくやるので気を付けたい\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 28, 2022",
          "title": "JSONファイルをBigQueryに読ませJSON型で扱うためにそのままCSVで保存する",
          "slug": "/entries/json_to_csv/",
          "rawMarkdownBody": "\n[Working with JSON data in Standard SQL  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/json-data)\n\n先日BigQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
          "timeToRead": 1,
          "objectID": "6ed6b22c-63cc-5fb2-99d6-eeada5709406",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__B__/ais-highlight__igQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__b__/ais-highlight__igquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__B__/ais-highlight__igQueryでnative JSON型が",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 28, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "JSONファイルを__ais-highlight__B__/ais-highlight__igQueryに読ませJSON型で扱うためにそのままCSVで保存する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__B__/ais-highlight__igQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__b__/ais-highlight__igquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__B__/ais-highlight__igQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\n__ais-highlight__b__/ais-highlight__q load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "November 15, 2020",
          "title": "Error: React-Hot-Loader: AppContainer should be patched",
          "slug": "/entries/react_hot_loader_should_be_patched/",
          "rawMarkdownBody": "\n次のリンクとまったく同じ状態になった\n\n[Gatsby doesn't work with React 17 RC (Error: React-Hot-Loader: AppContainer should be patched) · Issue #26979 · gatsbyjs/gatsby](https://github.com/gatsbyjs/gatsby/issues/26979)\n\nhttps://github.com/gatsbyjs/gatsby/issues/26979#issuecomment-696702777\n\nのコメントにあるようにパッケージのバージョンを上げればOKのよう\n\n`react-hot-loader`自体はgatsbyの依存モジュールで`package.json`には含まれていなかったため\n\n気にせず`yarn add`したら解決するかと思ったら解決せず…\n\n`yarn why`で確認すると2つのバージョンが混在する状態になっていた\n\n```shell\n$ yarn why react-hot-loader\nyarn why v1.22.5\n[1/4] Why do we have the module \"react-hot-loader\"...?\n[2/4] Initialising dependency graph...\n[3/4] Finding dependency...\n[4/4] Calculating file sizes...\n=> Found \"react-hot-loader@4.13.0\"\ninfo Has been hoisted to \"react-hot-loader\"\ninfo This module exists because it's specified in \"devDependencies\".\ninfo Disk size without dependencies: \"652KB\"\ninfo Disk size with unique dependencies: \"1.96MB\"\ninfo Disk size with transitive dependencies: \"2.8MB\"\ninfo Number of shared dependencies: 16\n=> Found \"gatsby#react-hot-loader@4.12.21\"\ninfo This module exists because \"gatsby\" depends on it.\ninfo Disk size without dependencies: \"288KB\"\ninfo Disk size with unique dependencies: \"1.61MB\"\ninfo Disk size with transitive dependencies: \"2.45MB\"\ninfo Number of shared dependencies: 16\nDone in 1.94s.\n```\n\n新たにインストールしたほうは呼ばれていないっぽい\n\nということで次の記事を参考にして`yarn.lock`の`gatsby#react-hot-loader`の部分を削除して再度`yarn install`で解決した\n\n[yarn upgrade で更新できない間接的な依存パッケージだけをアップグレードするには - Qiita](https://qiita.com/uasi/items/ca440a750a77ca62321b)\n\n[https://qiita.com/uasi/items/ca440a750a77ca62321b:embed:cite]\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\n直接`yarn.lock`触るのはちょっと気が引けたので別の機会で他の方法がないか調べてみようと思う\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->",
          "timeToRead": 2,
          "objectID": "615d3429-691b-5e22-8a3d-081486b9673c",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "dependency...\n[4/4] Calculating file sizes...\n=> Found \"react-hot-loader@4.13.0\"\ninfo Has __ais-highlight__b__/ais-highlight__een hoisted to \"react-hot-loader\"\ninfo This module exists __ais-highlight__b__/ais-highlight__ecause it's specified in",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "November 15, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Error: React-Hot-Loader: AppContainer should __ais-highlight__b__/ais-highlight__e patched",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/react_hot_loader_should___ais-highlight__b__/ais-highlight__e_patched/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n次のリンクとまったく同じ状態になった\n\n[Gatsby doesn't work with React 17 RC (Error: React-Hot-Loader: AppContainer should __ais-highlight__b__/ais-highlight__e patched) · Issue #26979 · gatsbyjs/gatsby](https://github.com/gatsbyjs/gatsby/issues/26979)\n\nhttps://github.com/gatsbyjs/gatsby/issues/26979#issuecomment-696702777\n\nのコメントにあるようにパッケージのバージョンを上げればOKのよう\n\n`react-hot-loader`自体はgatsbyの依存モジュールで`package.json`には含まれていなかったため\n\n気にせず`yarn add`したら解決するかと思ったら解決せず…\n\n`yarn why`で確認すると2つのバージョンが混在する状態になっていた\n\n```shell\n$ yarn why react-hot-loader\nyarn why v1.22.5\n[1/4] Why do we have the module \"react-hot-loader\"...?\n[2/4] Initialising dependency graph...\n[3/4] Finding dependency...\n[4/4] Calculating file sizes...\n=> Found \"react-hot-loader@4.13.0\"\ninfo Has __ais-highlight__b__/ais-highlight__een hoisted to \"react-hot-loader\"\ninfo This module exists __ais-highlight__b__/ais-highlight__ecause it's specified in \"devDependencies\".\ninfo Disk size without dependencies: \"652KB\"\ninfo Disk size with unique dependencies: \"1.96MB\"\ninfo Disk size with transitive dependencies: \"2.8MB\"\ninfo Number of shared dependencies: 16\n=> Found \"gatsby#react-hot-loader@4.12.21\"\ninfo This module exists __ais-highlight__b__/ais-highlight__ecause \"gatsby\" depends on it.\ninfo Disk size without dependencies: \"288KB\"\ninfo Disk size with unique dependencies: \"1.61MB\"\ninfo Disk size with transitive dependencies: \"2.45MB\"\ninfo Number of shared dependencies: 16\nDone in 1.94s.\n```\n\n新たにインストールしたほうは呼ばれていないっぽい\n\nということで次の記事を参考にして`yarn.lock`の`gatsby#react-hot-loader`の部分を削除して再度`yarn install`で解決した\n\n[yarn upgrade で更新できない間接的な依存パッケージだけをアップグレードするには - Qiita](https://qiita.com/uasi/items/ca440a750a77ca62321b)\n\n[https://qiita.com/uasi/items/ca440a750a77ca62321b:embed:cite]\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\n直接`yarn.lock`触るのはちょっと気が引けたので別の機会で他の方法がないか調べてみようと思う\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 07, 2021",
          "title": "PocketのデータをAPI経由でBigQueryに取り込む",
          "slug": "/entries/start_pocket_api/",
          "rawMarkdownBody": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONをBigQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`bq load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:bqjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and be at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### BigQueryに入れ込む\n\n```\nbq load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
          "timeToRead": 3,
          "objectID": "196c4775-45c9-57b9-a004-cefc6bc4752e",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ったのでその場合は空配列にする\n\n### __ais-highlight__B__/ais-highlight__igQueryに入れ込む\n\n```\n__ais-highlight__b__/ais-highlight__q load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 07, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "PocketのデータをAPI経由で__ais-highlight__B__/ais-highlight__igQueryに取り込む",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/start_pocket_api/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONを__ais-highlight__B__/ais-highlight__igQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`__ais-highlight__b__/ais-highlight__q load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:__ais-highlight__b__/ais-highlight__qjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and __ais-highlight__b__/ais-highlight__e at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### __ais-highlight__B__/ais-highlight__igQueryに入れ込む\n\n```\n__ais-highlight__b__/ais-highlight__q load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 13, 2021",
          "title": "Workflowsで Memory usage limit exeeded",
          "slug": "/entries/workflows_logging_bigquery_failed/",
          "rawMarkdownBody": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのままBigQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクでBigQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+BigQueryへloadってパターンがベターなのかな",
          "timeToRead": 2,
          "objectID": "18e04e5f-00f2-50a2-a8d7-b7ac41718457",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "たいてそのレスポンスをそのまま__ais-highlight__B__/ais-highlight__igQueryに突っ込むみたいなやつ\n\nプライ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 13, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Workflowsで Memory usage limit exeeded",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/workflows_logging___ais-highlight__b__/ais-highlight__igquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__B__/ais-highlight__igQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクで__ais-highlight__B__/ais-highlight__igQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena___ais-highlight__b__/ais-highlight__ookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena___ais-highlight__b__/ais-highlight__ookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+__ais-highlight__B__/ais-highlight__igQueryへloadってパターンがベターなのかな",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 26, 2021",
          "title": "MySQLのgenerallogから特定のSQLを抜き出す",
          "slug": "/entries/filter_by_explain_result/",
          "rawMarkdownBody": "\nAWSで稼働しているRDSからgeneral logを取ってきてそのクエリログから特定のクエリを抽出してExplainの結果を判定するということをやったのでそのときやったことをメモしておく\n\n単発だったのでいくつか簡単なスクリプトを書いて対応したがしくみ化するならいろいろおもしろいかも\n\n## 前提\n\nローカルからのフォワーディングや本番サーバなどから実行するなど本番のDBに接続できる必要がある\n\ngeneral logをファイルに出力する設定をしておく必要がある\n\n## やること\n### general logの取得\n\nAPIのドキュメントは下記\n\n[Accessing Amazon RDS database log files - Amazon Relational Database Service](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html)\n\n直近24時間分のログが取れる\n\n数値はUTC時刻の範囲で出力されるっぽいので`general/mysql-general.log.0`はJSTでは`09:00`台の内容\n\n```shell\n#!/bin/bash\n\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.0  > 0.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.1  > 1.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.2  > 2.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.3  > 3.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.4  > 4.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.5  > 5.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.6  > 6.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.7  > 7.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.8  > 8.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.9  > 9.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.10 > 10.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.11 > 11.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.12 > 12.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.13 > 13.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.14 > 14.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.15 > 15.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.16 > 16.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.17 > 17.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.18 > 18.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.19 > 19.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.20 > 20.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.21 > 21.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.22 > 22.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.23 > 23.log\n```\n\n### クエリのフォーマット、フィルタリング\n\ngeneral logの形式が次のような感じなのでクエリ部分を抜き出す必要がある\n\n```\nTime                 Id Command    Argument\n                946458 Query    SELECT hoge FROM fuga....\n```\n\n[Mysql general log parser](https://gist.github.com/httpdss/948386)\n\n<!-- textlint-disable prh,spellcheck-tech-word -->\nからパーススクリプトを持ってきて配置し（mysql-general-log-parser.pl）次のようなシェルを書いた\n<!-- textlint-enable prh,spellcheck-tech-word  -->\n\n- filter_general_log.sh\n\n```shell\nfile=$1\n\nperl mysql-general-log-parser.pl $file | grep -v 'Your log message was truncated' | grep -v 'rds_heartbeat2' | grep -v 'rds_configuration' | grep -v 'mysql-connector-java' | grep -v 'EXPLAIN ' | sort | uniq > $file.query_list.txt\n```\n\n- 実行\n\n```shell\nls -l {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23}.log | awk '{print $9}' | xargs -i ./filter_general_log.sh {}\n```\n\n### 生成したファイルをマージする\n\n```\ncat *.query_list.txt > query_list.txt\n```\n\n### 特定クエリの抽出\n\n`GROUP BY`, `DISTINCT`を使用しているクエリを拾う\n\n- filter_group_by_query.py\n\n```python\nimport sqlparse\nimport sys\n\nfilepath = sys.argv[1]\n\nf = open(filepath)\nlines = f.readlines()\nf.close()\n\nfor line in lines:\n    parsed = sqlparse.parse(line)[0]\n    tokens = list(parsed.flatten())\n    is_grouped = filter(lambda t: t.match(sqlparse.tokens.Keyword, \"GROUP\\s+BY\", regex=True), tokens)\n    is_distinct = filter(lambda t: t.match(sqlparse.tokens.Name, \"DISTINCT\"), tokens)\n    if len(list(is_grouped)) > 0 or len(list(is_distinct )) > 0:\n        print(line)\n```\n\n- 実行\n\n```shell\npip install sqlparse\npython filter_group_by_query.py query_list.txt > group_by_query.txt\n```\n\n### チェック\n\nexplainの結果に`Using index for group-by`が含まれるものを抜き出す\n\n- check_group_by_query.sh\n\n```shell\n#!/bin/bash\n\nfile=$1\n\ncnt=0\ncat $file | while read line\ndo\n  cnt=`expr $cnt + 1`\n  echo $cnt\n  mysql -uhoge -P 13306 -h localhost -ppass dbname -e \"EXPLAIN $line\" | grep 'Using index for group-by'\n  if [ $? -eq 0 ]; then\n    echo \"Found Query\"\n    echo $line\n    echo $line >> result.txt\n  fi\ndone\n```\n\n- 実行\n\n```\nsh check_group_by_query.sh group_by_query.txt\n```\n\nという感じでいくつかのクエリを探すようなことをした",
          "timeToRead": 5,
          "objectID": "847cfd9d-a35c-5a9e-a4e9-7bb2044e7191",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "__ais-highlight__b__/ais-highlight__y`が含まれるものを抜き出す\n\n- check_group___ais-highlight__b__/ais-highlight__y_query.sh\n\n```shell\n#!/__ais-highlight__b__/ais-highlight__in/__ais-highlight__b__/ais-highlight__ash\n\nfile=$1\n\ncnt=0\ncat $file | while read line",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 26, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "MySQLのgenerallogから特定のSQLを抜き出す",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/filter___ais-highlight__b__/ais-highlight__y_explain_result/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nAWSで稼働しているRDSからgeneral logを取ってきてそのクエリログから特定のクエリを抽出してExplainの結果を判定するということをやったのでそのときやったことをメモしておく\n\n単発だったのでいくつか簡単なスクリプトを書いて対応したがしくみ化するならいろいろおもしろいかも\n\n## 前提\n\nローカルからのフォワーディングや本番サーバなどから実行するなど本番のDBに接続できる必要がある\n\ngeneral logをファイルに出力する設定をしておく必要がある\n\n## やること\n### general logの取得\n\nAPIのドキュメントは下記\n\n[Accessing Amazon RDS database log files - Amazon Relational Database Service](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html)\n\n直近24時間分のログが取れる\n\n数値はUTC時刻の範囲で出力されるっぽいので`general/mysql-general.log.0`はJSTでは`09:00`台の内容\n\n```shell\n#!/__ais-highlight__b__/ais-highlight__in/__ais-highlight__b__/ais-highlight__ash\n\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.0  > 0.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.1  > 1.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.2  > 2.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.3  > 3.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.4  > 4.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.5  > 5.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.6  > 6.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.7  > 7.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.8  > 8.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.9  > 9.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.10 > 10.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.11 > 11.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.12 > 12.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.13 > 13.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.14 > 14.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.15 > 15.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.16 > 16.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.17 > 17.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.18 > 18.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.19 > 19.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.20 > 20.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.21 > 21.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.22 > 22.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.23 > 23.log\n```\n\n### クエリのフォーマット、フィルタリング\n\ngeneral logの形式が次のような感じなのでクエリ部分を抜き出す必要がある\n\n```\nTime                 Id Command    Argument\n                946458 Query    SELECT hoge FROM fuga....\n```\n\n[Mysql general log parser](https://gist.github.com/httpdss/948386)\n\n<!-- textlint-disable prh,spellcheck-tech-word -->\nからパーススクリプトを持ってきて配置し（mysql-general-log-parser.pl）次のようなシェルを書いた\n<!-- textlint-enable prh,spellcheck-tech-word  -->\n\n- filter_general_log.sh\n\n```shell\nfile=$1\n\nperl mysql-general-log-parser.pl $file | grep -v 'Your log message was truncated' | grep -v 'rds_heartbeat2' | grep -v 'rds_configuration' | grep -v 'mysql-connector-java' | grep -v 'EXPLAIN ' | sort | uniq > $file.query_list.txt\n```\n\n- 実行\n\n```shell\nls -l {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23}.log | awk '{print $9}' | xargs -i ./filter_general_log.sh {}\n```\n\n### 生成したファイルをマージする\n\n```\ncat *.query_list.txt > query_list.txt\n```\n\n### 特定クエリの抽出\n\n`GROUP __ais-highlight__B__/ais-highlight__Y`, `DISTINCT`を使用しているクエリを拾う\n\n- filter_group___ais-highlight__b__/ais-highlight__y_query.py\n\n```python\nimport sqlparse\nimport sys\n\nfilepath = sys.argv[1]\n\nf = open(filepath)\nlines = f.readlines()\nf.close()\n\nfor line in lines:\n    parsed = sqlparse.parse(line)[0]\n    tokens = list(parsed.flatten())\n    is_grouped = filter(lambda t: t.match(sqlparse.tokens.Keyword, \"GROUP\\s+__ais-highlight__B__/ais-highlight__Y\", regex=True), tokens)\n    is_distinct = filter(lambda t: t.match(sqlparse.tokens.Name, \"DISTINCT\"), tokens)\n    if len(list(is_grouped)) > 0 or len(list(is_distinct )) > 0:\n        print(line)\n```\n\n- 実行\n\n```shell\npip install sqlparse\npython filter_group___ais-highlight__b__/ais-highlight__y_query.py query_list.txt > group___ais-highlight__b__/ais-highlight__y_query.txt\n```\n\n### チェック\n\nexplainの結果に`Using index for group-__ais-highlight__b__/ais-highlight__y`が含まれるものを抜き出す\n\n- check_group___ais-highlight__b__/ais-highlight__y_query.sh\n\n```shell\n#!/__ais-highlight__b__/ais-highlight__in/__ais-highlight__b__/ais-highlight__ash\n\nfile=$1\n\ncnt=0\ncat $file | while read line\ndo\n  cnt=`expr $cnt + 1`\n  echo $cnt\n  mysql -uhoge -P 13306 -h localhost -ppass dbname -e \"EXPLAIN $line\" | grep 'Using index for group-__ais-highlight__b__/ais-highlight__y'\n  if [ $? -eq 0 ]; then\n    echo \"Found Query\"\n    echo $line\n    echo $line >> result.txt\n  fi\ndone\n```\n\n- 実行\n\n```\nsh check_group___ais-highlight__b__/ais-highlight__y_query.sh group___ais-highlight__b__/ais-highlight__y_query.txt\n```\n\nという感じでいくつかのクエリを探すようなことをした",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "5",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 07, 2021",
          "title": "Terraform+GCSでバックエンドの設定をCLIで行う",
          "slug": "/entries/terraform_gcs_backend/",
          "rawMarkdownBody": "\n環境ごとにバックエンドの設定を変えたりする場合などに有効\n\n- backend.tf\n\n```terraform\nterraform {\n  backend \"gcs\" {\n  }\n}\n```\n\n## ファイルから設定する\n\n- backend-config.tfvars\n\n```tfvars\nbucket = \"hoge-tfstate\"\nprefix = \"prefix-hoge\"\n```\n\n```shell\nterraform init -backend-config=backend-config.tfvars\n```\n\n## コマンドラインから設定する\n\n```shell\nterraform init -backend-config=\"bucket=hoge-tfstate\" -backend-config=\"prefix=prefix-hoge\"\n```\n",
          "timeToRead": 1,
          "objectID": "99e788a3-d7c3-5b67-97fa-85e0fa23dfbb",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "tf\n\n```terraform\nterraform {\n  __ais-highlight__b__/ais-highlight__ackend \"gcs\" {\n  }\n}\n```\n\n## ファイルから設定する\n\n- __ais-highlight__b__/ais-highlight__ackend-config.tfvars\n\n```tfvars\n__ais-highlight__b__/ais-highlight__ucket = \"hoge-tfstate\"\nprefix = \"prefix-hoge\"\n```\n\n```shell\nterraform init -__ais-highlight__b__/ais-highlight__ackend-config",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 07, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Terraform+GCSでバックエンドの設定をCLIで行う",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/terraform_gcs___ais-highlight__b__/ais-highlight__ackend/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n環境ごとにバックエンドの設定を変えたりする場合などに有効\n\n- __ais-highlight__b__/ais-highlight__ackend.tf\n\n```terraform\nterraform {\n  __ais-highlight__b__/ais-highlight__ackend \"gcs\" {\n  }\n}\n```\n\n## ファイルから設定する\n\n- __ais-highlight__b__/ais-highlight__ackend-config.tfvars\n\n```tfvars\n__ais-highlight__b__/ais-highlight__ucket = \"hoge-tfstate\"\nprefix = \"prefix-hoge\"\n```\n\n```shell\nterraform init -__ais-highlight__b__/ais-highlight__ackend-config=__ais-highlight__b__/ais-highlight__ackend-config.tfvars\n```\n\n## コマンドラインから設定する\n\n```shell\nterraform init -__ais-highlight__b__/ais-highlight__ackend-config=\"__ais-highlight__b__/ais-highlight__ucket=hoge-tfstate\" -__ais-highlight__b__/ais-highlight__ackend-config=\"prefix=prefix-hoge\"\n```\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "June 10, 2021",
          "title": "TOCを抽出するためのブックマークレット",
          "slug": "/entries/toc_bookmarklet/",
          "rawMarkdownBody": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + body + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(msg)%20=>%20{%20console.log(msg)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(body)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
          "timeToRead": 1,
          "objectID": "72256919-995e-5a10-884d-8ed2a363da52",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (__ais-highlight__b__/ais-highlight__ody) => {\n    const d = window.open().document;\n    d.writeln('TOC' + __ais-highlight__b__/ais-highlight__ody + '');\n    d.close();\n  };\n\n  const toc = Array",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "June 10, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "TOCを抽出するためのブックマークレット",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/toc___ais-highlight__b__/ais-highlight__ookmarklet/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (__ais-highlight__b__/ais-highlight__ody) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + __ais-highlight__b__/ais-highlight__ody + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(msg)%20=>%20{%20console.log(msg)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(__ais-highlight__b__/ais-highlight__ody)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 23, 2021",
          "title": "Rubyで進捗表示のスクリプトを書くとき",
          "slug": "/entries/ruby_progress_bar/ruby_progress_bar/",
          "rawMarkdownBody": "\n```ruby\n(1..100).each { |n| print \"#{'#' * n}#{'-' * (100 - n)} #{n}% \\r\"; sleep 1}\n```\n\n書き捨てスクリプトなどで進捗を表示させたいときなど`\\r`を末尾に付けることで再描画できるので進捗が進んでいるような見え方をさせられる\n\n![alt](ruby_progress_bar01.gif)\n",
          "timeToRead": 1,
          "objectID": "2631f8bc-7df7-5e04-be79-7572e72a2ddd",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "できるので進捗が進んでいるような見え方をさせられる\n\n![alt](ruby_progress___ais-highlight__b__/ais-highlight__ar01.gif)\n",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 23, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Rubyで進捗表示のスクリプトを書くとき",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ruby_progress___ais-highlight__b__/ais-highlight__ar/ruby_progress___ais-highlight__b__/ais-highlight__ar/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n```ruby\n(1..100).each { |n| print \"#{'#' * n}#{'-' * (100 - n)} #{n}% \\r\"; sleep 1}\n```\n\n書き捨てスクリプトなどで進捗を表示させたいときなど`\\r`を末尾に付けることで再描画できるので進捗が進んでいるような見え方をさせられる\n\n![alt](ruby_progress___ais-highlight__b__/ais-highlight__ar01.gif)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 18, 2020",
          "title": "S3利用料をバケット毎に詳細に出すための情報",
          "slug": "/entries/s3_price_per_bucket/",
          "rawMarkdownBody": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/billing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
          "timeToRead": 2,
          "objectID": "3c9d8e94-ccb4-5473-83bf-8e8f5a0204bd",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ーネット -> `DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - リージョン間 -> `AWS-Out-__ais-highlight__B__/ais-highlight__ytes`,`C3DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - `S3G-DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`はリージョン間",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 18, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "S3利用料をバケット毎に詳細に出すための情報",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/s3_price_per___ais-highlight__b__/ais-highlight__ucket/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__b__/ais-highlight__illing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-__ais-highlight__B__/ais-highlight__yteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - リージョン間 -> `AWS-Out-__ais-highlight__B__/ais-highlight__ytes`,`C3DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - `S3G-DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-__ais-highlight__B__/ais-highlight__ytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/__ais-highlight__B__/ais-highlight__ucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "September 25, 2021",
          "title": "GitHubのコントリビュート一覧に飛ぶためのブックマークレット",
          "slug": "/entries/github_contribute_bookmarklet/",
          "rawMarkdownBody": "\n以前Twitterで`採用などでGitHubアカウントもらったらこのクエリでコントリビューションみますね`みたいなのを見かけた\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\nとりあえずそのうち見るときのためにタブをそのままにしていたが、いろいろな人のも見られるとおもしろいかもと思ってブックマークレットを書いた\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->\n\nユーザーページもしくは対象ユーザーのどこかのリポジトリなど、ユーザー名がURLに存在すれば実行可能\n\n- github_contribute.js\n\n```javascript\n(function(){\n  const user = window.location.href.split(\"/\")[3];\n  const excludeOrgs = [];\n  const w = window.open();\n  const excludeOrgQuery = excludeOrgs.map(o => `-org%3A${o}`).join('+');\n  w.location.href = `https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;\n})()\n```\n\n- ブックマークバーへの貼り付け用出力\n\n```shell\n$ cat github_contribute.js |  sed -e ':loop;N;$!b loop;s/\\n/ /g' -e 's/ \\+/%20/g' -e 's/^/javascript:/'\njavascript:(function(){%20const%20user%20=%20window.location.href.split(\"/\")[3];%20const%20excludeOrgs%20=%20[];%20const%20w%20=%20window.open();%20const%20excludeOrgQuery%20=%20excludeOrgs.map(o%20=>%20`-org%3A${o}`).join('+');%20w.location.href%20=%20`https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;%20})()\n```\n\n`excludeOrgs`は自分が所属している組織へのPRやissueは除外するための記述\n\nGitHubで仕事の開発している場合は対象組織のPRなども表示されてしまうのでその除外\n\n感想としては自分はあんまりコントリビュートできてません!ということがわかりました。まる。\n",
          "timeToRead": 1,
          "objectID": "fb6ffa09-87e0-5cfc-a9fa-8886cfcd6da5",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "け用出力\n\n```shell\n$ cat github_contribute.js |  sed -e ':loop;N;$!__ais-highlight__b__/ais-highlight__ loop;s/\\n/ /g' -e 's/ \\+/%20/g' -e 's/^/javascript:/'\njavascript:(function(){%20const",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "September 25, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "GitHubのコントリビュート一覧に飛ぶためのブックマークレット",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/github_contribute___ais-highlight__b__/ais-highlight__ookmarklet/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n以前Twitterで`採用などでGitHubアカウントもらったらこのクエリでコントリビューションみますね`みたいなのを見かけた\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\nとりあえずそのうち見るときのためにタブをそのままにしていたが、いろいろな人のも見られるとおもしろいかもと思ってブックマークレットを書いた\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->\n\nユーザーページもしくは対象ユーザーのどこかのリポジトリなど、ユーザー名がURLに存在すれば実行可能\n\n- github_contribute.js\n\n```javascript\n(function(){\n  const user = window.location.href.split(\"/\")[3];\n  const excludeOrgs = [];\n  const w = window.open();\n  const excludeOrgQuery = excludeOrgs.map(o => `-org%3A${o}`).join('+');\n  w.location.href = `https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;\n})()\n```\n\n- ブックマークバーへの貼り付け用出力\n\n```shell\n$ cat github_contribute.js |  sed -e ':loop;N;$!__ais-highlight__b__/ais-highlight__ loop;s/\\n/ /g' -e 's/ \\+/%20/g' -e 's/^/javascript:/'\njavascript:(function(){%20const%20user%20=%20window.location.href.split(\"/\")[3];%20const%20excludeOrgs%20=%20[];%20const%20w%20=%20window.open();%20const%20excludeOrgQuery%20=%20excludeOrgs.map(o%20=>%20`-org%3A${o}`).join('+');%20w.location.href%20=%20`https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;%20})()\n```\n\n`excludeOrgs`は自分が所属している組織へのPRやissueは除外するための記述\n\nGitHubで仕事の開発している場合は対象組織のPRなども表示されてしまうのでその除外\n\n感想としては自分はあんまりコントリビュートできてません!ということがわかりました。まる。\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 26, 2021",
          "title": "VagrantのVMが立ち上がらなくなってしまったときの対処方いくつか",
          "slug": "/entries/vagrant_boot_failed/",
          "rawMarkdownBody": "\nホスト機がフリーズしてしまったとかVMを正常に終了させられないまま再起動してしまったときなど\n\nごくたまにVagrantで使っているVMが起動しなくなる\n\nいくつか試してみたのでその記録\n\n本記事では`dev4`というVM名で進める\n\n```shell\n$ vagrant up\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Checking if box 'bento/centos-7.4' version '201803.24.0' is up to date...\n==> default: Clearing any previously set forwarded ports...\nThere was an error while executing `VBoxManage`, a CLI used by Vagrant\nfor controlling VirtualBox. The command and stderr is shown below.\n\nCommand: [\"modifyvm\", \"d4c26ea5-e507-4049-878a-2c89a841f9e6\", \"--natpf1\", \"delete\", \"127.0.0.1tcp22396\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9200\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9300\", \"--natpf1\", \"delete\", \"ssh\"]\n\nStderr: VBoxManage.exe: error: The machine 'dev4' is already locked for a session (or being unlocked)\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_OBJECT_STATE (0x80bb0007), component MachineWrap, interface IMachine, callee IUnknown\nVBoxManage.exe: error: Context: \"LockMachine(a->session, LockType_Write)\" at line 554 of file VBoxManageModifyVM.cpp\n```\n\nlockされてます\n\nいくつか調べたら`poweroff`にすればよいとあったので実行してみる\n\n```shell\n$ cd /c/Program\\ Files/Oracle/VirtualBox\n$ ./VBoxManage.exe controlvm dev4 poweroff\nVBoxManage.exe: error: The virtual machine is being powered down\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_VM_STATE (0x80bb0002), component ConsoleWrap, interface IConsole, callee IUnknown\nVBoxManage.exe: error: Context: \"PowerDown(progress.asOutParam())\" at line 619 of file VBoxManageControlVM.cpp\n```\n\nもう止まっているよということのよう\n\n```\n$ vagrant status\nCurrent machine states:\n\ndefault                   stopping (virtualbox)\n\nThe VM is stopping.\n```\n\n- 参考\n\n[VirtualBoxで仮想コンピュータが反応しなくなった時( = _ = )](https://qiita.com/Ikumi/items/557808a232a0c12d3027)\n\nを参考に強制的に落とす\n\n```shell\n ./VBoxManage.exe startvm dev4 --type emergencystop\n```\n\nabortedになった\n\n```shell\n$ vagrant status\nCurrent machine states:\n\ndefault                   aborted (virtualbox)\n\nThe VM is in an aborted state. This means that it was abruptly\nstopped without properly closing the session. Run `vagrant up`\nto resume this virtual machine. If any problems persist, you may\nhave to destroy and restart the virtual machine.\n```\n\nここから`vagrant up`して無事立ち上げることができた\n\n\n```\n$ vagrant up\n.....\n.....\n.....\nTimed out while waiting for the machine to boot. This means that\nVagrant was unable to communicate with the guest machine within\nthe configured (\"config.vm.boot_timeout\" value) time period.\n\nIf you look above, you should be able to see the error(s) that\nVagrant had when attempting to connect to the machine. These errors\nare usually good hints as to what may be wrong.\n\nIf you're using a custom box, make sure that networking is properly\nworking and you're able to connect to the machine. It is a common\nproblem that networking isn't setup properly in these boxes.\nVerify that authentication configurations are also setup properly,\nas well.\n\nIf the box appears to be booting properly, you may want to increase\nthe timeout (\"config.vm.boot_timeout\") value.\n```\n\nが、立ち上がったは良いがsshできないという感じになってしまった\n\nVirtualBoxからものぞいてみようと試みたがVMが完全に立ち上がらない状態で操作できず\n\n結局ホストのWindowsを完全シャットダウン（shift+シャットダウン）&起動してVM起動したら動くようになっていた\n\nただの徒労…\n",
          "timeToRead": 3,
          "objectID": "472ccc60-931d-5077-bfd7-c2d4388530aa",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "in these __ais-highlight__b__/ais-highlight__oxes.\nVerify that authentication configurations are also setup properly,\nas well.\n\nIf the __ais-highlight__b__/ais-highlight__ox appears to __ais-highlight__b__/ais-highlight__e __ais-highlight__b__/ais-highlight__ooting properly, you may want to increase\nthe timeout (\"config.vm",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 26, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VagrantのVMが立ち上がらなくなってしまったときの対処方いくつか",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vagrant___ais-highlight__b__/ais-highlight__oot_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nホスト機がフリーズしてしまったとかVMを正常に終了させられないまま再起動してしまったときなど\n\nごくたまにVagrantで使っているVMが起動しなくなる\n\nいくつか試してみたのでその記録\n\n本記事では`dev4`というVM名で進める\n\n```shell\n$ vagrant up\n__ais-highlight__B__/ais-highlight__ringing machine 'default' up with 'virtualbox' provider...\n==> default: Checking if __ais-highlight__b__/ais-highlight__ox '__ais-highlight__b__/ais-highlight__ento/centos-7.4' version '201803.24.0' is up to date...\n==> default: Clearing any previously set forwarded ports...\nThere was an error while executing `VBoxManage`, a CLI used __ais-highlight__b__/ais-highlight__y Vagrant\nfor controlling VirtualBox. The command and stderr is shown __ais-highlight__b__/ais-highlight__elow.\n\nCommand: [\"modifyvm\", \"d4c26ea5-e507-4049-878a-2c89a841f9e6\", \"--natpf1\", \"delete\", \"127.0.0.1tcp22396\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9200\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9300\", \"--natpf1\", \"delete\", \"ssh\"]\n\nStderr: VBoxManage.exe: error: The machine 'dev4' is already locked for a session (or __ais-highlight__b__/ais-highlight__eing unlocked)\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_OBJECT_STATE (0x80bb0007), component MachineWrap, interface IMachine, callee IUnknown\nVBoxManage.exe: error: Context: \"LockMachine(a->session, LockType_Write)\" at line 554 of file VBoxManageModifyVM.cpp\n```\n\nlockされてます\n\nいくつか調べたら`poweroff`にすればよいとあったので実行してみる\n\n```shell\n$ cd /c/Program\\ Files/Oracle/VirtualBox\n$ ./VBoxManage.exe controlvm dev4 poweroff\nVBoxManage.exe: error: The virtual machine is __ais-highlight__b__/ais-highlight__eing powered down\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_VM_STATE (0x80bb0002), component ConsoleWrap, interface IConsole, callee IUnknown\nVBoxManage.exe: error: Context: \"PowerDown(progress.asOutParam())\" at line 619 of file VBoxManageControlVM.cpp\n```\n\nもう止まっているよということのよう\n\n```\n$ vagrant status\nCurrent machine states:\n\ndefault                   stopping (virtualbox)\n\nThe VM is stopping.\n```\n\n- 参考\n\n[VirtualBoxで仮想コンピュータが反応しなくなった時( = _ = )](https://qiita.com/Ikumi/items/557808a232a0c12d3027)\n\nを参考に強制的に落とす\n\n```shell\n ./VBoxManage.exe startvm dev4 --type emergencystop\n```\n\nabortedになった\n\n```shell\n$ vagrant status\nCurrent machine states:\n\ndefault                   aborted (virtualbox)\n\nThe VM is in an aborted state. This means that it was abruptly\nstopped without properly closing the session. Run `vagrant up`\nto resume this virtual machine. If any problems persist, you may\nhave to destroy and restart the virtual machine.\n```\n\nここから`vagrant up`して無事立ち上げることができた\n\n\n```\n$ vagrant up\n.....\n.....\n.....\nTimed out while waiting for the machine to __ais-highlight__b__/ais-highlight__oot. This means that\nVagrant was unable to communicate with the guest machine within\nthe configured (\"config.vm.__ais-highlight__b__/ais-highlight__oot_timeout\" value) time period.\n\nIf you look above, you should __ais-highlight__b__/ais-highlight__e able to see the error(s) that\nVagrant had when attempting to connect to the machine. These errors\nare usually good hints as to what may __ais-highlight__b__/ais-highlight__e wrong.\n\nIf you're using a custom __ais-highlight__b__/ais-highlight__ox, make sure that networking is properly\nworking and you're able to connect to the machine. It is a common\nproblem that networking isn't setup properly in these __ais-highlight__b__/ais-highlight__oxes.\nVerify that authentication configurations are also setup properly,\nas well.\n\nIf the __ais-highlight__b__/ais-highlight__ox appears to __ais-highlight__b__/ais-highlight__e __ais-highlight__b__/ais-highlight__ooting properly, you may want to increase\nthe timeout (\"config.vm.__ais-highlight__b__/ais-highlight__oot_timeout\") value.\n```\n\nが、立ち上がったは良いがsshできないという感じになってしまった\n\nVirtualBoxからものぞいてみようと試みたがVMが完全に立ち上がらない状態で操作できず\n\n結局ホストのWindowsを完全シャットダウン（shift+シャットダウン）&起動してVM起動したら動くようになっていた\n\nただの徒労…\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "October 23, 2020",
          "title": "特定の容量のダミーファイルを生成する",
          "slug": "/entries/dd/",
          "rawMarkdownBody": "\n```shell\n$ dd if=/dev/zero of=1K_M.out bs=1K count=1\n1+0 records in\n1+0 records out\n1024 bytes (1.0 kB) copied, 0.000412943 s, 2.5 MB/s\n```\n\n```\n$ ls -al 1K_M.out\n-rw-rw-r-- 1 vagrant vagrant 1024 Oct 24 04:46 1K_M.out\n```\n\nディスク的には4KBで固定のよう\n\n```\n$ du -sh 1K_M.out\n4.0K    1K_M.out\n```\n\n`1K_M.out`というファイル名にnull文字で埋める、1KBで1ファイル作成する\n\n容量によって確認したいことが変わる場合など容量を合わせていくの意外と面倒だったりするのでそういうときに使える\n",
          "timeToRead": 1,
          "objectID": "aa24d6f2-a7ed-50f3-afa3-5e13f53f523f",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n```shell\n$ dd if=/dev/zero of=1K_M.out __ais-highlight__b__/ais-highlight__s=1K count=1\n1+0 records in\n1+0 records out\n1024 __ais-highlight__b__/ais-highlight__ytes (1.0 kB) copied, 0",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "October 23, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "特定の容量のダミーファイルを生成する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/dd/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n```shell\n$ dd if=/dev/zero of=1K_M.out __ais-highlight__b__/ais-highlight__s=1K count=1\n1+0 records in\n1+0 records out\n1024 __ais-highlight__b__/ais-highlight__ytes (1.0 kB) copied, 0.000412943 s, 2.5 MB/s\n```\n\n```\n$ ls -al 1K_M.out\n-rw-rw-r-- 1 vagrant vagrant 1024 Oct 24 04:46 1K_M.out\n```\n\nディスク的には4KBで固定のよう\n\n```\n$ du -sh 1K_M.out\n4.0K    1K_M.out\n```\n\n`1K_M.out`というファイル名にnull文字で埋める、1KBで1ファイル作成する\n\n容量によって確認したいことが変わる場合など容量を合わせていくの意外と面倒だったりするのでそういうときに使える\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 84,
      "page": 0,
      "nbPages": 5,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "query": "B",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&query=B&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 11
    },
    {
      "hits": [
        {
          "date": "March 25, 2022",
          "title": "BigQueryの日付を扱う際のメモ",
          "slug": "/entries/bigquery_date_function/",
          "rawMarkdownBody": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
          "timeToRead": 1,
          "objectID": "68f46908-591f-5bb4-82bd-f2fc099406d2",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "March 25, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryの日付を扱う際のメモ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 08, 2021",
          "title": "BigQueryのbq load時にautodetectを使えない場合",
          "slug": "/entries/bigquery_cant_use_autodetect/",
          "rawMarkdownBody": "\nPocketのデータをAPIで取得してBigQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\nBigQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/bigquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、BigQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。BigQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
          "timeToRead": 3,
          "objectID": "511a0a9b-6cec-55d0-a965-148667fcf789",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "タは次の3つ（__ais-highlight__b__/ais-highlight__ucket名はサンプル）\n\n```\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 08, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryの__ais-highlight__b__/ais-highlight__q load時にautodetectを使えない場合",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__B__/ais-highlight__igQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`__ais-highlight__b__/ais-highlight__q load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\n__ais-highlight__B__/ais-highlight__igQuery error in load operation: Error processing job\n'project-111111:__ais-highlight__b__/ais-highlight__qjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\n__ais-highlight__b__/ais-highlight__ad: 0; error percent: 0\n- gs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（__ais-highlight__b__/ais-highlight__ucket名はサンプル）\n\n```\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/__ais-highlight__b__/ais-highlight__igquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、__ais-highlight__B__/ais-highlight__igQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。__ais-highlight__B__/ais-highlight__igQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\n__ais-highlight__b__/ais-highlight__q show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\n__ais-highlight__b__/ais-highlight__q mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\n__ais-highlight__b__/ais-highlight__q load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-__ais-highlight__b__/ais-highlight__ucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`__ais-highlight__b__/ais-highlight__q load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "December 09, 2020",
          "title": "BigQueryでサンプルデータをサクッと作る",
          "slug": "/entries/bigquery_sample_data/",
          "rawMarkdownBody": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
          "timeToRead": 1,
          "objectID": "28192504-51b0-5f94-9f12-c62f278c23cc",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "December 09, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryでサンプルデータをサクッと作る",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 21, 2021",
          "title": "BigQueryで日付を扱うときはTimezoneを意識する",
          "slug": "/entries/bigquery_date_timezone/",
          "rawMarkdownBody": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\nBigQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
          "timeToRead": 1,
          "objectID": "1d531f2a-2c16-5859-96ce-a8cf37a230b8",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "SELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) __ais-highlight__B__/ais-highlight__ETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXな",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 21, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__B__/ais-highlight__igQueryで日付を扱うときはTimezoneを意識する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__igquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) __ais-highlight__B__/ais-highlight__ETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__B__/ais-highlight__igQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 25, 2021",
          "title": "gcloud buildsでログが見れない時",
          "slug": "/entries/gcloud_project_iam/",
          "rawMarkdownBody": "\nCloudRunでCDやろうと思ったらつまずいた\n\nサービスアカウントにコンテナのイメージをビルドさせたいときの話\n\n```\n$ gcloud builds submit --tag gcr.io/${project-id}/${name}\nCheck the gcloud log [/home/circleci/.config/gcloud/logs/2020.12.10/18.23.37.852071.log] to see which files and the contents of the default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn                                                                           more).\n.....\n.....\n.....\nERROR: (gcloud.builds.submit) HTTPError 403: <?xml version='1.0' encoding='UTF-8'?><Error><Code>AccessDenied</Code><Message>Access denied.</Message><Details>name-run-invoker@project-id.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.</Details></Error>\n```\n\nサービスアカウントには`storage.objects.get`は付いているのに…\n\n[ビルド結果の表示  |  Cloud Build のドキュメント  |  Google Cloud](https://cloud.google.com/cloud-build/docs/view-build-results#gcloud)\n\n特にログのバケットを指定してないため、ログを表示するにはプロジェクト＞閲覧者の権限も必要なよう\n\nいわゆる`roles/viewer`\n\n## projectの閲覧者権限の追加\n\n[個人的によく使うgcloudコマンドまとめ ~ IAM・サービスアカウント関連 ~](https://qiita.com/rodotan/items/9a97dbffd8cd0bbd3ae9)\n\n```shell\ngcloud projects add-iam-policy-binding ${project-id} --member=serviceAccount:${name}-run-invoker@${project-id}.iam.gserviceaccount.com --role=roles/viewer\n```\n\nこれで解決した\n\nなんとなくプロジェクトにまつわる権限の話がわかってきた気がするがはっきり説明できるほどにはなっていない…",
          "timeToRead": 1,
          "objectID": "67875ce1-4ae7-5251-9b9a-4e147102d386",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "__ais-highlight__B__/ais-highlight__uild のドキュメント  |  Google Cloud](https://cloud.google.com/cloud-__ais-highlight__b__/ais-highlight__uild/docs/view-__ais-highlight__b__/ais-highlight__uild-results#gcloud)\n\n特にログのバケット",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 25, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "gcloud __ais-highlight__b__/ais-highlight__uildsでログが見れない時",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/gcloud_project_iam/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nCloudRunでCDやろうと思ったらつまずいた\n\nサービスアカウントにコンテナのイメージをビルドさせたいときの話\n\n```\n$ gcloud __ais-highlight__b__/ais-highlight__uilds submit --tag gcr.io/${project-id}/${name}\nCheck the gcloud log [/home/circleci/.config/gcloud/logs/2020.12.10/18.23.37.852071.log] to see which files and the contents of the default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn                                                                           more).\n.....\n.....\n.....\nERROR: (gcloud.__ais-highlight__b__/ais-highlight__uilds.submit) HTTPError 403: <?xml version='1.0' encoding='UTF-8'?><Error><Code>AccessDenied</Code><Message>Access denied.</Message><Details>name-run-invoker@project-id.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object.</Details></Error>\n```\n\nサービスアカウントには`storage.objects.get`は付いているのに…\n\n[ビルド結果の表示  |  Cloud __ais-highlight__B__/ais-highlight__uild のドキュメント  |  Google Cloud](https://cloud.google.com/cloud-__ais-highlight__b__/ais-highlight__uild/docs/view-__ais-highlight__b__/ais-highlight__uild-results#gcloud)\n\n特にログのバケットを指定してないため、ログを表示するにはプロジェクト＞閲覧者の権限も必要なよう\n\nいわゆる`roles/viewer`\n\n## projectの閲覧者権限の追加\n\n[個人的によく使うgcloudコマンドまとめ ~ IAM・サービスアカウント関連 ~](https://qiita.com/rodotan/items/9a97dbffd8cd0bbd3ae9)\n\n```shell\ngcloud projects add-iam-policy-__ais-highlight__b__/ais-highlight__inding ${project-id} --member=serviceAccount:${name}-run-invoker@${project-id}.iam.gserviceaccount.com --role=roles/viewer\n```\n\nこれで解決した\n\nなんとなくプロジェクトにまつわる権限の話がわかってきた気がするがはっきり説明できるほどにはなっていない…",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 21, 2022",
          "title": "GitHub Projects(beta)のデータを収集する",
          "slug": "/entries/github_projects_data_from_graphql/",
          "rawMarkdownBody": "\nGitHubのProjects（Beta）を使って自動化や集計をするなどしたい場合のメモ\n\nAPIの基本的な使い方に関しては下記を参照し、1つずつ実行していけばイメージはつかめる\n\n[APIを使ったプロジェクト（ベータ）の管理 - GitHub Docs](https://docs.github.com/ja/issues/trying-out-the-new-projects-experience/using-the-api-to-manage-projects)\n\n事前にProjectのIDだけ取得しメモしておく\n\n次のクエリ一発でだいたい必要なデータは取れそう\n\n```graphql\nquery ($project_id: ID!) {\n  node(id: $project_id) {\n    ... on ProjectNext {\n      items(first: 100) {\n        nodes {\n          title\n          createdAt\n          fieldValues(first: 8) {\n            nodes {\n              value\n              createdAt\n              projectField {\n                name\n                settings\n              }\n            }\n          }\n          content {\n            ... on Issue {\n              id\n              number\n              url\n              repository {\n                name\n              }\n              milestone {\n                id\n                title\n              }\n              createdAt\n              closed\n              closedAt\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n            }\n            ... on PullRequest {\n              id\n              number\n              url\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n              repository {\n                name\n              }\n              createdAt\n              closed\n              closedAt\n              merged\n              mergedAt\n              reviewRequests(first: 10) {\n                nodes {\n                  requestedReviewer {\n                    ... on User {\n                      name\n                    }\n                  }\n                }\n              }\n            }\n          }\n          id\n          updatedAt\n        }\n      }\n    }\n  }\n}\n```\n\nproject_idは事前にメモしておいた値\n\nどのカラムが必要かなどは下記で`Explorer`を展開して1つずつ見ていけば把握できる\n\n[Explorer - GitHub Docs](https://docs.github.com/ja/graphql/overview/explorer)\n\nExplorerのiframeの範囲が狭くて見づらいのがちょっと不満ではあるがそれ以外は便利に使える\n\nカードに紐づくIssueやPullRequestなどの情報も取ってこれるのでフラットにして集計する前のデータとして使える\n\nとりあえずプロジェクトのデータ使って云々やりたい場合はこのくらいデータが有れば十分かなと感じる\n\n- 結果（一部抜粋）\n\n```json\n{\n  \"data\": {\n    \"node\": {\n      \"items\": {\n        \"nodes\": [\n          {\n            \"title\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n            \"id\": \"PNI_xxxxxxxxxxxxxxxxxxxx\",\n            \"updatedAt\": \"2022-01-19T06:12:59Z\",\n            \"fieldValues\": {\n              \"nodes\": [\n                {\n                  \"value\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n                  \"projectField\": {\n                    \"name\": \"Title\",\n                    \"settings\": \"{\\\"width\\\":319}\"\n                  }\n                },\n                {\n                  \"value\": \"98236657\",\n                  \"projectField\": {\n                    \"name\": \"Status\",\n                    \"settings\": \"{\\\"width\\\":125,\\\"options\\\":[{\\\"id\\\":\\\"xxxxxxx1\\\",\\\"name\\\":\\\"New\\\",\\\"name_html\\\":\\\"New\\\"},{\\\"id\\\":\\\"xxxxxxx2\\\",\\\"name\\\":\\\"Epic\\\",\\\"name_html\\\":\\\"Epic\\\"},{\\\"id\\\":\\\"xxxxxxx3\\\",\\\"name\\\":\\\"Idea\\\",\\\"name_html\\\":\\\"Idea\\\"},{\\\"id\\\":\\\"xxxxxxx4\\\",\\\"name\\\":\\\"Todo\\\",\\\"name_html\\\":\\\"Todo\\\"},{\\\"id\\\":\\\"xxxxxxx5\\\",\\\"name\\\":\\\"In Progress\\\",\\\"name_html\\\":\\\"In Progress\\\"},{\\\"id\\\":\\\"xxxxxxx6\\\",\\\"name\\\":\\\"Review\\\",\\\"name_html\\\":\\\"Review\\\"},{\\\"id\\\":\\\"xxxxxxx7\\\",\\\"name\\\":\\\"Done\\\",\\\"name_html\\\":\\\"Done\\\"}]}\"\n                  }\n                },\n                {\n                  \"value\": \"2\",\n                  \"projectField\": {\n                    \"name\": \"Point\",\n                    \"settings\": \"{\\\"width\\\":69}\"\n                  }\n                },\n                {\n                  \"value\": \"2022-01-01T00:00:00+00:00\",\n                  \"projectField\": {\n                    \"name\": \"Month\",\n                    \"settings\": \"null\"\n                  }\n                },\n                {\n                  \"value\": \"e9bbecfa\",\n                  \"projectField\": {\n                    \"name\": \"Iteration\",\n                    \"settings\": \"{\\\"configuration\\\":{\\\"duration\\\":14,\\\"start_day\\\":1,\\\"iterations\\\":[{\\\"id\\\":\\\"xxxxxxa\\\",\\\"title\\\":\\\"2022-01_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-17\\\",\\\"title_html\\\":\\\"2022-01_2\\\"},{\\\"id\\\":\\\"xxxxxxb\\\",\\\"title\\\":\\\"2022-02_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-31\\\",\\\"title_html\\\":\\\"2022-02_1\\\"},{\\\"id\\\":\\\"xxxxxxc\\\",\\\"title\\\":\\\"2022-02_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-02-14\\\",\\\"title_html\\\":\\\"2022-02_2\\\"}],\\\"completed_iterations\\\":[{\\\"id\\\":\\\"xxxxxxd\\\",\\\"title\\\":\\\"2022-01_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-03\\\",\\\"title_html\\\":\\\"2022-01_1\\\"},{\\\"id\\\":\\\"xxxxxxe\\\",\\\"title\\\":\\\"Iteration 1\\\",\\\"duration\\\":7,\\\"start_date\\\":\\\"2021-12-27\\\",\\\"title_html\\\":\\\"Iteration 1\\\"}]}}\"\n                  }\n                }\n              ]\n            },\n            \"content\": {\n              \"id\": \"I_xxxxxxxxxxxxxxxx\",\n              \"number\": 56,\n              \"url\": \"https://github.com/swfz/tools/issues/56\",\n              \"closed\": true,\n              \"closedAt\": \"2022-01-20T16:27:38Z\",\n              \"createdAt\": \"2022-01-19T06:12:59Z\",\n              \"repository\": {\n                \"name\": \"tools\"\n              },\n              \"milestone\": null,\n              \"assignees\": {\n                \"nodes\": [\n                  {\n                    \"name\": \"swfz\"\n                  }\n                ]\n              }\n            }\n          },\n          .....\n          .....\n          .....\n          .....\n```\n\nまた、実際にこのデータを用いて何かやるなら100件以上のデータが存在することのほうが多いはずなのでページングにも対応したクエリにする必要があるが今回はここまで\n",
          "timeToRead": 3,
          "objectID": "c5f74971-5cdb-55f9-ab0e-c99b41357a69",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nGitHubのProjects（__ais-highlight__B__/ais-highlight__eta）を使って自動化や集計をするなどしたい場合のメモ\n\nAPIの",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 21, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "GitHub Projects(__ais-highlight__b__/ais-highlight__eta)のデータを収集する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/github_projects_data_from_graphql/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nGitHubのProjects（__ais-highlight__B__/ais-highlight__eta）を使って自動化や集計をするなどしたい場合のメモ\n\nAPIの基本的な使い方に関しては下記を参照し、1つずつ実行していけばイメージはつかめる\n\n[APIを使ったプロジェクト（ベータ）の管理 - GitHub Docs](https://docs.github.com/ja/issues/trying-out-the-new-projects-experience/using-the-api-to-manage-projects)\n\n事前にProjectのIDだけ取得しメモしておく\n\n次のクエリ一発でだいたい必要なデータは取れそう\n\n```graphql\nquery ($project_id: ID!) {\n  node(id: $project_id) {\n    ... on ProjectNext {\n      items(first: 100) {\n        nodes {\n          title\n          createdAt\n          fieldValues(first: 8) {\n            nodes {\n              value\n              createdAt\n              projectField {\n                name\n                settings\n              }\n            }\n          }\n          content {\n            ... on Issue {\n              id\n              number\n              url\n              repository {\n                name\n              }\n              milestone {\n                id\n                title\n              }\n              createdAt\n              closed\n              closedAt\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n            }\n            ... on PullRequest {\n              id\n              number\n              url\n              assignees(first: 5) {\n                nodes {\n                  name\n                }\n              }\n              repository {\n                name\n              }\n              createdAt\n              closed\n              closedAt\n              merged\n              mergedAt\n              reviewRequests(first: 10) {\n                nodes {\n                  requestedReviewer {\n                    ... on User {\n                      name\n                    }\n                  }\n                }\n              }\n            }\n          }\n          id\n          updatedAt\n        }\n      }\n    }\n  }\n}\n```\n\nproject_idは事前にメモしておいた値\n\nどのカラムが必要かなどは下記で`Explorer`を展開して1つずつ見ていけば把握できる\n\n[Explorer - GitHub Docs](https://docs.github.com/ja/graphql/overview/explorer)\n\nExplorerのiframeの範囲が狭くて見づらいのがちょっと不満ではあるがそれ以外は便利に使える\n\nカードに紐づくIssueやPullRequestなどの情報も取ってこれるのでフラットにして集計する前のデータとして使える\n\nとりあえずプロジェクトのデータ使って云々やりたい場合はこのくらいデータが有れば十分かなと感じる\n\n- 結果（一部抜粋）\n\n```json\n{\n  \"data\": {\n    \"node\": {\n      \"items\": {\n        \"nodes\": [\n          {\n            \"title\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n            \"id\": \"PNI_xxxxxxxxxxxxxxxxxxxx\",\n            \"updatedAt\": \"2022-01-19T06:12:59Z\",\n            \"fieldValues\": {\n              \"nodes\": [\n                {\n                  \"value\": \"timerの時刻がブラウザの負荷状況によってずれる\",\n                  \"projectField\": {\n                    \"name\": \"Title\",\n                    \"settings\": \"{\\\"width\\\":319}\"\n                  }\n                },\n                {\n                  \"value\": \"98236657\",\n                  \"projectField\": {\n                    \"name\": \"Status\",\n                    \"settings\": \"{\\\"width\\\":125,\\\"options\\\":[{\\\"id\\\":\\\"xxxxxxx1\\\",\\\"name\\\":\\\"New\\\",\\\"name_html\\\":\\\"New\\\"},{\\\"id\\\":\\\"xxxxxxx2\\\",\\\"name\\\":\\\"Epic\\\",\\\"name_html\\\":\\\"Epic\\\"},{\\\"id\\\":\\\"xxxxxxx3\\\",\\\"name\\\":\\\"Idea\\\",\\\"name_html\\\":\\\"Idea\\\"},{\\\"id\\\":\\\"xxxxxxx4\\\",\\\"name\\\":\\\"Todo\\\",\\\"name_html\\\":\\\"Todo\\\"},{\\\"id\\\":\\\"xxxxxxx5\\\",\\\"name\\\":\\\"In Progress\\\",\\\"name_html\\\":\\\"In Progress\\\"},{\\\"id\\\":\\\"xxxxxxx6\\\",\\\"name\\\":\\\"Review\\\",\\\"name_html\\\":\\\"Review\\\"},{\\\"id\\\":\\\"xxxxxxx7\\\",\\\"name\\\":\\\"Done\\\",\\\"name_html\\\":\\\"Done\\\"}]}\"\n                  }\n                },\n                {\n                  \"value\": \"2\",\n                  \"projectField\": {\n                    \"name\": \"Point\",\n                    \"settings\": \"{\\\"width\\\":69}\"\n                  }\n                },\n                {\n                  \"value\": \"2022-01-01T00:00:00+00:00\",\n                  \"projectField\": {\n                    \"name\": \"Month\",\n                    \"settings\": \"null\"\n                  }\n                },\n                {\n                  \"value\": \"e9bbecfa\",\n                  \"projectField\": {\n                    \"name\": \"Iteration\",\n                    \"settings\": \"{\\\"configuration\\\":{\\\"duration\\\":14,\\\"start_day\\\":1,\\\"iterations\\\":[{\\\"id\\\":\\\"xxxxxxa\\\",\\\"title\\\":\\\"2022-01_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-17\\\",\\\"title_html\\\":\\\"2022-01_2\\\"},{\\\"id\\\":\\\"xxxxxxb\\\",\\\"title\\\":\\\"2022-02_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-31\\\",\\\"title_html\\\":\\\"2022-02_1\\\"},{\\\"id\\\":\\\"xxxxxxc\\\",\\\"title\\\":\\\"2022-02_2\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-02-14\\\",\\\"title_html\\\":\\\"2022-02_2\\\"}],\\\"completed_iterations\\\":[{\\\"id\\\":\\\"xxxxxxd\\\",\\\"title\\\":\\\"2022-01_1\\\",\\\"duration\\\":14,\\\"start_date\\\":\\\"2022-01-03\\\",\\\"title_html\\\":\\\"2022-01_1\\\"},{\\\"id\\\":\\\"xxxxxxe\\\",\\\"title\\\":\\\"Iteration 1\\\",\\\"duration\\\":7,\\\"start_date\\\":\\\"2021-12-27\\\",\\\"title_html\\\":\\\"Iteration 1\\\"}]}}\"\n                  }\n                }\n              ]\n            },\n            \"content\": {\n              \"id\": \"I_xxxxxxxxxxxxxxxx\",\n              \"number\": 56,\n              \"url\": \"https://github.com/swfz/tools/issues/56\",\n              \"closed\": true,\n              \"closedAt\": \"2022-01-20T16:27:38Z\",\n              \"createdAt\": \"2022-01-19T06:12:59Z\",\n              \"repository\": {\n                \"name\": \"tools\"\n              },\n              \"milestone\": null,\n              \"assignees\": {\n                \"nodes\": [\n                  {\n                    \"name\": \"swfz\"\n                  }\n                ]\n              }\n            }\n          },\n          .....\n          .....\n          .....\n          .....\n```\n\nまた、実際にこのデータを用いて何かやるなら100件以上のデータが存在することのほうが多いはずなのでページングにも対応したクエリにする必要があるが今回はここまで\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "June 22, 2021",
          "title": "node-fetchでBasicAuthする",
          "slug": "/entries/basic_auth_in_node_fetch/",
          "rawMarkdownBody": "\n## auth用の文字列の生成\n\n今どきは`new Buffer`ではないらしい\n\n次のようなWarningが出力される\n\n```\n(node:22161) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n```\n\nということで下記のように認証用の文字列を生成する\n\n```javascript\nconst buffer = Buffer.from(`username:token`);\nconst authString = buffer.toString('base64');\n```\n\n## リクエスト\n\n```javascript\nconst request = async () => {\n  const res = await fetch(`https://example.com`, {\n    method: 'GET',\n    headers: {\n      'Accept': 'application/json',\n      'Authorization': `Basic ${authString}`\n    }\n  });\n\n  return await res.json();\n}\n\n(async () => {\n  const json = request();\n  console.log(json);\n})();\n```\n\nheadersの`Authorization`にユーザー名とTOKENやパスワードを`:`でつなげbase64した文字列を入れる\n\nそれだけ",
          "timeToRead": 1,
          "objectID": "2b3a59a9-d2a1-5d40-b7f8-4da4b20870f4",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "22161) [DEP0005] DeprecationWarning: __ais-highlight__B__/ais-highlight__uffer() is deprecated due to security and usability issues. Please use the __ais-highlight__B__/ais-highlight__uffer.alloc(), __ais-highlight__B__/ais-highlight__uffer.allocUnsafe(), or __ais-highlight__B__/ais-highlight__uffer.from() methods instead.\n(Use `node --trace-deprecation ...` to show",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "June 22, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "node-fetchで__ais-highlight__B__/ais-highlight__asicAuthする",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__b__/ais-highlight__asic_auth_in_node_fetch/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n## auth用の文字列の生成\n\n今どきは`new __ais-highlight__B__/ais-highlight__uffer`ではないらしい\n\n次のようなWarningが出力される\n\n```\n(node:22161) [DEP0005] DeprecationWarning: __ais-highlight__B__/ais-highlight__uffer() is deprecated due to security and usability issues. Please use the __ais-highlight__B__/ais-highlight__uffer.alloc(), __ais-highlight__B__/ais-highlight__uffer.allocUnsafe(), or __ais-highlight__B__/ais-highlight__uffer.from() methods instead.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n```\n\nということで下記のように認証用の文字列を生成する\n\n```javascript\nconst __ais-highlight__b__/ais-highlight__uffer = __ais-highlight__B__/ais-highlight__uffer.from(`username:token`);\nconst authString = __ais-highlight__b__/ais-highlight__uffer.toString('__ais-highlight__b__/ais-highlight__ase64');\n```\n\n## リクエスト\n\n```javascript\nconst request = async () => {\n  const res = await fetch(`https://example.com`, {\n    method: 'GET',\n    headers: {\n      'Accept': 'application/json',\n      'Authorization': `__ais-highlight__B__/ais-highlight__asic ${authString}`\n    }\n  });\n\n  return await res.json();\n}\n\n(async () => {\n  const json = request();\n  console.log(json);\n})();\n```\n\nheadersの`Authorization`にユーザー名とTOKENやパスワードを`:`でつなげ__ais-highlight__b__/ais-highlight__ase64した文字列を入れる\n\nそれだけ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "December 12, 2020",
          "title": "curl: (3) [globbing] error: bad range specification after pos 3",
          "slug": "/entries/curl_with_grep_color/",
          "rawMarkdownBody": "\ntflintを入れてみようと思いREADMEにしたがいワンライナーで落としてこようと思ったら思わぬところでつまずいた\n\n```shell\n$ curl -L \"$(curl -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\")\" -o tflint.zip && unzip tflint.zip && rm tflint.zip\ncurl: (3) [globbing] error: bad range specification after pos 3\n```\n\nglob…どこかで`[]`や`{}`使っているか?という感じだったが`grep`が悪さをしていた\n\n自分のシェル環境だとデフォルトでgrepの結果に色をつけるようにしていたのでその結果に対して`curl`しようとすることでエスケープシーケンスも含まれてしまっていた\n\n```\n$ curl  -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\" > url.txt\n$ cat -v url.txt\n^[[01;31m^[[Khttps://github.com/terraform-linters/tflint/releases/download/v0.22.0/tflint_linux_amd64.zip^[[m^[[K\n```\n\nもともとURLに`[]`や`{}`が含まれているパターンではないのでこの場合の対応は`--globoff`ではだめだった\n\n`grep --color=no`を追加することでcurl対象のURLがプレーンなテキストになるのでcurlできるようになった\n\nエスケープシーケンスはよくやるので気を付けたい\n",
          "timeToRead": 1,
          "objectID": "cf55191e-5e3e-54f6-8964-be56698fe6ff",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "amd64.zip\")\" -o tflint.zip && unzip tflint.zip && rm tflint.zip\ncurl: (3) [globbing] error: __ais-highlight__b__/ais-highlight__ad range specification after pos 3\n```\n\nglob…どこかで`[]`や`{}`使って",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "December 12, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "curl: (3) [globbing] error: __ais-highlight__b__/ais-highlight__ad range specification after pos 3",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/curl_with_grep_color/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\ntflintを入れてみようと思いREADMEにしたがいワンライナーで落としてこようと思ったら思わぬところでつまずいた\n\n```shell\n$ curl -L \"$(curl -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\")\" -o tflint.zip && unzip tflint.zip && rm tflint.zip\ncurl: (3) [globbing] error: __ais-highlight__b__/ais-highlight__ad range specification after pos 3\n```\n\nglob…どこかで`[]`や`{}`使っているか?という感じだったが`grep`が悪さをしていた\n\n自分のシェル環境だとデフォルトでgrepの結果に色をつけるようにしていたのでその結果に対して`curl`しようとすることでエスケープシーケンスも含まれてしまっていた\n\n```\n$ curl  -Ls https://api.github.com/repos/terraform-linters/tflint/releases/latest | grep -o -E \"https://.+?_linux_amd64.zip\" > url.txt\n$ cat -v url.txt\n^[[01;31m^[[Khttps://github.com/terraform-linters/tflint/releases/download/v0.22.0/tflint_linux_amd64.zip^[[m^[[K\n```\n\nもともとURLに`[]`や`{}`が含まれているパターンではないのでこの場合の対応は`--globoff`ではだめだった\n\n`grep --color=no`を追加することでcurl対象のURLがプレーンなテキストになるのでcurlできるようになった\n\nエスケープシーケンスはよくやるので気を付けたい\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 28, 2022",
          "title": "JSONファイルをBigQueryに読ませJSON型で扱うためにそのままCSVで保存する",
          "slug": "/entries/json_to_csv/",
          "rawMarkdownBody": "\n[Working with JSON data in Standard SQL  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/json-data)\n\n先日BigQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
          "timeToRead": 1,
          "objectID": "6ed6b22c-63cc-5fb2-99d6-eeada5709406",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__B__/ais-highlight__igQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__b__/ais-highlight__igquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__B__/ais-highlight__igQueryでnative JSON型が",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 28, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "JSONファイルを__ais-highlight__B__/ais-highlight__igQueryに読ませJSON型で扱うためにそのままCSVで保存する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__B__/ais-highlight__igQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__b__/ais-highlight__igquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__B__/ais-highlight__igQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\n__ais-highlight__b__/ais-highlight__q load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "November 15, 2020",
          "title": "Error: React-Hot-Loader: AppContainer should be patched",
          "slug": "/entries/react_hot_loader_should_be_patched/",
          "rawMarkdownBody": "\n次のリンクとまったく同じ状態になった\n\n[Gatsby doesn't work with React 17 RC (Error: React-Hot-Loader: AppContainer should be patched) · Issue #26979 · gatsbyjs/gatsby](https://github.com/gatsbyjs/gatsby/issues/26979)\n\nhttps://github.com/gatsbyjs/gatsby/issues/26979#issuecomment-696702777\n\nのコメントにあるようにパッケージのバージョンを上げればOKのよう\n\n`react-hot-loader`自体はgatsbyの依存モジュールで`package.json`には含まれていなかったため\n\n気にせず`yarn add`したら解決するかと思ったら解決せず…\n\n`yarn why`で確認すると2つのバージョンが混在する状態になっていた\n\n```shell\n$ yarn why react-hot-loader\nyarn why v1.22.5\n[1/4] Why do we have the module \"react-hot-loader\"...?\n[2/4] Initialising dependency graph...\n[3/4] Finding dependency...\n[4/4] Calculating file sizes...\n=> Found \"react-hot-loader@4.13.0\"\ninfo Has been hoisted to \"react-hot-loader\"\ninfo This module exists because it's specified in \"devDependencies\".\ninfo Disk size without dependencies: \"652KB\"\ninfo Disk size with unique dependencies: \"1.96MB\"\ninfo Disk size with transitive dependencies: \"2.8MB\"\ninfo Number of shared dependencies: 16\n=> Found \"gatsby#react-hot-loader@4.12.21\"\ninfo This module exists because \"gatsby\" depends on it.\ninfo Disk size without dependencies: \"288KB\"\ninfo Disk size with unique dependencies: \"1.61MB\"\ninfo Disk size with transitive dependencies: \"2.45MB\"\ninfo Number of shared dependencies: 16\nDone in 1.94s.\n```\n\n新たにインストールしたほうは呼ばれていないっぽい\n\nということで次の記事を参考にして`yarn.lock`の`gatsby#react-hot-loader`の部分を削除して再度`yarn install`で解決した\n\n[yarn upgrade で更新できない間接的な依存パッケージだけをアップグレードするには - Qiita](https://qiita.com/uasi/items/ca440a750a77ca62321b)\n\n[https://qiita.com/uasi/items/ca440a750a77ca62321b:embed:cite]\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\n直接`yarn.lock`触るのはちょっと気が引けたので別の機会で他の方法がないか調べてみようと思う\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->",
          "timeToRead": 2,
          "objectID": "615d3429-691b-5e22-8a3d-081486b9673c",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "dependency...\n[4/4] Calculating file sizes...\n=> Found \"react-hot-loader@4.13.0\"\ninfo Has __ais-highlight__b__/ais-highlight__een hoisted to \"react-hot-loader\"\ninfo This module exists __ais-highlight__b__/ais-highlight__ecause it's specified in",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "November 15, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Error: React-Hot-Loader: AppContainer should __ais-highlight__b__/ais-highlight__e patched",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/react_hot_loader_should___ais-highlight__b__/ais-highlight__e_patched/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n次のリンクとまったく同じ状態になった\n\n[Gatsby doesn't work with React 17 RC (Error: React-Hot-Loader: AppContainer should __ais-highlight__b__/ais-highlight__e patched) · Issue #26979 · gatsbyjs/gatsby](https://github.com/gatsbyjs/gatsby/issues/26979)\n\nhttps://github.com/gatsbyjs/gatsby/issues/26979#issuecomment-696702777\n\nのコメントにあるようにパッケージのバージョンを上げればOKのよう\n\n`react-hot-loader`自体はgatsbyの依存モジュールで`package.json`には含まれていなかったため\n\n気にせず`yarn add`したら解決するかと思ったら解決せず…\n\n`yarn why`で確認すると2つのバージョンが混在する状態になっていた\n\n```shell\n$ yarn why react-hot-loader\nyarn why v1.22.5\n[1/4] Why do we have the module \"react-hot-loader\"...?\n[2/4] Initialising dependency graph...\n[3/4] Finding dependency...\n[4/4] Calculating file sizes...\n=> Found \"react-hot-loader@4.13.0\"\ninfo Has __ais-highlight__b__/ais-highlight__een hoisted to \"react-hot-loader\"\ninfo This module exists __ais-highlight__b__/ais-highlight__ecause it's specified in \"devDependencies\".\ninfo Disk size without dependencies: \"652KB\"\ninfo Disk size with unique dependencies: \"1.96MB\"\ninfo Disk size with transitive dependencies: \"2.8MB\"\ninfo Number of shared dependencies: 16\n=> Found \"gatsby#react-hot-loader@4.12.21\"\ninfo This module exists __ais-highlight__b__/ais-highlight__ecause \"gatsby\" depends on it.\ninfo Disk size without dependencies: \"288KB\"\ninfo Disk size with unique dependencies: \"1.61MB\"\ninfo Disk size with transitive dependencies: \"2.45MB\"\ninfo Number of shared dependencies: 16\nDone in 1.94s.\n```\n\n新たにインストールしたほうは呼ばれていないっぽい\n\nということで次の記事を参考にして`yarn.lock`の`gatsby#react-hot-loader`の部分を削除して再度`yarn install`で解決した\n\n[yarn upgrade で更新できない間接的な依存パッケージだけをアップグレードするには - Qiita](https://qiita.com/uasi/items/ca440a750a77ca62321b)\n\n[https://qiita.com/uasi/items/ca440a750a77ca62321b:embed:cite]\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\n直接`yarn.lock`触るのはちょっと気が引けたので別の機会で他の方法がないか調べてみようと思う\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 07, 2021",
          "title": "PocketのデータをAPI経由でBigQueryに取り込む",
          "slug": "/entries/start_pocket_api/",
          "rawMarkdownBody": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONをBigQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`bq load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:bqjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and be at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### BigQueryに入れ込む\n\n```\nbq load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
          "timeToRead": 3,
          "objectID": "196c4775-45c9-57b9-a004-cefc6bc4752e",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ったのでその場合は空配列にする\n\n### __ais-highlight__B__/ais-highlight__igQueryに入れ込む\n\n```\n__ais-highlight__b__/ais-highlight__q load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 07, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "PocketのデータをAPI経由で__ais-highlight__B__/ais-highlight__igQueryに取り込む",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "slug": {
              "value": "/entries/start_pocket_api/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONを__ais-highlight__B__/ais-highlight__igQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`__ais-highlight__b__/ais-highlight__q load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:__ais-highlight__b__/ais-highlight__qjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and __ais-highlight__b__/ais-highlight__e at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### __ais-highlight__B__/ais-highlight__igQueryに入れ込む\n\n```\n__ais-highlight__b__/ais-highlight__q load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 13, 2021",
          "title": "Workflowsで Memory usage limit exeeded",
          "slug": "/entries/workflows_logging_bigquery_failed/",
          "rawMarkdownBody": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのままBigQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクでBigQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+BigQueryへloadってパターンがベターなのかな",
          "timeToRead": 2,
          "objectID": "18e04e5f-00f2-50a2-a8d7-b7ac41718457",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "たいてそのレスポンスをそのまま__ais-highlight__B__/ais-highlight__igQueryに突っ込むみたいなやつ\n\nプライ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 13, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Workflowsで Memory usage limit exeeded",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/workflows_logging___ais-highlight__b__/ais-highlight__igquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__B__/ais-highlight__igQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクで__ais-highlight__B__/ais-highlight__igQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena___ais-highlight__b__/ais-highlight__ookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena___ais-highlight__b__/ais-highlight__ookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+__ais-highlight__B__/ais-highlight__igQueryへloadってパターンがベターなのかな",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 26, 2021",
          "title": "MySQLのgenerallogから特定のSQLを抜き出す",
          "slug": "/entries/filter_by_explain_result/",
          "rawMarkdownBody": "\nAWSで稼働しているRDSからgeneral logを取ってきてそのクエリログから特定のクエリを抽出してExplainの結果を判定するということをやったのでそのときやったことをメモしておく\n\n単発だったのでいくつか簡単なスクリプトを書いて対応したがしくみ化するならいろいろおもしろいかも\n\n## 前提\n\nローカルからのフォワーディングや本番サーバなどから実行するなど本番のDBに接続できる必要がある\n\ngeneral logをファイルに出力する設定をしておく必要がある\n\n## やること\n### general logの取得\n\nAPIのドキュメントは下記\n\n[Accessing Amazon RDS database log files - Amazon Relational Database Service](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html)\n\n直近24時間分のログが取れる\n\n数値はUTC時刻の範囲で出力されるっぽいので`general/mysql-general.log.0`はJSTでは`09:00`台の内容\n\n```shell\n#!/bin/bash\n\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.0  > 0.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.1  > 1.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.2  > 2.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.3  > 3.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.4  > 4.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.5  > 5.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.6  > 6.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.7  > 7.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.8  > 8.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.9  > 9.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.10 > 10.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.11 > 11.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.12 > 12.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.13 > 13.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.14 > 14.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.15 > 15.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.16 > 16.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.17 > 17.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.18 > 18.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.19 > 19.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.20 > 20.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.21 > 21.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.22 > 22.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.23 > 23.log\n```\n\n### クエリのフォーマット、フィルタリング\n\ngeneral logの形式が次のような感じなのでクエリ部分を抜き出す必要がある\n\n```\nTime                 Id Command    Argument\n                946458 Query    SELECT hoge FROM fuga....\n```\n\n[Mysql general log parser](https://gist.github.com/httpdss/948386)\n\n<!-- textlint-disable prh,spellcheck-tech-word -->\nからパーススクリプトを持ってきて配置し（mysql-general-log-parser.pl）次のようなシェルを書いた\n<!-- textlint-enable prh,spellcheck-tech-word  -->\n\n- filter_general_log.sh\n\n```shell\nfile=$1\n\nperl mysql-general-log-parser.pl $file | grep -v 'Your log message was truncated' | grep -v 'rds_heartbeat2' | grep -v 'rds_configuration' | grep -v 'mysql-connector-java' | grep -v 'EXPLAIN ' | sort | uniq > $file.query_list.txt\n```\n\n- 実行\n\n```shell\nls -l {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23}.log | awk '{print $9}' | xargs -i ./filter_general_log.sh {}\n```\n\n### 生成したファイルをマージする\n\n```\ncat *.query_list.txt > query_list.txt\n```\n\n### 特定クエリの抽出\n\n`GROUP BY`, `DISTINCT`を使用しているクエリを拾う\n\n- filter_group_by_query.py\n\n```python\nimport sqlparse\nimport sys\n\nfilepath = sys.argv[1]\n\nf = open(filepath)\nlines = f.readlines()\nf.close()\n\nfor line in lines:\n    parsed = sqlparse.parse(line)[0]\n    tokens = list(parsed.flatten())\n    is_grouped = filter(lambda t: t.match(sqlparse.tokens.Keyword, \"GROUP\\s+BY\", regex=True), tokens)\n    is_distinct = filter(lambda t: t.match(sqlparse.tokens.Name, \"DISTINCT\"), tokens)\n    if len(list(is_grouped)) > 0 or len(list(is_distinct )) > 0:\n        print(line)\n```\n\n- 実行\n\n```shell\npip install sqlparse\npython filter_group_by_query.py query_list.txt > group_by_query.txt\n```\n\n### チェック\n\nexplainの結果に`Using index for group-by`が含まれるものを抜き出す\n\n- check_group_by_query.sh\n\n```shell\n#!/bin/bash\n\nfile=$1\n\ncnt=0\ncat $file | while read line\ndo\n  cnt=`expr $cnt + 1`\n  echo $cnt\n  mysql -uhoge -P 13306 -h localhost -ppass dbname -e \"EXPLAIN $line\" | grep 'Using index for group-by'\n  if [ $? -eq 0 ]; then\n    echo \"Found Query\"\n    echo $line\n    echo $line >> result.txt\n  fi\ndone\n```\n\n- 実行\n\n```\nsh check_group_by_query.sh group_by_query.txt\n```\n\nという感じでいくつかのクエリを探すようなことをした",
          "timeToRead": 5,
          "objectID": "847cfd9d-a35c-5a9e-a4e9-7bb2044e7191",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "__ais-highlight__b__/ais-highlight__y`が含まれるものを抜き出す\n\n- check_group___ais-highlight__b__/ais-highlight__y_query.sh\n\n```shell\n#!/__ais-highlight__b__/ais-highlight__in/__ais-highlight__b__/ais-highlight__ash\n\nfile=$1\n\ncnt=0\ncat $file | while read line",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 26, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "MySQLのgenerallogから特定のSQLを抜き出す",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/filter___ais-highlight__b__/ais-highlight__y_explain_result/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nAWSで稼働しているRDSからgeneral logを取ってきてそのクエリログから特定のクエリを抽出してExplainの結果を判定するということをやったのでそのときやったことをメモしておく\n\n単発だったのでいくつか簡単なスクリプトを書いて対応したがしくみ化するならいろいろおもしろいかも\n\n## 前提\n\nローカルからのフォワーディングや本番サーバなどから実行するなど本番のDBに接続できる必要がある\n\ngeneral logをファイルに出力する設定をしておく必要がある\n\n## やること\n### general logの取得\n\nAPIのドキュメントは下記\n\n[Accessing Amazon RDS database log files - Amazon Relational Database Service](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_LogAccess.html)\n\n直近24時間分のログが取れる\n\n数値はUTC時刻の範囲で出力されるっぽいので`general/mysql-general.log.0`はJSTでは`09:00`台の内容\n\n```shell\n#!/__ais-highlight__b__/ais-highlight__in/__ais-highlight__b__/ais-highlight__ash\n\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.0  > 0.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.1  > 1.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.2  > 2.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.3  > 3.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.4  > 4.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.5  > 5.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.6  > 6.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.7  > 7.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.8  > 8.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.9  > 9.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.10 > 10.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.11 > 11.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.12 > 12.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.13 > 13.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.14 > 14.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.15 > 15.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.16 > 16.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.17 > 17.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.18 > 18.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.19 > 19.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.20 > 20.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.21 > 21.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.22 > 22.log\naws rds download-db-log-file-portion --db-instance-identifier hoge-db --starting-token 0 --output text --log-file-name general/mysql-general.log.23 > 23.log\n```\n\n### クエリのフォーマット、フィルタリング\n\ngeneral logの形式が次のような感じなのでクエリ部分を抜き出す必要がある\n\n```\nTime                 Id Command    Argument\n                946458 Query    SELECT hoge FROM fuga....\n```\n\n[Mysql general log parser](https://gist.github.com/httpdss/948386)\n\n<!-- textlint-disable prh,spellcheck-tech-word -->\nからパーススクリプトを持ってきて配置し（mysql-general-log-parser.pl）次のようなシェルを書いた\n<!-- textlint-enable prh,spellcheck-tech-word  -->\n\n- filter_general_log.sh\n\n```shell\nfile=$1\n\nperl mysql-general-log-parser.pl $file | grep -v 'Your log message was truncated' | grep -v 'rds_heartbeat2' | grep -v 'rds_configuration' | grep -v 'mysql-connector-java' | grep -v 'EXPLAIN ' | sort | uniq > $file.query_list.txt\n```\n\n- 実行\n\n```shell\nls -l {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23}.log | awk '{print $9}' | xargs -i ./filter_general_log.sh {}\n```\n\n### 生成したファイルをマージする\n\n```\ncat *.query_list.txt > query_list.txt\n```\n\n### 特定クエリの抽出\n\n`GROUP __ais-highlight__B__/ais-highlight__Y`, `DISTINCT`を使用しているクエリを拾う\n\n- filter_group___ais-highlight__b__/ais-highlight__y_query.py\n\n```python\nimport sqlparse\nimport sys\n\nfilepath = sys.argv[1]\n\nf = open(filepath)\nlines = f.readlines()\nf.close()\n\nfor line in lines:\n    parsed = sqlparse.parse(line)[0]\n    tokens = list(parsed.flatten())\n    is_grouped = filter(lambda t: t.match(sqlparse.tokens.Keyword, \"GROUP\\s+__ais-highlight__B__/ais-highlight__Y\", regex=True), tokens)\n    is_distinct = filter(lambda t: t.match(sqlparse.tokens.Name, \"DISTINCT\"), tokens)\n    if len(list(is_grouped)) > 0 or len(list(is_distinct )) > 0:\n        print(line)\n```\n\n- 実行\n\n```shell\npip install sqlparse\npython filter_group___ais-highlight__b__/ais-highlight__y_query.py query_list.txt > group___ais-highlight__b__/ais-highlight__y_query.txt\n```\n\n### チェック\n\nexplainの結果に`Using index for group-__ais-highlight__b__/ais-highlight__y`が含まれるものを抜き出す\n\n- check_group___ais-highlight__b__/ais-highlight__y_query.sh\n\n```shell\n#!/__ais-highlight__b__/ais-highlight__in/__ais-highlight__b__/ais-highlight__ash\n\nfile=$1\n\ncnt=0\ncat $file | while read line\ndo\n  cnt=`expr $cnt + 1`\n  echo $cnt\n  mysql -uhoge -P 13306 -h localhost -ppass dbname -e \"EXPLAIN $line\" | grep 'Using index for group-__ais-highlight__b__/ais-highlight__y'\n  if [ $? -eq 0 ]; then\n    echo \"Found Query\"\n    echo $line\n    echo $line >> result.txt\n  fi\ndone\n```\n\n- 実行\n\n```\nsh check_group___ais-highlight__b__/ais-highlight__y_query.sh group___ais-highlight__b__/ais-highlight__y_query.txt\n```\n\nという感じでいくつかのクエリを探すようなことをした",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "5",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 07, 2021",
          "title": "Terraform+GCSでバックエンドの設定をCLIで行う",
          "slug": "/entries/terraform_gcs_backend/",
          "rawMarkdownBody": "\n環境ごとにバックエンドの設定を変えたりする場合などに有効\n\n- backend.tf\n\n```terraform\nterraform {\n  backend \"gcs\" {\n  }\n}\n```\n\n## ファイルから設定する\n\n- backend-config.tfvars\n\n```tfvars\nbucket = \"hoge-tfstate\"\nprefix = \"prefix-hoge\"\n```\n\n```shell\nterraform init -backend-config=backend-config.tfvars\n```\n\n## コマンドラインから設定する\n\n```shell\nterraform init -backend-config=\"bucket=hoge-tfstate\" -backend-config=\"prefix=prefix-hoge\"\n```\n",
          "timeToRead": 1,
          "objectID": "99e788a3-d7c3-5b67-97fa-85e0fa23dfbb",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "tf\n\n```terraform\nterraform {\n  __ais-highlight__b__/ais-highlight__ackend \"gcs\" {\n  }\n}\n```\n\n## ファイルから設定する\n\n- __ais-highlight__b__/ais-highlight__ackend-config.tfvars\n\n```tfvars\n__ais-highlight__b__/ais-highlight__ucket = \"hoge-tfstate\"\nprefix = \"prefix-hoge\"\n```\n\n```shell\nterraform init -__ais-highlight__b__/ais-highlight__ackend-config",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 07, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Terraform+GCSでバックエンドの設定をCLIで行う",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/terraform_gcs___ais-highlight__b__/ais-highlight__ackend/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n環境ごとにバックエンドの設定を変えたりする場合などに有効\n\n- __ais-highlight__b__/ais-highlight__ackend.tf\n\n```terraform\nterraform {\n  __ais-highlight__b__/ais-highlight__ackend \"gcs\" {\n  }\n}\n```\n\n## ファイルから設定する\n\n- __ais-highlight__b__/ais-highlight__ackend-config.tfvars\n\n```tfvars\n__ais-highlight__b__/ais-highlight__ucket = \"hoge-tfstate\"\nprefix = \"prefix-hoge\"\n```\n\n```shell\nterraform init -__ais-highlight__b__/ais-highlight__ackend-config=__ais-highlight__b__/ais-highlight__ackend-config.tfvars\n```\n\n## コマンドラインから設定する\n\n```shell\nterraform init -__ais-highlight__b__/ais-highlight__ackend-config=\"__ais-highlight__b__/ais-highlight__ucket=hoge-tfstate\" -__ais-highlight__b__/ais-highlight__ackend-config=\"prefix=prefix-hoge\"\n```\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "June 10, 2021",
          "title": "TOCを抽出するためのブックマークレット",
          "slug": "/entries/toc_bookmarklet/",
          "rawMarkdownBody": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + body + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(msg)%20=>%20{%20console.log(msg)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(body)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
          "timeToRead": 1,
          "objectID": "72256919-995e-5a10-884d-8ed2a363da52",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (__ais-highlight__b__/ais-highlight__ody) => {\n    const d = window.open().document;\n    d.writeln('TOC' + __ais-highlight__b__/ais-highlight__ody + '');\n    d.close();\n  };\n\n  const toc = Array",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "June 10, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "TOCを抽出するためのブックマークレット",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/toc___ais-highlight__b__/ais-highlight__ookmarklet/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (__ais-highlight__b__/ais-highlight__ody) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + __ais-highlight__b__/ais-highlight__ody + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(msg)%20=>%20{%20console.log(msg)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(__ais-highlight__b__/ais-highlight__ody)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 23, 2021",
          "title": "Rubyで進捗表示のスクリプトを書くとき",
          "slug": "/entries/ruby_progress_bar/ruby_progress_bar/",
          "rawMarkdownBody": "\n```ruby\n(1..100).each { |n| print \"#{'#' * n}#{'-' * (100 - n)} #{n}% \\r\"; sleep 1}\n```\n\n書き捨てスクリプトなどで進捗を表示させたいときなど`\\r`を末尾に付けることで再描画できるので進捗が進んでいるような見え方をさせられる\n\n![alt](ruby_progress_bar01.gif)\n",
          "timeToRead": 1,
          "objectID": "2631f8bc-7df7-5e04-be79-7572e72a2ddd",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "できるので進捗が進んでいるような見え方をさせられる\n\n![alt](ruby_progress___ais-highlight__b__/ais-highlight__ar01.gif)\n",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 23, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Rubyで進捗表示のスクリプトを書くとき",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ruby_progress___ais-highlight__b__/ais-highlight__ar/ruby_progress___ais-highlight__b__/ais-highlight__ar/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n```ruby\n(1..100).each { |n| print \"#{'#' * n}#{'-' * (100 - n)} #{n}% \\r\"; sleep 1}\n```\n\n書き捨てスクリプトなどで進捗を表示させたいときなど`\\r`を末尾に付けることで再描画できるので進捗が進んでいるような見え方をさせられる\n\n![alt](ruby_progress___ais-highlight__b__/ais-highlight__ar01.gif)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 18, 2020",
          "title": "S3利用料をバケット毎に詳細に出すための情報",
          "slug": "/entries/s3_price_per_bucket/",
          "rawMarkdownBody": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/billing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
          "timeToRead": 2,
          "objectID": "3c9d8e94-ccb4-5473-83bf-8e8f5a0204bd",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ーネット -> `DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - リージョン間 -> `AWS-Out-__ais-highlight__B__/ais-highlight__ytes`,`C3DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - `S3G-DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`はリージョン間",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 18, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "S3利用料をバケット毎に詳細に出すための情報",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/s3_price_per___ais-highlight__b__/ais-highlight__ucket/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__b__/ais-highlight__illing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-__ais-highlight__B__/ais-highlight__yteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - リージョン間 -> `AWS-Out-__ais-highlight__B__/ais-highlight__ytes`,`C3DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`\n            - `S3G-DataTransfer-Out-__ais-highlight__B__/ais-highlight__ytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-__ais-highlight__B__/ais-highlight__ytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/__ais-highlight__B__/ais-highlight__ucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "September 25, 2021",
          "title": "GitHubのコントリビュート一覧に飛ぶためのブックマークレット",
          "slug": "/entries/github_contribute_bookmarklet/",
          "rawMarkdownBody": "\n以前Twitterで`採用などでGitHubアカウントもらったらこのクエリでコントリビューションみますね`みたいなのを見かけた\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\nとりあえずそのうち見るときのためにタブをそのままにしていたが、いろいろな人のも見られるとおもしろいかもと思ってブックマークレットを書いた\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->\n\nユーザーページもしくは対象ユーザーのどこかのリポジトリなど、ユーザー名がURLに存在すれば実行可能\n\n- github_contribute.js\n\n```javascript\n(function(){\n  const user = window.location.href.split(\"/\")[3];\n  const excludeOrgs = [];\n  const w = window.open();\n  const excludeOrgQuery = excludeOrgs.map(o => `-org%3A${o}`).join('+');\n  w.location.href = `https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;\n})()\n```\n\n- ブックマークバーへの貼り付け用出力\n\n```shell\n$ cat github_contribute.js |  sed -e ':loop;N;$!b loop;s/\\n/ /g' -e 's/ \\+/%20/g' -e 's/^/javascript:/'\njavascript:(function(){%20const%20user%20=%20window.location.href.split(\"/\")[3];%20const%20excludeOrgs%20=%20[];%20const%20w%20=%20window.open();%20const%20excludeOrgQuery%20=%20excludeOrgs.map(o%20=>%20`-org%3A${o}`).join('+');%20w.location.href%20=%20`https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;%20})()\n```\n\n`excludeOrgs`は自分が所属している組織へのPRやissueは除外するための記述\n\nGitHubで仕事の開発している場合は対象組織のPRなども表示されてしまうのでその除外\n\n感想としては自分はあんまりコントリビュートできてません!ということがわかりました。まる。\n",
          "timeToRead": 1,
          "objectID": "fb6ffa09-87e0-5cfc-a9fa-8886cfcd6da5",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "け用出力\n\n```shell\n$ cat github_contribute.js |  sed -e ':loop;N;$!__ais-highlight__b__/ais-highlight__ loop;s/\\n/ /g' -e 's/ \\+/%20/g' -e 's/^/javascript:/'\njavascript:(function(){%20const",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "September 25, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "GitHubのコントリビュート一覧に飛ぶためのブックマークレット",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/github_contribute___ais-highlight__b__/ais-highlight__ookmarklet/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\n以前Twitterで`採用などでGitHubアカウントもらったらこのクエリでコントリビューションみますね`みたいなのを見かけた\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\nとりあえずそのうち見るときのためにタブをそのままにしていたが、いろいろな人のも見られるとおもしろいかもと思ってブックマークレットを書いた\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->\n\nユーザーページもしくは対象ユーザーのどこかのリポジトリなど、ユーザー名がURLに存在すれば実行可能\n\n- github_contribute.js\n\n```javascript\n(function(){\n  const user = window.location.href.split(\"/\")[3];\n  const excludeOrgs = [];\n  const w = window.open();\n  const excludeOrgQuery = excludeOrgs.map(o => `-org%3A${o}`).join('+');\n  w.location.href = `https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;\n})()\n```\n\n- ブックマークバーへの貼り付け用出力\n\n```shell\n$ cat github_contribute.js |  sed -e ':loop;N;$!__ais-highlight__b__/ais-highlight__ loop;s/\\n/ /g' -e 's/ \\+/%20/g' -e 's/^/javascript:/'\njavascript:(function(){%20const%20user%20=%20window.location.href.split(\"/\")[3];%20const%20excludeOrgs%20=%20[];%20const%20w%20=%20window.open();%20const%20excludeOrgQuery%20=%20excludeOrgs.map(o%20=>%20`-org%3A${o}`).join('+');%20w.location.href%20=%20`https://github.com/pulls?q=involves%3A${user}+-user%3A${user}+${excludeOrgQuery}`;%20})()\n```\n\n`excludeOrgs`は自分が所属している組織へのPRやissueは除外するための記述\n\nGitHubで仕事の開発している場合は対象組織のPRなども表示されてしまうのでその除外\n\n感想としては自分はあんまりコントリビュートできてません!ということがわかりました。まる。\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "January 26, 2021",
          "title": "VagrantのVMが立ち上がらなくなってしまったときの対処方いくつか",
          "slug": "/entries/vagrant_boot_failed/",
          "rawMarkdownBody": "\nホスト機がフリーズしてしまったとかVMを正常に終了させられないまま再起動してしまったときなど\n\nごくたまにVagrantで使っているVMが起動しなくなる\n\nいくつか試してみたのでその記録\n\n本記事では`dev4`というVM名で進める\n\n```shell\n$ vagrant up\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Checking if box 'bento/centos-7.4' version '201803.24.0' is up to date...\n==> default: Clearing any previously set forwarded ports...\nThere was an error while executing `VBoxManage`, a CLI used by Vagrant\nfor controlling VirtualBox. The command and stderr is shown below.\n\nCommand: [\"modifyvm\", \"d4c26ea5-e507-4049-878a-2c89a841f9e6\", \"--natpf1\", \"delete\", \"127.0.0.1tcp22396\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9200\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9300\", \"--natpf1\", \"delete\", \"ssh\"]\n\nStderr: VBoxManage.exe: error: The machine 'dev4' is already locked for a session (or being unlocked)\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_OBJECT_STATE (0x80bb0007), component MachineWrap, interface IMachine, callee IUnknown\nVBoxManage.exe: error: Context: \"LockMachine(a->session, LockType_Write)\" at line 554 of file VBoxManageModifyVM.cpp\n```\n\nlockされてます\n\nいくつか調べたら`poweroff`にすればよいとあったので実行してみる\n\n```shell\n$ cd /c/Program\\ Files/Oracle/VirtualBox\n$ ./VBoxManage.exe controlvm dev4 poweroff\nVBoxManage.exe: error: The virtual machine is being powered down\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_VM_STATE (0x80bb0002), component ConsoleWrap, interface IConsole, callee IUnknown\nVBoxManage.exe: error: Context: \"PowerDown(progress.asOutParam())\" at line 619 of file VBoxManageControlVM.cpp\n```\n\nもう止まっているよということのよう\n\n```\n$ vagrant status\nCurrent machine states:\n\ndefault                   stopping (virtualbox)\n\nThe VM is stopping.\n```\n\n- 参考\n\n[VirtualBoxで仮想コンピュータが反応しなくなった時( = _ = )](https://qiita.com/Ikumi/items/557808a232a0c12d3027)\n\nを参考に強制的に落とす\n\n```shell\n ./VBoxManage.exe startvm dev4 --type emergencystop\n```\n\nabortedになった\n\n```shell\n$ vagrant status\nCurrent machine states:\n\ndefault                   aborted (virtualbox)\n\nThe VM is in an aborted state. This means that it was abruptly\nstopped without properly closing the session. Run `vagrant up`\nto resume this virtual machine. If any problems persist, you may\nhave to destroy and restart the virtual machine.\n```\n\nここから`vagrant up`して無事立ち上げることができた\n\n\n```\n$ vagrant up\n.....\n.....\n.....\nTimed out while waiting for the machine to boot. This means that\nVagrant was unable to communicate with the guest machine within\nthe configured (\"config.vm.boot_timeout\" value) time period.\n\nIf you look above, you should be able to see the error(s) that\nVagrant had when attempting to connect to the machine. These errors\nare usually good hints as to what may be wrong.\n\nIf you're using a custom box, make sure that networking is properly\nworking and you're able to connect to the machine. It is a common\nproblem that networking isn't setup properly in these boxes.\nVerify that authentication configurations are also setup properly,\nas well.\n\nIf the box appears to be booting properly, you may want to increase\nthe timeout (\"config.vm.boot_timeout\") value.\n```\n\nが、立ち上がったは良いがsshできないという感じになってしまった\n\nVirtualBoxからものぞいてみようと試みたがVMが完全に立ち上がらない状態で操作できず\n\n結局ホストのWindowsを完全シャットダウン（shift+シャットダウン）&起動してVM起動したら動くようになっていた\n\nただの徒労…\n",
          "timeToRead": 3,
          "objectID": "472ccc60-931d-5077-bfd7-c2d4388530aa",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "in these __ais-highlight__b__/ais-highlight__oxes.\nVerify that authentication configurations are also setup properly,\nas well.\n\nIf the __ais-highlight__b__/ais-highlight__ox appears to __ais-highlight__b__/ais-highlight__e __ais-highlight__b__/ais-highlight__ooting properly, you may want to increase\nthe timeout (\"config.vm",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "January 26, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VagrantのVMが立ち上がらなくなってしまったときの対処方いくつか",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vagrant___ais-highlight__b__/ais-highlight__oot_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "rawMarkdownBody": {
              "value": "\nホスト機がフリーズしてしまったとかVMを正常に終了させられないまま再起動してしまったときなど\n\nごくたまにVagrantで使っているVMが起動しなくなる\n\nいくつか試してみたのでその記録\n\n本記事では`dev4`というVM名で進める\n\n```shell\n$ vagrant up\n__ais-highlight__B__/ais-highlight__ringing machine 'default' up with 'virtualbox' provider...\n==> default: Checking if __ais-highlight__b__/ais-highlight__ox '__ais-highlight__b__/ais-highlight__ento/centos-7.4' version '201803.24.0' is up to date...\n==> default: Clearing any previously set forwarded ports...\nThere was an error while executing `VBoxManage`, a CLI used __ais-highlight__b__/ais-highlight__y Vagrant\nfor controlling VirtualBox. The command and stderr is shown __ais-highlight__b__/ais-highlight__elow.\n\nCommand: [\"modifyvm\", \"d4c26ea5-e507-4049-878a-2c89a841f9e6\", \"--natpf1\", \"delete\", \"127.0.0.1tcp22396\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9200\", \"--natpf1\", \"delete\", \"127.0.0.1tcp9300\", \"--natpf1\", \"delete\", \"ssh\"]\n\nStderr: VBoxManage.exe: error: The machine 'dev4' is already locked for a session (or __ais-highlight__b__/ais-highlight__eing unlocked)\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_OBJECT_STATE (0x80bb0007), component MachineWrap, interface IMachine, callee IUnknown\nVBoxManage.exe: error: Context: \"LockMachine(a->session, LockType_Write)\" at line 554 of file VBoxManageModifyVM.cpp\n```\n\nlockされてます\n\nいくつか調べたら`poweroff`にすればよいとあったので実行してみる\n\n```shell\n$ cd /c/Program\\ Files/Oracle/VirtualBox\n$ ./VBoxManage.exe controlvm dev4 poweroff\nVBoxManage.exe: error: The virtual machine is __ais-highlight__b__/ais-highlight__eing powered down\nVBoxManage.exe: error: Details: code VBOX_E_INVALID_VM_STATE (0x80bb0002), component ConsoleWrap, interface IConsole, callee IUnknown\nVBoxManage.exe: error: Context: \"PowerDown(progress.asOutParam())\" at line 619 of file VBoxManageControlVM.cpp\n```\n\nもう止まっているよということのよう\n\n```\n$ vagrant status\nCurrent machine states:\n\ndefault                   stopping (virtualbox)\n\nThe VM is stopping.\n```\n\n- 参考\n\n[VirtualBoxで仮想コンピュータが反応しなくなった時( = _ = )](https://qiita.com/Ikumi/items/557808a232a0c12d3027)\n\nを参考に強制的に落とす\n\n```shell\n ./VBoxManage.exe startvm dev4 --type emergencystop\n```\n\nabortedになった\n\n```shell\n$ vagrant status\nCurrent machine states:\n\ndefault                   aborted (virtualbox)\n\nThe VM is in an aborted state. This means that it was abruptly\nstopped without properly closing the session. Run `vagrant up`\nto resume this virtual machine. If any problems persist, you may\nhave to destroy and restart the virtual machine.\n```\n\nここから`vagrant up`して無事立ち上げることができた\n\n\n```\n$ vagrant up\n.....\n.....\n.....\nTimed out while waiting for the machine to __ais-highlight__b__/ais-highlight__oot. This means that\nVagrant was unable to communicate with the guest machine within\nthe configured (\"config.vm.__ais-highlight__b__/ais-highlight__oot_timeout\" value) time period.\n\nIf you look above, you should __ais-highlight__b__/ais-highlight__e able to see the error(s) that\nVagrant had when attempting to connect to the machine. These errors\nare usually good hints as to what may __ais-highlight__b__/ais-highlight__e wrong.\n\nIf you're using a custom __ais-highlight__b__/ais-highlight__ox, make sure that networking is properly\nworking and you're able to connect to the machine. It is a common\nproblem that networking isn't setup properly in these __ais-highlight__b__/ais-highlight__oxes.\nVerify that authentication configurations are also setup properly,\nas well.\n\nIf the __ais-highlight__b__/ais-highlight__ox appears to __ais-highlight__b__/ais-highlight__e __ais-highlight__b__/ais-highlight__ooting properly, you may want to increase\nthe timeout (\"config.vm.__ais-highlight__b__/ais-highlight__oot_timeout\") value.\n```\n\nが、立ち上がったは良いがsshできないという感じになってしまった\n\nVirtualBoxからものぞいてみようと試みたがVMが完全に立ち上がらない状態で操作できず\n\n結局ホストのWindowsを完全シャットダウン（shift+シャットダウン）&起動してVM起動したら動くようになっていた\n\nただの徒労…\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "October 23, 2020",
          "title": "特定の容量のダミーファイルを生成する",
          "slug": "/entries/dd/",
          "rawMarkdownBody": "\n```shell\n$ dd if=/dev/zero of=1K_M.out bs=1K count=1\n1+0 records in\n1+0 records out\n1024 bytes (1.0 kB) copied, 0.000412943 s, 2.5 MB/s\n```\n\n```\n$ ls -al 1K_M.out\n-rw-rw-r-- 1 vagrant vagrant 1024 Oct 24 04:46 1K_M.out\n```\n\nディスク的には4KBで固定のよう\n\n```\n$ du -sh 1K_M.out\n4.0K    1K_M.out\n```\n\n`1K_M.out`というファイル名にnull文字で埋める、1KBで1ファイル作成する\n\n容量によって確認したいことが変わる場合など容量を合わせていくの意外と面倒だったりするのでそういうときに使える\n",
          "timeToRead": 1,
          "objectID": "aa24d6f2-a7ed-50f3-afa3-5e13f53f523f",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n```shell\n$ dd if=/dev/zero of=1K_M.out __ais-highlight__b__/ais-highlight__s=1K count=1\n1+0 records in\n1+0 records out\n1024 __ais-highlight__b__/ais-highlight__ytes (1.0 kB) copied, 0",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "October 23, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "特定の容量のダミーファイルを生成する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/dd/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n```shell\n$ dd if=/dev/zero of=1K_M.out __ais-highlight__b__/ais-highlight__s=1K count=1\n1+0 records in\n1+0 records out\n1024 __ais-highlight__b__/ais-highlight__ytes (1.0 kB) copied, 0.000412943 s, 2.5 MB/s\n```\n\n```\n$ ls -al 1K_M.out\n-rw-rw-r-- 1 vagrant vagrant 1024 Oct 24 04:46 1K_M.out\n```\n\nディスク的には4KBで固定のよう\n\n```\n$ du -sh 1K_M.out\n4.0K    1K_M.out\n```\n\n`1K_M.out`というファイル名にnull文字で埋める、1KBで1ファイル作成する\n\n容量によって確認したいことが変わる場合など容量を合わせていくの意外と面倒だったりするのでそういうときに使える\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["b"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 84,
      "page": 0,
      "nbPages": 5,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "query": "B",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&query=B&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 10
    }
  ]
}
