{
  "results": [
    {
      "hits": [
        {
          "date": "March 25, 2022",
          "title": "BigQueryの日付を扱う際のメモ",
          "slug": "/entries/bigquery_date_function/",
          "rawMarkdownBody": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
          "timeToRead": 1,
          "objectID": "68f46908-591f-5bb4-82bd-f2fc099406d2",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "March 25, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryの日付を扱う際のメモ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 08, 2021",
          "title": "BigQueryのbq load時にautodetectを使えない場合",
          "slug": "/entries/bigquery_cant_use_autodetect/",
          "rawMarkdownBody": "\nPocketのデータをAPIで取得してBigQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\nBigQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/bigquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、BigQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。BigQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
          "timeToRead": 3,
          "objectID": "511a0a9b-6cec-55d0-a965-148667fcf789",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSON",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 08, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryのbq load時にautodetectを使えない場合",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\n__ais-highlight__Bi__/ais-highlight__gQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、__ais-highlight__Bi__/ais-highlight__gQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。__ais-highlight__Bi__/ais-highlight__gQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "December 09, 2020",
          "title": "BigQueryでサンプルデータをサクッと作る",
          "slug": "/entries/bigquery_sample_data/",
          "rawMarkdownBody": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
          "timeToRead": 1,
          "objectID": "28192504-51b0-5f94-9f12-c62f278c23cc",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "December 09, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryでサンプルデータをサクッと作る",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 21, 2021",
          "title": "BigQueryで日付を扱うときはTimezoneを意識する",
          "slug": "/entries/bigquery_date_timezone/",
          "rawMarkdownBody": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\nBigQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
          "timeToRead": 1,
          "objectID": "1d531f2a-2c16-5859-96ce-a8cf37a230b8",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ータに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 21, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryで日付を扱うときはTimezoneを意識する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 28, 2022",
          "title": "JSONファイルをBigQueryに読ませJSON型で扱うためにそのままCSVで保存する",
          "slug": "/entries/json_to_csv/",
          "rawMarkdownBody": "\n[Working with JSON data in Standard SQL  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/json-data)\n\n先日BigQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
          "timeToRead": 1,
          "objectID": "6ed6b22c-63cc-5fb2-99d6-eeada5709406",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型が",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 28, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "JSONファイルを__ais-highlight__Bi__/ais-highlight__gQueryに読ませJSON型で扱うためにそのままCSVで保存する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 07, 2021",
          "title": "PocketのデータをAPI経由でBigQueryに取り込む",
          "slug": "/entries/start_pocket_api/",
          "rawMarkdownBody": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONをBigQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`bq load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:bqjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and be at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### BigQueryに入れ込む\n\n```\nbq load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
          "timeToRead": 3,
          "objectID": "196c4775-45c9-57b9-a004-cefc6bc4752e",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "てはこの辺\n\n## おまけ\n\nここで得たJSONを__ais-highlight__Bi__/ais-highlight__gQueryに放り込んでよしなにやろうと",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 07, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "PocketのデータをAPI経由で__ais-highlight__Bi__/ais-highlight__gQueryに取り込む",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/start_pocket_api/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONを__ais-highlight__Bi__/ais-highlight__gQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`bq load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:bqjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and be at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### __ais-highlight__Bi__/ais-highlight__gQueryに入れ込む\n\n```\nbq load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 13, 2021",
          "title": "Workflowsで Memory usage limit exeeded",
          "slug": "/entries/workflows_logging_bigquery_failed/",
          "rawMarkdownBody": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのままBigQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクでBigQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+BigQueryへloadってパターンがベターなのかな",
          "timeToRead": 2,
          "objectID": "18e04e5f-00f2-50a2-a8d7-b7ac41718457",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "たいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 13, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Workflowsで Memory usage limit exeeded",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/workflows_logging___ais-highlight__bi__/ais-highlight__gquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクで__ais-highlight__Bi__/ais-highlight__gQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+__ais-highlight__Bi__/ais-highlight__gQueryへloadってパターンがベターなのかな",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 10, 2021",
          "title": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
          "slug": "/entries/dataportal_experience_date/",
          "rawMarkdownBody": "\nただのメモ\n\nTogglからBigQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
          "timeToRead": 2,
          "objectID": "17cb94a3-6fe4-5894-bec2-e090afbbdb8d",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 10, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/dataportal_experience_date/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 13, 2021",
          "title": "tfenvを使いTerraformのバージョンを切り替える",
          "slug": "/entries/tfenv/",
          "rawMarkdownBody": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/bin\n$ ln -s ~/.tfenv/bin/* ~/.local/bin\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/bin:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
          "timeToRead": 1,
          "objectID": "4c8c0fb8-2bb1-575a-94a8-c7637ce72ecb",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 13, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "tfenvを使いTerraformのバージョンを切り替える",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/tfenv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 15, 2020",
          "title": "CentOS7系でのrmagickのインストール",
          "slug": "/entries/ruby_rmagick_install/",
          "rawMarkdownBody": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
          "timeToRead": 3,
          "objectID": "4ff80e3f-7590-50b7-a068-4370fb8d098a",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 15, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "CentOS7系でのrmagickのインストール",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ruby_rmagick_install/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 18, 2020",
          "title": "S3利用料をバケット毎に詳細に出すための情報",
          "slug": "/entries/s3_price_per_bucket/",
          "rawMarkdownBody": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/billing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
          "timeToRead": 2,
          "objectID": "3c9d8e94-ccb4-5473-83bf-8e8f5a0204bd",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サー",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 18, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "S3利用料をバケット毎に詳細に出すための情報",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/s3_price_per_bucket/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "November 30, 2021",
          "title": "VS Codeのターミナルプロファイル設定",
          "slug": "/entries/vscode_terminal_profile/",
          "rawMarkdownBody": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/bin/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
          "timeToRead": 1,
          "objectID": "203c16a1-d621-565f-9467-d727d12f04b8",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultで",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "November 30, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VS Codeのターミナルプロファイル設定",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vscode_terminal_profile/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "September 05, 2021",
          "title": "Lambdaのソースコード差分を取得する",
          "slug": "/entries/lambda_diff/",
          "rawMarkdownBody": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/bin/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/bin/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
          "timeToRead": 1,
          "objectID": "4365a1dd-799e-546c-8c05-d2cac5c7bbe0",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "とで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "September 05, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Lambdaのソースコード差分を取得する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/lambda_diff/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "October 15, 2020",
          "title": "AnsibleでAWS CLI v2をインストールする",
          "slug": "/entries/ansible_install_awscliv2/",
          "rawMarkdownBody": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
          "timeToRead": 2,
          "objectID": "99e28ca7-2980-59fe-996e-ff500f2f3ee3",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "October 15, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "AnsibleでAWS CLI v2をインストールする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ansible_install_awscliv2/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 14, 2020",
          "title": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
          "slug": "/entries/docker_host/",
          "rawMarkdownBody": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/bin/dockerd -H unix://\n+ ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
          "timeToRead": 1,
          "objectID": "82e9a7ed-566d-569c-99ef-7215b036a725",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 14, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/docker_host/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 19, 2021",
          "title": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
          "slug": "/entries/introduction_jest_and_testing_library_to_gatsby/",
          "rawMarkdownBody": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 ms)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
          "timeToRead": 2,
          "objectID": "26e74846-3144-508a-bb2e-b72e781ffdf7",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 19, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 27, 2021",
          "title": "WSL2でDockerForWindowsのコマンドを叩く",
          "slug": "/entries/wsl_docker_for_windows/",
          "rawMarkdownBody": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/bin/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker\n\n```bash\n#!/usr/bin/env sh\nbinary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port binding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
          "timeToRead": 2,
          "objectID": "a8956213-b2d5-5b19-886e-3030ada5bd23",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "で決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 27, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "WSL2でDockerForWindowsのコマンドを叩く",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/wsl_docker_for_windows/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port __ais-highlight__bi__/ais-highlight__nding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "October 14, 2021",
          "title": "VS Code Remote WSLが起動しない",
          "slug": "/entries/vscode_wsl_failed/",
          "rawMarkdownBody": "\nPCをセットアップし直してWSLも入れ直していざVS Codeを起動したらWSLに接続できなかった\n\n- エラーログ\n\n```\n[2021-10-08 17:49:31.526] Resolving wsl+Ubuntu, resolveAttempt: 1\n[2021-10-08 17:49:31.649] Starting VS Code Server inside WSL (Ubuntu)\n[2021-10-08 17:49:31.649] Extension version: 0.58.2, Windows build: 19041. Multi distro support: available. WSL path support: enabled\n[2021-10-08 17:49:31.650] No shell environment set or found for current distro.\n[2021-10-08 17:49:31.887] Probing if server is already installed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/bin/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] Unable to detect if server is already installed: Error: Command failed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/bin/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] 指定されたファイルが見つかりません。\n[2021-10-08 17:49:32.000] \n[2021-10-08 17:49:32.001] Launching C:\\Windows\\System32\\wsl.exe -d Ubuntu sh -c '\"$VSCODE_WSL_EXT_LOCATION/scripts/wslServer.sh\" 69755771804a4f5097277cbbb50dff67 stable .vscode-server 0  '}\n[2021-10-08 17:49:32.080] \n[2021-10-08 17:49:32.081] VS Code Server for WSL closed unexpectedly.\n[2021-10-08 17:49:32.082] For help with startup problems, go to\n[2021-10-08 17:49:32.082] https://code.visualstudio.com/docs/remote/troubleshooting#_wsl-tips\n[2021-10-08 17:49:32.102] WSL Daemon exited with code 0\n```\n\n<!-- textlint-disable prh -->\n一部文字化けしていたので該当箇所は削除した\n<!-- textlint-enable prh -->\n\n使用しているWSLのディストリビューションがデフォルトでなくなってしまっていた模様\n\n[Developing in the Windows Subsystem for Linux with Visual Studio Code](https://code.visualstudio.com/docs/remote/wsl#_why-am-i-asked-to-change-the-default-distro)\n\n現在使っているのは`Ubuntu-20.04`\n\n確認してみる\n\n```shell\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu (既定)\ndocker-desktop\nUbuntu-20.04\ndocker-desktop-data\n\n> wslconfig /setdefault Ubuntu-20.04\n\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu-20.04 (既定)\nUbuntu\ndocker-desktop\ndocker-desktop-data\n```\n\n`Ubuntu`のディストリビューションはPC移行以前に使っていたが新しいPCにWSLのデータを移行できなかったので起動できなかったと推測できる\n\nVS CodeのRemote WSLではデフォルトのディストリビューションに接続する仕様なのでホスト側でデフォルトのWSLのディストリビューションを決めてあげる必要がある\n\n無事VS CodeでRemoteWSL拡張が使えるようになった",
          "timeToRead": 2,
          "objectID": "0ef6d022-c0b5-58c5-819b-9768bd9396b0",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "already installed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/__ais-highlight__bi__/ais-highlight__n/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "October 14, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VS Code Remote WSLが起動しない",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vscode_wsl_failed/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nPCをセットアップし直してWSLも入れ直していざVS Codeを起動したらWSLに接続できなかった\n\n- エラーログ\n\n```\n[2021-10-08 17:49:31.526] Resolving wsl+Ubuntu, resolveAttempt: 1\n[2021-10-08 17:49:31.649] Starting VS Code Server inside WSL (Ubuntu)\n[2021-10-08 17:49:31.649] Extension version: 0.58.2, Windows build: 19041. Multi distro support: available. WSL path support: enabled\n[2021-10-08 17:49:31.650] No shell environment set or found for current distro.\n[2021-10-08 17:49:31.887] Probing if server is already installed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/__ais-highlight__bi__/ais-highlight__n/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] Unable to detect if server is already installed: Error: Command failed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/__ais-highlight__bi__/ais-highlight__n/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] 指定されたファイルが見つかりません。\n[2021-10-08 17:49:32.000] \n[2021-10-08 17:49:32.001] Launching C:\\Windows\\System32\\wsl.exe -d Ubuntu sh -c '\"$VSCODE_WSL_EXT_LOCATION/scripts/wslServer.sh\" 69755771804a4f5097277cbbb50dff67 stable .vscode-server 0  '}\n[2021-10-08 17:49:32.080] \n[2021-10-08 17:49:32.081] VS Code Server for WSL closed unexpectedly.\n[2021-10-08 17:49:32.082] For help with startup problems, go to\n[2021-10-08 17:49:32.082] https://code.visualstudio.com/docs/remote/troubleshooting#_wsl-tips\n[2021-10-08 17:49:32.102] WSL Daemon exited with code 0\n```\n\n<!-- textlint-disable prh -->\n一部文字化けしていたので該当箇所は削除した\n<!-- textlint-enable prh -->\n\n使用しているWSLのディストリビューションがデフォルトでなくなってしまっていた模様\n\n[Developing in the Windows Subsystem for Linux with Visual Studio Code](https://code.visualstudio.com/docs/remote/wsl#_why-am-i-asked-to-change-the-default-distro)\n\n現在使っているのは`Ubuntu-20.04`\n\n確認してみる\n\n```shell\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu (既定)\ndocker-desktop\nUbuntu-20.04\ndocker-desktop-data\n\n> wslconfig /setdefault Ubuntu-20.04\n\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu-20.04 (既定)\nUbuntu\ndocker-desktop\ndocker-desktop-data\n```\n\n`Ubuntu`のディストリビューションはPC移行以前に使っていたが新しいPCにWSLのデータを移行できなかったので起動できなかったと推測できる\n\nVS CodeのRemote WSLではデフォルトのディストリビューションに接続する仕様なのでホスト側でデフォルトのWSLのディストリビューションを決めてあげる必要がある\n\n無事VS CodeでRemoteWSL拡張が使えるようになった",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 17, 2021",
          "title": "WSL2に移行した",
          "slug": "/entries/wsl2_installed/",
          "rawMarkdownBody": "\n下記参考にWSL→WSL2へ移行した際の記録\n\n[Windows Subsystem for Linux (WSL) を Windows 10 にインストールする | Microsoft Docs](https://docs.microsoft.com/ja-jp/windows/wsl/install-win10)\n\n上記を参考に各種設定を行い次のコマンドを打ったが何も変わらず…\n\n```\n$ wsl --set-version Ubuntu 2\n変換中です。この処理には数分かかることがあります...\nWSL 2 との主な違いについては、https://aka.ms/wsl2 を参照してください\nWindows の仮想マシン プラットフォーム機能を有効にして、BIOS で仮想化が有効になっていることを確認してください。\n詳細については、https://aka.ms/wsl2-install を参照してください\n```\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         1\n```\n\nBIOSでの確認もしてみたが仮想化機能も有効になっていそう…\n\n何度か一連の手順を踏んでみたが変わらず\n\n最終的にはDockerForWindowsを入れてそちらの方で「仮想化機能をEnableにする」ダイアログをクリックして再起動したらWSL2側も使えるようになった\n\n<!-- textlint-disable ja-hiragana-fukushi -->\nというか仮想化機能自体が「Windowsの機能の有効化または無効化」の設定やPowershellのコマンドからだと正しくONにできなかったように見える\n<!-- textlint-enable ja-hiragana-fukushi -->\n\nもしくはほかにも設定変更をするべき項目が存在したか…\n\n正直良くわからないが無事にWSL2+Dockerを使えるようになった\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n```\n\n`docker-desktop`も出力されるよう\n\n以前から使っていたVagrant+VirtualBox（v6.1.16）のVMも問題なく起動して動かせたので良き\n\n今までDockerを使うリポジトリは全部VMの中で開発していたがこれでWSL側でも開発できる",
          "timeToRead": 1,
          "objectID": "2fed46ed-ffd0-5e59-849a-adee22132af0",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ラットフォーム機能を有効にして、__ais-highlight__BI__/ais-highlight__OS で仮想化が有効になっているこ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 17, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "WSL2に移行した",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/wsl2_installed/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n下記参考にWSL→WSL2へ移行した際の記録\n\n[Windows Subsystem for Linux (WSL) を Windows 10 にインストールする | Microsoft Docs](https://docs.microsoft.com/ja-jp/windows/wsl/install-win10)\n\n上記を参考に各種設定を行い次のコマンドを打ったが何も変わらず…\n\n```\n$ wsl --set-version Ubuntu 2\n変換中です。この処理には数分かかることがあります...\nWSL 2 との主な違いについては、https://aka.ms/wsl2 を参照してください\nWindows の仮想マシン プラットフォーム機能を有効にして、__ais-highlight__BI__/ais-highlight__OS で仮想化が有効になっていることを確認してください。\n詳細については、https://aka.ms/wsl2-install を参照してください\n```\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         1\n```\n\n__ais-highlight__BI__/ais-highlight__OSでの確認もしてみたが仮想化機能も有効になっていそう…\n\n何度か一連の手順を踏んでみたが変わらず\n\n最終的にはDockerForWindowsを入れてそちらの方で「仮想化機能をEnableにする」ダイアログをクリックして再起動したらWSL2側も使えるようになった\n\n<!-- textlint-disable ja-hiragana-fukushi -->\nというか仮想化機能自体が「Windowsの機能の有効化または無効化」の設定やPowershellのコマンドからだと正しくONにできなかったように見える\n<!-- textlint-enable ja-hiragana-fukushi -->\n\nもしくはほかにも設定変更をするべき項目が存在したか…\n\n正直良くわからないが無事にWSL2+Dockerを使えるようになった\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n```\n\n`docker-desktop`も出力されるよう\n\n以前から使っていたVagrant+VirtualBox（v6.1.16）のVMも問題なく起動して動かせたので良き\n\n今までDockerを使うリポジトリは全部VMの中で開発していたがこれでWSL側でも開発できる",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "November 07, 2020",
          "title": "digest-crc gemがインストールできない",
          "slug": "/entries/install_digest_crc_in_docker_image/",
          "rawMarkdownBody": "\nCloudRun Rubyのチュートリアルを進めた後に`google-cloud`のGemを使っていろいろやってみようとインストールして見たら怒られた\n\n- Dockerfile\n\n```dockerfile\nFROM ruby:2.7-slim\n\nWORKDIR /usr/src/app\nCOPY Gemfile Gemfile.lock ./\nENV BUNDLE_FROZEN=true\nRUN gem install bundler && bundle install --without test\n\nCOPY . ./\n\nCMD [\"ruby\", \"./app.rb\"]\n```\n\n- Gemfile\n\n```gemfile\nsource \"https://rubygems.org\"\n\ngem \"google-cloud-storage\"\ngem \"google-cloud-secret_manager\"\ngem \"sinatra\", \"~>2.0\"\n\ngroup :test do\n  gem \"rack-test\"\n  gem \"rest-client\"\n  gem \"rspec\"\n  gem \"rspec_junit_formatter\"\n  gem \"rubysl-securerandom\"\nend\n```\n\n```\nInstalling digest-crc 0.6.1 with native extensions\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /usr/local/bundle/gems/digest-crc-0.6.1/ext/digest\n/usr/local/bin/ruby -I/usr/local/lib/ruby/2.7.0/rubygems -rrubygems\n/usr/local/lib/ruby/gems/2.7.0/gems/rake-13.0.1/exe/rake\nRUBYARCHDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\nRUBYLIBDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\n/usr/local/bin/ruby -S extconf.rb\nchecking for stdint.h... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/usr/local/bin/$(RUBY_BASE_NAME)\n        --with-stdint-dir\n        --without-stdint-dir\n        --with-stdint-include\n        --without-stdint-include=${stdint-dir}/include\n        --with-stdint-lib\n        --without-stdint-lib=${stdint-dir}/lib\n/usr/local/lib/ruby/2.7.0/mkmf.rb:471:in `try_do': The compiler failed to\ngenerate an executable file. (RuntimeError)\nYou have to install development tools first.\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:613:in `try_cpp'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1124:in `block in have_header'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:971:in `block in checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block (2 levels) in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:357:in `postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:970:in `checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1123:in `have_header'\n        from extconf.rb:3:in `<main>'\nrake aborted!\nCommand failed with status (1): [/usr/local/bin/ruby -S extconf.rb...]\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:32:in `block (3\nlevels) in <top (required)>'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `chdir'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `block (2\nlevels) in <top (required)>'\nTasks: TOP => default => crc15/crc15_ext.so => crc15/Makefile\n(See full trace by running task with --trace)\n\nrake failed, exit code 1\n\nGem files will remain installed in /usr/local/bundle/gems/digest-crc-0.6.1 for\ninspection.\nResults logged to\n/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1/gem_make.out\n\nAn error occurred while installing digest-crc (0.6.1), and Bundler cannot\ncontinue.\nMake sure that `gem install digest-crc -v '0.6.1' --source\n'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  google-cloud-storage was resolved to 1.29.1, which depends on\n    digest-crc\nThe command '/bin/sh -c gem install bundler && bundle install --without test' returned a non-zero code: 5\nERROR\nERROR: build step 0 \"gcr.io/cloud-builders/docker\" failed: step exited with non-zero status: 5\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------\n\nERROR: (gcloud.builds.submit) build 57e77985-ae0b-40b7-b0d7-04ce7bcbd099 completed with status \"FAILURE\"\n```\n\nちょっと調べただけだとわからなかった\n\nruby2.7-slim -> ruby2.7にしたらインストールできたのでいったんそれでも良いかと思ったがよく読んだら\n\n`You have to install development tools first.`ということで次の対応でインストールできるようにした\n\n```diff\n COPY Gemfile Gemfile.lock ./\n ENV BUNDLE_FROZEN=true\n+\n+RUN apt-get update && apt-get install -y \\\n+    build-essential\n```\n\nもっと詳しい中身までは追っていない…\n",
          "timeToRead": 3,
          "objectID": "be05a748-ceea-5021-b4c2-917df2ef41c7",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "current directory: /usr/local/bundle/gems/digest-crc-0.6.1/ext/digest\n/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -I/usr/local/lib/ruby/2.7.0/rubygems -rrubygems\n/usr/local/lib",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "November 07, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "digest-crc gemがインストールできない",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/install_digest_crc_in_docker_image/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nCloudRun Rubyのチュートリアルを進めた後に`google-cloud`のGemを使っていろいろやってみようとインストールして見たら怒られた\n\n- Dockerfile\n\n```dockerfile\nFROM ruby:2.7-slim\n\nWORKDIR /usr/src/app\nCOPY Gemfile Gemfile.lock ./\nENV BUNDLE_FROZEN=true\nRUN gem install bundler && bundle install --without test\n\nCOPY . ./\n\nCMD [\"ruby\", \"./app.rb\"]\n```\n\n- Gemfile\n\n```gemfile\nsource \"https://rubygems.org\"\n\ngem \"google-cloud-storage\"\ngem \"google-cloud-secret_manager\"\ngem \"sinatra\", \"~>2.0\"\n\ngroup :test do\n  gem \"rack-test\"\n  gem \"rest-client\"\n  gem \"rspec\"\n  gem \"rspec_junit_formatter\"\n  gem \"rubysl-securerandom\"\nend\n```\n\n```\nInstalling digest-crc 0.6.1 with native extensions\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /usr/local/bundle/gems/digest-crc-0.6.1/ext/digest\n/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -I/usr/local/lib/ruby/2.7.0/rubygems -rrubygems\n/usr/local/lib/ruby/gems/2.7.0/gems/rake-13.0.1/exe/rake\nRUBYARCHDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\nRUBYLIBDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\n/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -S extconf.rb\nchecking for stdint.h... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/usr/local/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n        --with-stdint-dir\n        --without-stdint-dir\n        --with-stdint-include\n        --without-stdint-include=${stdint-dir}/include\n        --with-stdint-lib\n        --without-stdint-lib=${stdint-dir}/lib\n/usr/local/lib/ruby/2.7.0/mkmf.rb:471:in `try_do': The compiler failed to\ngenerate an executable file. (RuntimeError)\nYou have to install development tools first.\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:613:in `try_cpp'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1124:in `block in have_header'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:971:in `block in checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block (2 levels) in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:357:in `postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:970:in `checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1123:in `have_header'\n        from extconf.rb:3:in `<main>'\nrake aborted!\nCommand failed with status (1): [/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -S extconf.rb...]\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:32:in `block (3\nlevels) in <top (required)>'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `chdir'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `block (2\nlevels) in <top (required)>'\nTasks: TOP => default => crc15/crc15_ext.so => crc15/Makefile\n(See full trace by running task with --trace)\n\nrake failed, exit code 1\n\nGem files will remain installed in /usr/local/bundle/gems/digest-crc-0.6.1 for\ninspection.\nResults logged to\n/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1/gem_make.out\n\nAn error occurred while installing digest-crc (0.6.1), and Bundler cannot\ncontinue.\nMake sure that `gem install digest-crc -v '0.6.1' --source\n'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  google-cloud-storage was resolved to 1.29.1, which depends on\n    digest-crc\nThe command '/__ais-highlight__bi__/ais-highlight__n/sh -c gem install bundler && bundle install --without test' returned a non-zero code: 5\nERROR\nERROR: build step 0 \"gcr.io/cloud-builders/docker\" failed: step exited with non-zero status: 5\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------\n\nERROR: (gcloud.builds.submit) build 57e77985-ae0b-40b7-b0d7-04ce7bcbd099 completed with status \"FAILURE\"\n```\n\nちょっと調べただけだとわからなかった\n\nruby2.7-slim -> ruby2.7にしたらインストールできたのでいったんそれでも良いかと思ったがよく読んだら\n\n`You have to install development tools first.`ということで次の対応でインストールできるようにした\n\n```diff\n COPY Gemfile Gemfile.lock ./\n ENV BUNDLE_FROZEN=true\n+\n+RUN apt-get update && apt-get install -y \\\n+    build-essential\n```\n\nもっと詳しい中身までは追っていない…\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 34,
      "page": 0,
      "nbPages": 2,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "query": "Bi",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&query=Bi&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 9
    },
    {
      "hits": [
        {
          "date": "March 25, 2022",
          "title": "BigQueryの日付を扱う際のメモ",
          "slug": "/entries/bigquery_date_function/",
          "rawMarkdownBody": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
          "timeToRead": 1,
          "objectID": "68f46908-591f-5bb4-82bd-f2fc099406d2",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "March 25, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryの日付を扱う際のメモ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 08, 2021",
          "title": "BigQueryのbq load時にautodetectを使えない場合",
          "slug": "/entries/bigquery_cant_use_autodetect/",
          "rawMarkdownBody": "\nPocketのデータをAPIで取得してBigQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\nBigQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/bigquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、BigQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。BigQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
          "timeToRead": 3,
          "objectID": "511a0a9b-6cec-55d0-a965-148667fcf789",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSON",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 08, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryのbq load時にautodetectを使えない場合",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\n__ais-highlight__Bi__/ais-highlight__gQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、__ais-highlight__Bi__/ais-highlight__gQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。__ais-highlight__Bi__/ais-highlight__gQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "December 09, 2020",
          "title": "BigQueryでサンプルデータをサクッと作る",
          "slug": "/entries/bigquery_sample_data/",
          "rawMarkdownBody": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
          "timeToRead": 1,
          "objectID": "28192504-51b0-5f94-9f12-c62f278c23cc",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "December 09, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryでサンプルデータをサクッと作る",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 21, 2021",
          "title": "BigQueryで日付を扱うときはTimezoneを意識する",
          "slug": "/entries/bigquery_date_timezone/",
          "rawMarkdownBody": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\nBigQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
          "timeToRead": 1,
          "objectID": "1d531f2a-2c16-5859-96ce-a8cf37a230b8",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ータに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 21, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryで日付を扱うときはTimezoneを意識する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 28, 2022",
          "title": "JSONファイルをBigQueryに読ませJSON型で扱うためにそのままCSVで保存する",
          "slug": "/entries/json_to_csv/",
          "rawMarkdownBody": "\n[Working with JSON data in Standard SQL  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/json-data)\n\n先日BigQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
          "timeToRead": 1,
          "objectID": "6ed6b22c-63cc-5fb2-99d6-eeada5709406",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型が",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 28, 2022",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "JSONファイルを__ais-highlight__Bi__/ais-highlight__gQueryに読ませJSON型で扱うためにそのままCSVで保存する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "May 07, 2021",
          "title": "PocketのデータをAPI経由でBigQueryに取り込む",
          "slug": "/entries/start_pocket_api/",
          "rawMarkdownBody": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONをBigQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`bq load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:bqjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and be at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### BigQueryに入れ込む\n\n```\nbq load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
          "timeToRead": 3,
          "objectID": "196c4775-45c9-57b9-a004-cefc6bc4752e",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "てはこの辺\n\n## おまけ\n\nここで得たJSONを__ais-highlight__Bi__/ais-highlight__gQueryに放り込んでよしなにやろうと",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "May 07, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "PocketのデータをAPI経由で__ais-highlight__Bi__/ais-highlight__gQueryに取り込む",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "slug": {
              "value": "/entries/start_pocket_api/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nまず`My Applications`から`CREATE APP`でアプリケーションを作成して`consumer key`を取得する\n\n取得した`consumer key`を環境変数に入れておく\n\n```shell\n$ export CONSUMER_KEY=xxxxx\n```\n\n## request tokenの発行\n\n適当なリダイレクト先を指定してrequest tokenを生成する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\n   https://getpocket.com/v3/oauth/request \\\n   -d @-<<EOS\n{\n  \"consumer_key\" : \"${CONSUMER_KEY}\",\n  \"redirect_uri\":\"http://localhost:8001/\"\n}\nEOS\ncode=xxxxx\n```\n\n結果を環境変数に入れておく\n\n```shell\n$ export REQUEST_TOKEN=xxxxx\n```\n\n## ブラウザへ遷移してアプリケーションのアクセス許可を行う\n\nリダイレクト先は適当に\n\n```shell\nopen \"https://getpocket.com/auth/authorize?request_token=${REQUEST_TOKEN}&redirect_uri=http://localhost:8001/\"\n```\n\n## access tokenの発行\n\n先の手順で得たrequest tokenを用いてaccess tokenの発行する\n\n```shell\n$ curl -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/oauth/authorize \\\n-d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"code\":\"${REQUEST_TOKEN}\"\n}\nEOS\naccess_token=xxxxx&username=hoge\n```\n\n`access_token=`の部分を環境変数に入れておく\n\n```shell\n$ export ACCESS_TOKEN=xxxxx\n```\n\nこれで準備が完了した\n\n## 何かしら問い合わせてみる\n\n記事データを取得してみる\n\n```shell\ncurl -o res.json -H \"Content-Type: application/json; charset=UTF-8\" -X POST \\\nhttps://getpocket.com/v3/get -d @-<<EOS\n{\n  \"consumer_key\":\"${CONSUMER_KEY}\",\n  \"access_token\":\"${ACCESS_TOKEN}\",\n  \"state\":\"unread\",\n  \"detailType\":\"complete\",\n  \"count\":3\n}\nEOS\n```\n\n[Pocket API: Retrieving a User's Pocket Data](https://getpocket.com/developer/docs/v3/retrieve)\n\nretrieveのAPIの仕様についてはこの辺\n\n## おまけ\n\nここで得たJSONを__ais-highlight__Bi__/ais-highlight__gQueryに放り込んでよしなにやろうとしたが一筋縄では行かなかった\n\n次のエラーはレスポンスのJSONファイルをそのままGCSにあげて`bq load`しようとした結果\n\n```\nError in query string: Error processing job 'project-111111:bqjob_r75b06933ac2f4481_0000017942c36b05_1': Invalid field name \"3292257344\". Fields must contain only letters, numbers, and\nunderscores, start with a letter or underscore, and be at most 300 characters long. Table: sample_8bb5a901_3d95_41f4_9512_e7f4fad8a737_source\n```\n\nエラー文言自体は`文字またはアンダースコアで始まり`の部分に違反しているのでエラーがでているがそもそもこのキーがIDなので記事によって可変であるためスキーマ定義ができない\n\njson形式が微妙すぎるのでどうしてもフォーマットしてあげないとダメそう\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": {\n    \"3324677936\": {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    \"3324677937\": {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n```\n\nこんな感じで数値キーのハッシュとして出力されている\n\n配列で表現してほしかった…\n\nということで数値キーになっている要素を数値キーを削除した形で保持させる\n\n```json\n{\n  \"status\": 1,\n  \"complete\": 0,\n  \"list\": [\n    {\n      \"item_id\": \"3324677936\",\n      \"resolved_id\": \"3324677936\",\n      .....\n    },\n    {\n      \"item_id\": \"3324677937\",\n      \"resolved_id\": \"3324677937\",\n      .....\n    },\n    .....\n  ]\n```\n\nこんな感じ\n\n中身を見た感じ`.list`以外にも同様の形式だったのでそちらも同様に配列に変更する必要がある\n\n### ハッシュ→配列にする必要がある要素\n\n執筆時点で把握しているのは下記\n\n- .list\n- .list.images\n- .list.videos\n- .list.authors\n\n### jqでよしなにやる\n\n```\ncat res.json| jq  -cr '.list=(.list|to_entries|map(.value)|map(.images=if has(\"images\") then .images|to_entries|map(.value) else [] end)|map(.videos=if has(\"videos\") then .videos|to_entries|map(.value) else [] end)|map(.authors=if has(\"authors\") then .authors|to_entries|map(.value) else [] end))' > list.json\n```\n\nキー自体がそもそもない場合もあったのでその場合は空配列にする\n\n### __ais-highlight__Bi__/ais-highlight__gQueryに入れ込む\n\n```\nbq load --replace --autodetect --source_format=NEWLINE_DELIMITED_JSON sample_dataset.sample list.json\n```\n\nこれでOK",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 13, 2021",
          "title": "Workflowsで Memory usage limit exeeded",
          "slug": "/entries/workflows_logging_bigquery_failed/",
          "rawMarkdownBody": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのままBigQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクでBigQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+BigQueryへloadってパターンがベターなのかな",
          "timeToRead": 2,
          "objectID": "18e04e5f-00f2-50a2-a8d7-b7ac41718457",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "たいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 13, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Workflowsで Memory usage limit exeeded",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/workflows_logging___ais-highlight__bi__/ais-highlight__gquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "rawMarkdownBody": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクで__ais-highlight__Bi__/ais-highlight__gQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+__ais-highlight__Bi__/ais-highlight__gQueryへloadってパターンがベターなのかな",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 10, 2021",
          "title": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
          "slug": "/entries/dataportal_experience_date/",
          "rawMarkdownBody": "\nただのメモ\n\nTogglからBigQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
          "timeToRead": 2,
          "objectID": "17cb94a3-6fe4-5894-bec2-e090afbbdb8d",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 10, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/dataportal_experience_date/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 13, 2021",
          "title": "tfenvを使いTerraformのバージョンを切り替える",
          "slug": "/entries/tfenv/",
          "rawMarkdownBody": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/bin\n$ ln -s ~/.tfenv/bin/* ~/.local/bin\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/bin:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
          "timeToRead": 1,
          "objectID": "4c8c0fb8-2bb1-575a-94a8-c7637ce72ecb",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 13, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "tfenvを使いTerraformのバージョンを切り替える",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/tfenv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 15, 2020",
          "title": "CentOS7系でのrmagickのインストール",
          "slug": "/entries/ruby_rmagick_install/",
          "rawMarkdownBody": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
          "timeToRead": 3,
          "objectID": "4ff80e3f-7590-50b7-a068-4370fb8d098a",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 15, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "CentOS7系でのrmagickのインストール",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ruby_rmagick_install/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 18, 2020",
          "title": "S3利用料をバケット毎に詳細に出すための情報",
          "slug": "/entries/s3_price_per_bucket/",
          "rawMarkdownBody": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/billing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
          "timeToRead": 2,
          "objectID": "3c9d8e94-ccb4-5473-83bf-8e8f5a0204bd",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サー",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 18, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "S3利用料をバケット毎に詳細に出すための情報",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/s3_price_per_bucket/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "November 30, 2021",
          "title": "VS Codeのターミナルプロファイル設定",
          "slug": "/entries/vscode_terminal_profile/",
          "rawMarkdownBody": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/bin/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
          "timeToRead": 1,
          "objectID": "203c16a1-d621-565f-9467-d727d12f04b8",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultで",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "November 30, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VS Codeのターミナルプロファイル設定",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vscode_terminal_profile/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "September 05, 2021",
          "title": "Lambdaのソースコード差分を取得する",
          "slug": "/entries/lambda_diff/",
          "rawMarkdownBody": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/bin/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/bin/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
          "timeToRead": 1,
          "objectID": "4365a1dd-799e-546c-8c05-d2cac5c7bbe0",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "とで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "September 05, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Lambdaのソースコード差分を取得する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/lambda_diff/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "October 15, 2020",
          "title": "AnsibleでAWS CLI v2をインストールする",
          "slug": "/entries/ansible_install_awscliv2/",
          "rawMarkdownBody": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
          "timeToRead": 2,
          "objectID": "99e28ca7-2980-59fe-996e-ff500f2f3ee3",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "October 15, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "AnsibleでAWS CLI v2をインストールする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ansible_install_awscliv2/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 14, 2020",
          "title": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
          "slug": "/entries/docker_host/",
          "rawMarkdownBody": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/bin/dockerd -H unix://\n+ ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
          "timeToRead": 1,
          "objectID": "82e9a7ed-566d-569c-99ef-7215b036a725",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 14, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/docker_host/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "July 19, 2021",
          "title": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
          "slug": "/entries/introduction_jest_and_testing_library_to_gatsby/",
          "rawMarkdownBody": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 ms)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
          "timeToRead": 2,
          "objectID": "26e74846-3144-508a-bb2e-b72e781ffdf7",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "July 19, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "April 27, 2021",
          "title": "WSL2でDockerForWindowsのコマンドを叩く",
          "slug": "/entries/wsl_docker_for_windows/",
          "rawMarkdownBody": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/bin/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker\n\n```bash\n#!/usr/bin/env sh\nbinary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port binding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
          "timeToRead": 2,
          "objectID": "a8956213-b2d5-5b19-886e-3030ada5bd23",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "で決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "April 27, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "WSL2でDockerForWindowsのコマンドを叩く",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/wsl_docker_for_windows/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port __ais-highlight__bi__/ais-highlight__nding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "October 14, 2021",
          "title": "VS Code Remote WSLが起動しない",
          "slug": "/entries/vscode_wsl_failed/",
          "rawMarkdownBody": "\nPCをセットアップし直してWSLも入れ直していざVS Codeを起動したらWSLに接続できなかった\n\n- エラーログ\n\n```\n[2021-10-08 17:49:31.526] Resolving wsl+Ubuntu, resolveAttempt: 1\n[2021-10-08 17:49:31.649] Starting VS Code Server inside WSL (Ubuntu)\n[2021-10-08 17:49:31.649] Extension version: 0.58.2, Windows build: 19041. Multi distro support: available. WSL path support: enabled\n[2021-10-08 17:49:31.650] No shell environment set or found for current distro.\n[2021-10-08 17:49:31.887] Probing if server is already installed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/bin/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] Unable to detect if server is already installed: Error: Command failed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/bin/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] 指定されたファイルが見つかりません。\n[2021-10-08 17:49:32.000] \n[2021-10-08 17:49:32.001] Launching C:\\Windows\\System32\\wsl.exe -d Ubuntu sh -c '\"$VSCODE_WSL_EXT_LOCATION/scripts/wslServer.sh\" 69755771804a4f5097277cbbb50dff67 stable .vscode-server 0  '}\n[2021-10-08 17:49:32.080] \n[2021-10-08 17:49:32.081] VS Code Server for WSL closed unexpectedly.\n[2021-10-08 17:49:32.082] For help with startup problems, go to\n[2021-10-08 17:49:32.082] https://code.visualstudio.com/docs/remote/troubleshooting#_wsl-tips\n[2021-10-08 17:49:32.102] WSL Daemon exited with code 0\n```\n\n<!-- textlint-disable prh -->\n一部文字化けしていたので該当箇所は削除した\n<!-- textlint-enable prh -->\n\n使用しているWSLのディストリビューションがデフォルトでなくなってしまっていた模様\n\n[Developing in the Windows Subsystem for Linux with Visual Studio Code](https://code.visualstudio.com/docs/remote/wsl#_why-am-i-asked-to-change-the-default-distro)\n\n現在使っているのは`Ubuntu-20.04`\n\n確認してみる\n\n```shell\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu (既定)\ndocker-desktop\nUbuntu-20.04\ndocker-desktop-data\n\n> wslconfig /setdefault Ubuntu-20.04\n\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu-20.04 (既定)\nUbuntu\ndocker-desktop\ndocker-desktop-data\n```\n\n`Ubuntu`のディストリビューションはPC移行以前に使っていたが新しいPCにWSLのデータを移行できなかったので起動できなかったと推測できる\n\nVS CodeのRemote WSLではデフォルトのディストリビューションに接続する仕様なのでホスト側でデフォルトのWSLのディストリビューションを決めてあげる必要がある\n\n無事VS CodeでRemoteWSL拡張が使えるようになった",
          "timeToRead": 2,
          "objectID": "0ef6d022-c0b5-58c5-819b-9768bd9396b0",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "already installed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/__ais-highlight__bi__/ais-highlight__n/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "October 14, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VS Code Remote WSLが起動しない",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vscode_wsl_failed/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nPCをセットアップし直してWSLも入れ直していざVS Codeを起動したらWSLに接続できなかった\n\n- エラーログ\n\n```\n[2021-10-08 17:49:31.526] Resolving wsl+Ubuntu, resolveAttempt: 1\n[2021-10-08 17:49:31.649] Starting VS Code Server inside WSL (Ubuntu)\n[2021-10-08 17:49:31.649] Extension version: 0.58.2, Windows build: 19041. Multi distro support: available. WSL path support: enabled\n[2021-10-08 17:49:31.650] No shell environment set or found for current distro.\n[2021-10-08 17:49:31.887] Probing if server is already installed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/__ais-highlight__bi__/ais-highlight__n/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] Unable to detect if server is already installed: Error: Command failed: C:\\Windows\\System32\\wsl.exe -d Ubuntu -e sh -c \"[ -d ~/.vscode-server/__ais-highlight__bi__/ais-highlight__n/69755771804a4f5097277cbbb50dff67 ] && printf found || ([ -f /etc/alpine-release ] && printf alpine-; uname -m)\"\n[2021-10-08 17:49:32.000] 指定されたファイルが見つかりません。\n[2021-10-08 17:49:32.000] \n[2021-10-08 17:49:32.001] Launching C:\\Windows\\System32\\wsl.exe -d Ubuntu sh -c '\"$VSCODE_WSL_EXT_LOCATION/scripts/wslServer.sh\" 69755771804a4f5097277cbbb50dff67 stable .vscode-server 0  '}\n[2021-10-08 17:49:32.080] \n[2021-10-08 17:49:32.081] VS Code Server for WSL closed unexpectedly.\n[2021-10-08 17:49:32.082] For help with startup problems, go to\n[2021-10-08 17:49:32.082] https://code.visualstudio.com/docs/remote/troubleshooting#_wsl-tips\n[2021-10-08 17:49:32.102] WSL Daemon exited with code 0\n```\n\n<!-- textlint-disable prh -->\n一部文字化けしていたので該当箇所は削除した\n<!-- textlint-enable prh -->\n\n使用しているWSLのディストリビューションがデフォルトでなくなってしまっていた模様\n\n[Developing in the Windows Subsystem for Linux with Visual Studio Code](https://code.visualstudio.com/docs/remote/wsl#_why-am-i-asked-to-change-the-default-distro)\n\n現在使っているのは`Ubuntu-20.04`\n\n確認してみる\n\n```shell\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu (既定)\ndocker-desktop\nUbuntu-20.04\ndocker-desktop-data\n\n> wslconfig /setdefault Ubuntu-20.04\n\n> wslconfig /l\nLinux 用 Windows サブシステム ディストリビューション:\nUbuntu-20.04 (既定)\nUbuntu\ndocker-desktop\ndocker-desktop-data\n```\n\n`Ubuntu`のディストリビューションはPC移行以前に使っていたが新しいPCにWSLのデータを移行できなかったので起動できなかったと推測できる\n\nVS CodeのRemote WSLではデフォルトのディストリビューションに接続する仕様なのでホスト側でデフォルトのWSLのディストリビューションを決めてあげる必要がある\n\n無事VS CodeでRemoteWSL拡張が使えるようになった",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "February 17, 2021",
          "title": "WSL2に移行した",
          "slug": "/entries/wsl2_installed/",
          "rawMarkdownBody": "\n下記参考にWSL→WSL2へ移行した際の記録\n\n[Windows Subsystem for Linux (WSL) を Windows 10 にインストールする | Microsoft Docs](https://docs.microsoft.com/ja-jp/windows/wsl/install-win10)\n\n上記を参考に各種設定を行い次のコマンドを打ったが何も変わらず…\n\n```\n$ wsl --set-version Ubuntu 2\n変換中です。この処理には数分かかることがあります...\nWSL 2 との主な違いについては、https://aka.ms/wsl2 を参照してください\nWindows の仮想マシン プラットフォーム機能を有効にして、BIOS で仮想化が有効になっていることを確認してください。\n詳細については、https://aka.ms/wsl2-install を参照してください\n```\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         1\n```\n\nBIOSでの確認もしてみたが仮想化機能も有効になっていそう…\n\n何度か一連の手順を踏んでみたが変わらず\n\n最終的にはDockerForWindowsを入れてそちらの方で「仮想化機能をEnableにする」ダイアログをクリックして再起動したらWSL2側も使えるようになった\n\n<!-- textlint-disable ja-hiragana-fukushi -->\nというか仮想化機能自体が「Windowsの機能の有効化または無効化」の設定やPowershellのコマンドからだと正しくONにできなかったように見える\n<!-- textlint-enable ja-hiragana-fukushi -->\n\nもしくはほかにも設定変更をするべき項目が存在したか…\n\n正直良くわからないが無事にWSL2+Dockerを使えるようになった\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n```\n\n`docker-desktop`も出力されるよう\n\n以前から使っていたVagrant+VirtualBox（v6.1.16）のVMも問題なく起動して動かせたので良き\n\n今までDockerを使うリポジトリは全部VMの中で開発していたがこれでWSL側でも開発できる",
          "timeToRead": 1,
          "objectID": "2fed46ed-ffd0-5e59-849a-adee22132af0",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "ラットフォーム機能を有効にして、__ais-highlight__BI__/ais-highlight__OS で仮想化が有効になっているこ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "February 17, 2021",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "WSL2に移行した",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/wsl2_installed/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\n下記参考にWSL→WSL2へ移行した際の記録\n\n[Windows Subsystem for Linux (WSL) を Windows 10 にインストールする | Microsoft Docs](https://docs.microsoft.com/ja-jp/windows/wsl/install-win10)\n\n上記を参考に各種設定を行い次のコマンドを打ったが何も変わらず…\n\n```\n$ wsl --set-version Ubuntu 2\n変換中です。この処理には数分かかることがあります...\nWSL 2 との主な違いについては、https://aka.ms/wsl2 を参照してください\nWindows の仮想マシン プラットフォーム機能を有効にして、__ais-highlight__BI__/ais-highlight__OS で仮想化が有効になっていることを確認してください。\n詳細については、https://aka.ms/wsl2-install を参照してください\n```\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         1\n```\n\n__ais-highlight__BI__/ais-highlight__OSでの確認もしてみたが仮想化機能も有効になっていそう…\n\n何度か一連の手順を踏んでみたが変わらず\n\n最終的にはDockerForWindowsを入れてそちらの方で「仮想化機能をEnableにする」ダイアログをクリックして再起動したらWSL2側も使えるようになった\n\n<!-- textlint-disable ja-hiragana-fukushi -->\nというか仮想化機能自体が「Windowsの機能の有効化または無効化」の設定やPowershellのコマンドからだと正しくONにできなかったように見える\n<!-- textlint-enable ja-hiragana-fukushi -->\n\nもしくはほかにも設定変更をするべき項目が存在したか…\n\n正直良くわからないが無事にWSL2+Dockerを使えるようになった\n\n```\n$ wsl --list --verbose\n  NAME                   STATE           VERSION\n* Ubuntu                 Running         2\n  docker-desktop         Running         2\n  docker-desktop-data    Running         2\n```\n\n`docker-desktop`も出力されるよう\n\n以前から使っていたVagrant+VirtualBox（v6.1.16）のVMも問題なく起動して動かせたので良き\n\n今までDockerを使うリポジトリは全部VMの中で開発していたがこれでWSL側でも開発できる",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "date": "November 07, 2020",
          "title": "digest-crc gemがインストールできない",
          "slug": "/entries/install_digest_crc_in_docker_image/",
          "rawMarkdownBody": "\nCloudRun Rubyのチュートリアルを進めた後に`google-cloud`のGemを使っていろいろやってみようとインストールして見たら怒られた\n\n- Dockerfile\n\n```dockerfile\nFROM ruby:2.7-slim\n\nWORKDIR /usr/src/app\nCOPY Gemfile Gemfile.lock ./\nENV BUNDLE_FROZEN=true\nRUN gem install bundler && bundle install --without test\n\nCOPY . ./\n\nCMD [\"ruby\", \"./app.rb\"]\n```\n\n- Gemfile\n\n```gemfile\nsource \"https://rubygems.org\"\n\ngem \"google-cloud-storage\"\ngem \"google-cloud-secret_manager\"\ngem \"sinatra\", \"~>2.0\"\n\ngroup :test do\n  gem \"rack-test\"\n  gem \"rest-client\"\n  gem \"rspec\"\n  gem \"rspec_junit_formatter\"\n  gem \"rubysl-securerandom\"\nend\n```\n\n```\nInstalling digest-crc 0.6.1 with native extensions\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /usr/local/bundle/gems/digest-crc-0.6.1/ext/digest\n/usr/local/bin/ruby -I/usr/local/lib/ruby/2.7.0/rubygems -rrubygems\n/usr/local/lib/ruby/gems/2.7.0/gems/rake-13.0.1/exe/rake\nRUBYARCHDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\nRUBYLIBDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\n/usr/local/bin/ruby -S extconf.rb\nchecking for stdint.h... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/usr/local/bin/$(RUBY_BASE_NAME)\n        --with-stdint-dir\n        --without-stdint-dir\n        --with-stdint-include\n        --without-stdint-include=${stdint-dir}/include\n        --with-stdint-lib\n        --without-stdint-lib=${stdint-dir}/lib\n/usr/local/lib/ruby/2.7.0/mkmf.rb:471:in `try_do': The compiler failed to\ngenerate an executable file. (RuntimeError)\nYou have to install development tools first.\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:613:in `try_cpp'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1124:in `block in have_header'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:971:in `block in checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block (2 levels) in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:357:in `postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:970:in `checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1123:in `have_header'\n        from extconf.rb:3:in `<main>'\nrake aborted!\nCommand failed with status (1): [/usr/local/bin/ruby -S extconf.rb...]\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:32:in `block (3\nlevels) in <top (required)>'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `chdir'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `block (2\nlevels) in <top (required)>'\nTasks: TOP => default => crc15/crc15_ext.so => crc15/Makefile\n(See full trace by running task with --trace)\n\nrake failed, exit code 1\n\nGem files will remain installed in /usr/local/bundle/gems/digest-crc-0.6.1 for\ninspection.\nResults logged to\n/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1/gem_make.out\n\nAn error occurred while installing digest-crc (0.6.1), and Bundler cannot\ncontinue.\nMake sure that `gem install digest-crc -v '0.6.1' --source\n'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  google-cloud-storage was resolved to 1.29.1, which depends on\n    digest-crc\nThe command '/bin/sh -c gem install bundler && bundle install --without test' returned a non-zero code: 5\nERROR\nERROR: build step 0 \"gcr.io/cloud-builders/docker\" failed: step exited with non-zero status: 5\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------\n\nERROR: (gcloud.builds.submit) build 57e77985-ae0b-40b7-b0d7-04ce7bcbd099 completed with status \"FAILURE\"\n```\n\nちょっと調べただけだとわからなかった\n\nruby2.7-slim -> ruby2.7にしたらインストールできたのでいったんそれでも良いかと思ったがよく読んだら\n\n`You have to install development tools first.`ということで次の対応でインストールできるようにした\n\n```diff\n COPY Gemfile Gemfile.lock ./\n ENV BUNDLE_FROZEN=true\n+\n+RUN apt-get update && apt-get install -y \\\n+    build-essential\n```\n\nもっと詳しい中身までは追っていない…\n",
          "timeToRead": 3,
          "objectID": "be05a748-ceea-5021-b4c2-917df2ef41c7",
          "_snippetResult": {
            "rawMarkdownBody": {
              "value": "current directory: /usr/local/bundle/gems/digest-crc-0.6.1/ext/digest\n/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -I/usr/local/lib/ruby/2.7.0/rubygems -rrubygems\n/usr/local/lib",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "date": {
              "value": "November 07, 2020",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "digest-crc gemがインストールできない",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/install_digest_crc_in_docker_image/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "rawMarkdownBody": {
              "value": "\nCloudRun Rubyのチュートリアルを進めた後に`google-cloud`のGemを使っていろいろやってみようとインストールして見たら怒られた\n\n- Dockerfile\n\n```dockerfile\nFROM ruby:2.7-slim\n\nWORKDIR /usr/src/app\nCOPY Gemfile Gemfile.lock ./\nENV BUNDLE_FROZEN=true\nRUN gem install bundler && bundle install --without test\n\nCOPY . ./\n\nCMD [\"ruby\", \"./app.rb\"]\n```\n\n- Gemfile\n\n```gemfile\nsource \"https://rubygems.org\"\n\ngem \"google-cloud-storage\"\ngem \"google-cloud-secret_manager\"\ngem \"sinatra\", \"~>2.0\"\n\ngroup :test do\n  gem \"rack-test\"\n  gem \"rest-client\"\n  gem \"rspec\"\n  gem \"rspec_junit_formatter\"\n  gem \"rubysl-securerandom\"\nend\n```\n\n```\nInstalling digest-crc 0.6.1 with native extensions\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /usr/local/bundle/gems/digest-crc-0.6.1/ext/digest\n/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -I/usr/local/lib/ruby/2.7.0/rubygems -rrubygems\n/usr/local/lib/ruby/gems/2.7.0/gems/rake-13.0.1/exe/rake\nRUBYARCHDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\nRUBYLIBDIR\\=/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1\n/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -S extconf.rb\nchecking for stdint.h... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/usr/local/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n        --with-stdint-dir\n        --without-stdint-dir\n        --with-stdint-include\n        --without-stdint-include=${stdint-dir}/include\n        --with-stdint-lib\n        --without-stdint-lib=${stdint-dir}/lib\n/usr/local/lib/ruby/2.7.0/mkmf.rb:471:in `try_do': The compiler failed to\ngenerate an executable file. (RuntimeError)\nYou have to install development tools first.\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:613:in `try_cpp'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1124:in `block in have_header'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:971:in `block in checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block (2 levels) in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:361:in `block in postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:331:in `open'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:357:in `postpone'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:970:in `checking_for'\n        from /usr/local/lib/ruby/2.7.0/mkmf.rb:1123:in `have_header'\n        from extconf.rb:3:in `<main>'\nrake aborted!\nCommand failed with status (1): [/usr/local/__ais-highlight__bi__/ais-highlight__n/ruby -S extconf.rb...]\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:32:in `block (3\nlevels) in <top (required)>'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `chdir'\n/usr/local/bundle/gems/digest-crc-0.6.1/ext/digest/Rakefile:31:in `block (2\nlevels) in <top (required)>'\nTasks: TOP => default => crc15/crc15_ext.so => crc15/Makefile\n(See full trace by running task with --trace)\n\nrake failed, exit code 1\n\nGem files will remain installed in /usr/local/bundle/gems/digest-crc-0.6.1 for\ninspection.\nResults logged to\n/usr/local/bundle/extensions/x86_64-linux/2.7.0/digest-crc-0.6.1/gem_make.out\n\nAn error occurred while installing digest-crc (0.6.1), and Bundler cannot\ncontinue.\nMake sure that `gem install digest-crc -v '0.6.1' --source\n'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  google-cloud-storage was resolved to 1.29.1, which depends on\n    digest-crc\nThe command '/__ais-highlight__bi__/ais-highlight__n/sh -c gem install bundler && bundle install --without test' returned a non-zero code: 5\nERROR\nERROR: build step 0 \"gcr.io/cloud-builders/docker\" failed: step exited with non-zero status: 5\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------\n\nERROR: (gcloud.builds.submit) build 57e77985-ae0b-40b7-b0d7-04ce7bcbd099 completed with status \"FAILURE\"\n```\n\nちょっと調べただけだとわからなかった\n\nruby2.7-slim -> ruby2.7にしたらインストールできたのでいったんそれでも良いかと思ったがよく読んだら\n\n`You have to install development tools first.`ということで次の対応でインストールできるようにした\n\n```diff\n COPY Gemfile Gemfile.lock ./\n ENV BUNDLE_FROZEN=true\n+\n+RUN apt-get update && apt-get install -y \\\n+    build-essential\n```\n\nもっと詳しい中身までは追っていない…\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 34,
      "page": 0,
      "nbPages": 2,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "query": "Bi",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&query=Bi&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 9
    }
  ]
}
