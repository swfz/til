{
  "results": [
    {
      "hits": [
        {
          "url": "https://til.swfz.io//entries/bigquery_sa_permission_from_cli/",
          "text": "\n特定のデータセット、特定サービスアカウントにREADやWRITE権限を与える\n\n`bq show`で対象データセットの設定を出力、中身の`access`に対象サービスアカウントのメールアドレスをと権限を追加して`bq update`\n\n```shell\nbq show --format=prettyjson memo-111111:sample  > sample.json\n```\n\n- sample.json\n\n```json\n\"access\": [\n  ...\n  ...\n  ...\n    {\n      \"role\": \"READER\",\n      \"userByEmail\": \"github-actions-sample-nokey@memo-111111.iam.gserviceaccount.com\"\n    }\n]\n```\n\n```shell\nbq update --source sample.json sample\n```\n\n## 確認\n\n対象サービスアカウントで実行した\n\n- bq ls\n\n```txt\n  datasetId  \n ----------- \n  sample     \n```\n\n- クエリ\n\n```shell\nbq query --nouse_legacy_sql 'select * from sample.summary'\n```\n\n```\n+------+-------+----+\n| view | title | id |\n+------+-------+----+\n|    3 | fuga  |  2 |\n|    3 | foo   |  4 |\n|    4 | piyo  |  3 |\n|    5 | hoge  |  1 |\n|    5 | bar   |  5 |\n+------+-------+----+\n```\n\nできた\n\n最近GitHubActionsのOIDC認証でCI用のサービスアカウントに対してクエリできるようにする + データセット単位で権限を絞るところまで行ったのでメモ\n\n個人使用ならこれで問題ないかなーという感じ",
          "date": "2022-10-12",
          "title": "BigQueryで特定データセットに権限を付与する",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "bq show + bq update",
          "slug": "/entries/bigquery_sa_permission_from_cli/",
          "timeToRead": 1,
          "objectID": "dafae263-fb55-5d08-bf9f-17c62c276690",
          "_snippetResult": {
            "text": {
              "value": "\n特定のデータセット、特定サービスアカウントにREADやWRITE権限を与える\n\n`bq show`で対象データセットの設定を出力、中身",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_sa_permission_from_cli/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\n特定のデータセット、特定サービスアカウントにREADやWRITE権限を与える\n\n`bq show`で対象データセットの設定を出力、中身の`access`に対象サービスアカウントのメールアドレスをと権限を追加して`bq update`\n\n```shell\nbq show --format=prettyjson memo-111111:sample  > sample.json\n```\n\n- sample.json\n\n```json\n\"access\": [\n  ...\n  ...\n  ...\n    {\n      \"role\": \"READER\",\n      \"userByEmail\": \"github-actions-sample-nokey@memo-111111.iam.gserviceaccount.com\"\n    }\n]\n```\n\n```shell\nbq update --source sample.json sample\n```\n\n## 確認\n\n対象サービスアカウントで実行した\n\n- bq ls\n\n```txt\n  datasetId  \n ----------- \n  sample     \n```\n\n- クエリ\n\n```shell\nbq query --nouse_legacy_sql 'select * from sample.summary'\n```\n\n```\n+------+-------+----+\n| view | title | id |\n+------+-------+----+\n|    3 | fuga  |  2 |\n|    3 | foo   |  4 |\n|    4 | piyo  |  3 |\n|    5 | hoge  |  1 |\n|    5 | bar   |  5 |\n+------+-------+----+\n```\n\nできた\n\n最近GitHubActionsのOIDC認証でCI用のサービスアカウントに対してクエリできるようにする + データセット単位で権限を絞るところまで行ったのでメモ\n\n個人使用ならこれで問題ないかなーという感じ",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2022-10-12",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryで特定データセットに権限を付与する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "bq show + bq update",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_sa_permission_from_cli/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_empty_string_array/",
          "text": "\n[配列関数  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/array_functions?hl=ja)\n\nGENERATE_ARRAYで作るとINT64の空配列になってしまう\n\n```sql\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\nUNIONなどで文字列の配列と結合させようとすると型が合わなくなってしまう\n\n## 例\n\n```sql\nSELECT ['a','b'] AS tags\nUNION ALL\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\n- 結果\n\n```\n Column 1 in UNION ALL has incompatible types: ARRAY<STRING>, ARRAY<INT64> at [3:1] \n```\n\n[Create empty string array BigQuery - Stack Overflow](https://stackoverflow.com/questions/58504188/create-empty-string-array-bigquery)\n\nこまったときのstackoverflow、答えが書いてありました\n\n```sql\nSELECT ARRAY<STRING>[] AS tags\n```\n\nでSTRINGの空配列を生成できる\n\n解決！\n",
          "date": "2022-07-22",
          "title": "BigQueryでStringの空配列を生成する",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "ARRAY",
          "slug": "/entries/bigquery_empty_string_array/",
          "timeToRead": 1,
          "objectID": "94f95f4a-5e85-5917-a74f-84500c7a5783",
          "_snippetResult": {
            "text": {
              "value": "\n[配列関数  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/array_functions?hl=ja)\n\nGENERATE_ARRAYで作るとINT64の空配列になってしまう\n\n```sql\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\nUNIONな",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_empty_string_array/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\n[配列関数  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/array_functions?hl=ja)\n\nGENERATE_ARRAYで作るとINT64の空配列になってしまう\n\n```sql\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\nUNIONなどで文字列の配列と結合させようとすると型が合わなくなってしまう\n\n## 例\n\n```sql\nSELECT ['a','b'] AS tags\nUNION ALL\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\n- 結果\n\n```\n Column 1 in UNION ALL has incompatible types: ARRAY<STRING>, ARRAY<INT64> at [3:1] \n```\n\n[Create empty string array __ais-highlight__Bi__/ais-highlight__gQuery - Stack Overflow](https://stackoverflow.com/questions/58504188/create-empty-string-array-__ais-highlight__bi__/ais-highlight__gquery)\n\nこまったときのstackoverflow、答えが書いてありました\n\n```sql\nSELECT ARRAY<STRING>[] AS tags\n```\n\nでSTRINGの空配列を生成できる\n\n解決！\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-07-22",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryでStringの空配列を生成する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "ARRAY",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_empty_string_array/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_cant_use_autodetect/",
          "text": "\nPocketのデータをAPIで取得してBigQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\nBigQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/bigquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、BigQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。BigQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
          "date": "2021-05-08",
          "title": "BigQueryのbq load時にautodetectを使えない場合",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "データにばらつきがありautodetectが使えないパターン",
          "slug": "/entries/bigquery_cant_use_autodetect/",
          "timeToRead": 3,
          "objectID": "6c49c87d-a92d-51b8-863d-7251544ccc40",
          "_snippetResult": {
            "text": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようと",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\n__ais-highlight__Bi__/ais-highlight__gQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、__ais-highlight__Bi__/ais-highlight__gQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。__ais-highlight__Bi__/ais-highlight__gQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-05-08",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryのbq load時にautodetectを使えない場合",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "データにばらつきがありautodetectが使えないパターン",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_date_function/",
          "text": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
          "date": "2022-03-25",
          "title": "BigQueryの日付を扱う際のメモ",
          "tags": ["BigQuery", "GoogleCloudPlatform", "SQL"],
          "description": "スニペット的なやつ",
          "slug": "/entries/bigquery_date_function/",
          "timeToRead": 1,
          "objectID": "6539d73b-40f3-50ab-8340-44ae50b6b75b",
          "_snippetResult": {
            "text": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2022-03-25",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryの日付を扱う際のメモ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "SQL", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "スニペット的なやつ",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_sample_data/",
          "text": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
          "date": "2020-12-09",
          "title": "BigQueryでサンプルデータをサクッと作る",
          "tags": ["BigQuery", "SQL"],
          "description": "WITH,UNNEST,ARRAY,STRUCTでやる",
          "slug": "/entries/bigquery_sample_data/",
          "timeToRead": 1,
          "objectID": "095f8841-166b-5319-8f30-c135a7d6b56b",
          "_snippetResult": {
            "text": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2020-12-09",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryでサンプルデータをサクッと作る",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              { "value": "SQL", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "WITH,UNNEST,ARRAY,STRUCTでやる",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_date_timezone/",
          "text": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\nBigQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
          "date": "2021-04-21",
          "title": "BigQueryで日付を扱うときはTimezoneを意識する",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "基本はUTCですねという話",
          "slug": "/entries/bigquery_date_timezone/",
          "timeToRead": 1,
          "objectID": "02883dc4-e742-5435-892c-a78e335fdde5",
          "_snippetResult": {
            "text": {
              "value": "ムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-04-21",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryで日付を扱うときはTimezoneを意識する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "基本はUTCですねという話",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/workflows_logging_bigquery_failed/",
          "text": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのままBigQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクでBigQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+BigQueryへloadってパターンがベターなのかな",
          "date": "2021-07-13",
          "title": "Workflowsで Memory usage limit exeeded",
          "tags": ["Workflows", "GoogleCloudPlatform"],
          "description": "失敗記録",
          "slug": "/entries/workflows_logging_bigquery_failed/",
          "timeToRead": 2,
          "objectID": "ac419206-6eea-559a-82a6-992344e0e64d",
          "_snippetResult": {
            "text": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライベート",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/workflows_logging___ais-highlight__bi__/ais-highlight__gquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクで__ais-highlight__Bi__/ais-highlight__gQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+__ais-highlight__Bi__/ais-highlight__gQueryへloadってパターンがベターなのかな",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-07-13",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Workflowsで Memory usage limit exeeded",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "Workflows",
                "matchLevel": "none",
                "matchedWords": []
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "失敗記録",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/workflows_logging___ais-highlight__bi__/ais-highlight__gquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/json_to_csv/",
          "text": "\n[Working with JSON data in Standard SQL  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/json-data)\n\n先日BigQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
          "date": "2022-02-28",
          "title": "JSONファイルをBigQueryに読ませJSON型で扱うためにそのままCSVで保存する",
          "tags": ["jq", "BigQuery", "GoogleCloudPlatform"],
          "description": "jq",
          "slug": "/entries/json_to_csv/",
          "timeToRead": 1,
          "objectID": "2e780a6a-d216-545c-8eb0-c5db3e4301ef",
          "_snippetResult": {
            "text": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではload",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-02-28",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "JSONファイルを__ais-highlight__Bi__/ais-highlight__gQueryに読ませJSON型で扱うためにそのままCSVで保存する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              { "value": "jq", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "jq",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/dataportal_experience_date/",
          "text": "\nただのメモ\n\nTogglからBigQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
          "date": "2021-04-10",
          "title": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
          "tags": ["GoogleCloudPlatform", "DataPortal"],
          "description": "if + parse_datetime + format_datetime",
          "slug": "/entries/dataportal_experience_date/",
          "timeToRead": 2,
          "objectID": "12505894-0414-5e44-8176-e3373bf7591f",
          "_snippetResult": {
            "text": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測し",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/dataportal_experience_date/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-04-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              },
              {
                "value": "DataPortal",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "if + parse_datetime + format_datetime",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/dataportal_experience_date/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/zx_arguments/",
          "text": "\n```shell\nzx query.mjs hoge\n[\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/bin/node',\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/bin/zx',\n  'query.mjs',\n  'hoge'\n]\n```\n\n普通のnodeスクリプトだと`process.argv.slice(2)`でコマンドライン引数のリストを取得するが、zxの場合には`process.argv.slice(3)`になる\n",
          "date": "2022-06-21",
          "title": "zx使用時のコマンドライン引数のリスト",
          "tags": ["zx", "JavaScript"],
          "description": "process.argv",
          "slug": "/entries/zx_arguments/",
          "timeToRead": 1,
          "objectID": "cc6ab13d-d6cc-59dc-9f9c-047b85a1f480",
          "_snippetResult": {
            "text": {
              "value": "\n```shell\nzx query.mjs hoge\n[\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/node',\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/zx',\n  'query.mjs',\n  'hoge'\n]\n```\n\n普通のnodeスクリプトだと`process.argv.slice(2)`でコマン",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/zx_arguments/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n```shell\nzx query.mjs hoge\n[\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/node',\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/zx',\n  'query.mjs',\n  'hoge'\n]\n```\n\n普通のnodeスクリプトだと`process.argv.slice(2)`でコマンドライン引数のリストを取得するが、zxの場合には`process.argv.slice(3)`になる\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-06-21",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "zx使用時のコマンドライン引数のリスト",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "zx", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "JavaScript",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "process.argv",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/zx_arguments/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/svg2png_with_sharp/",
          "text": "\nSVG出力されたレスポンスをPNGに変換する\n\n```javascript\n#!/usr/bin/env zx\n\nconst sharp = require('sharp');\n\nconst svgText = await fetch('https://localhost:8081/sample.svg').then(res => res.text())\nsharp(Buffer.from(svgText, 'utf-8')).toFile('sample.png')\n```\n\nsharpという画像処理をやってくれるライブラリを使用した\n\n簡単\n\nただdenoやCloudFlare Workersで使おうとすると使えなさそうだった",
          "date": "2022-09-29",
          "title": "Nodeのsharpでsvgをpngへ変換する",
          "tags": ["Node", "SVG", "PNG"],
          "description": "",
          "slug": "/entries/svg2png_with_sharp/",
          "timeToRead": 1,
          "objectID": "94642794-755f-551f-a27f-3e2a33fe83fb",
          "_snippetResult": {
            "text": {
              "value": "\nSVG出力されたレスポンスをPNGに変換する\n\n```javascript\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env zx\n\nconst sharp = require('sharp');\n\nconst svgText = await fetch('https://localhost:8081/sample.svg').then(res => res.text())\nsharp(Buffer.from(svgText, 'utf-8')).toFile('sample.png",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/svg2png_with_sharp/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nSVG出力されたレスポンスをPNGに変換する\n\n```javascript\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env zx\n\nconst sharp = require('sharp');\n\nconst svgText = await fetch('https://localhost:8081/sample.svg').then(res => res.text())\nsharp(Buffer.from(svgText, 'utf-8')).toFile('sample.png')\n```\n\nsharpという画像処理をやってくれるライブラリを使用した\n\n簡単\n\nただdenoやCloudFlare Workersで使おうとすると使えなさそうだった",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-09-29",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Nodeのsharpでsvgをpngへ変換する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Node", "matchLevel": "none", "matchedWords": [] },
              { "value": "SVG", "matchLevel": "none", "matchedWords": [] },
              { "value": "PNG", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/svg2png_with_sharp/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/tfenv/",
          "text": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/bin\n$ ln -s ~/.tfenv/bin/* ~/.local/bin\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/bin:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
          "date": "2021-02-13",
          "title": "tfenvを使いTerraformのバージョンを切り替える",
          "tags": ["Terraform"],
          "description": "tfenv",
          "slug": "/entries/tfenv/",
          "timeToRead": 1,
          "objectID": "e729f978-b42d-5c56-aad5-ee7b793415ff",
          "_snippetResult": {
            "text": {
              "value": "めのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH\"\n```\n\n当たり前だ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/tfenv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-02-13",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "tfenvを使いTerraformのバージョンを切り替える",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [{ "value": "Terraform", "matchLevel": "none", "matchedWords": [] }],
            "description": {
              "value": "tfenv",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/tfenv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/s3_price_per_bucket/",
          "text": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/billing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
          "date": "2020-07-18",
          "title": "S3利用料をバケット毎に詳細に出すための情報",
          "tags": ["AWS", "S3"],
          "description": "使用量レポートと合わせて計算する",
          "slug": "/entries/s3_price_per_bucket/",
          "timeToRead": 2,
          "objectID": "bdc0fa91-9ec4-5a0a-9c22-729b15d9b40d",
          "_snippetResult": {
            "text": {
              "value": "トをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/s3_price_per_bucket/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-07-18",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "S3利用料をバケット毎に詳細に出すための情報",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "AWS", "matchLevel": "none", "matchedWords": [] },
              { "value": "S3", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "使用量レポートと合わせて計算する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/s3_price_per_bucket/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/ruby_rmagick_install/",
          "text": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
          "date": "2020-07-15",
          "title": "CentOS7系でのrmagickのインストール",
          "tags": ["ImageMagick", "Ruby"],
          "description": "依存モジュールのインストールが必要",
          "slug": "/entries/ruby_rmagick_install/",
          "timeToRead": 3,
          "objectID": "cdbf8618-781e-5132-98ea-7304717c68b5",
          "_snippetResult": {
            "text": {
              "value": "2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/ruby_rmagick_install/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-07-15",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "CentOS7系でのrmagickのインストール",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "ImageMagick",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "Ruby", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "依存モジュールのインストールが必要",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ruby_rmagick_install/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/vscode_terminal_profile/",
          "text": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/bin/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
          "date": "2021-11-30",
          "title": "VS Codeのターミナルプロファイル設定",
          "tags": ["VS Code"],
          "description": "profile",
          "slug": "/entries/vscode_terminal_profile/",
          "timeToRead": 1,
          "objectID": "07b63e0d-f818-5f47-b18d-4010b70fdd96",
          "_snippetResult": {
            "text": {
              "value": "16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかった",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/vscode_terminal_profile/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-11-30",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VS Codeのターミナルプロファイル設定",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [{ "value": "VS Code", "matchLevel": "none", "matchedWords": [] }],
            "description": {
              "value": "profile",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vscode_terminal_profile/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/lambda_diff/",
          "text": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/bin/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/bin/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
          "date": "2021-09-05",
          "title": "Lambdaのソースコード差分を取得する",
          "tags": ["AWS", "Lambda"],
          "description": "zipを解凍して差分を取る",
          "slug": "/entries/lambda_diff/",
          "timeToRead": 1,
          "objectID": "eb11dfa0-4401-5cc7-b04d-3f291192bbb4",
          "_snippetResult": {
            "text": {
              "value": "のも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/lambda_diff/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-09-05",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Lambdaのソースコード差分を取得する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "AWS", "matchLevel": "none", "matchedWords": [] },
              { "value": "Lambda", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "zipを解凍して差分を取る",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/lambda_diff/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/docker_host/",
          "text": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/bin/dockerd -H unix://\n+ ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
          "date": "2020-07-14",
          "title": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
          "tags": ["Docker", "IntelliJ"],
          "description": "tcpで接続する",
          "slug": "/entries/docker_host/",
          "timeToRead": 1,
          "objectID": "972ad876-a35b-5497-bb5e-33cba66a3998",
          "_snippetResult": {
            "text": {
              "value": "serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/docker_host/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-07-14",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Docker", "matchLevel": "none", "matchedWords": [] },
              { "value": "IntelliJ", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "tcpで接続する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/docker_host/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/ansible_install_awscliv2/",
          "text": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
          "date": "2020-10-15",
          "title": "AnsibleでAWS CLI v2をインストールする",
          "tags": ["Ansible", "AWS"],
          "description": "",
          "slug": "/entries/ansible_install_awscliv2/",
          "timeToRead": 2,
          "objectID": "6223cafb-c96c-5937-ab87-4e069b55f0a0",
          "_snippetResult": {
            "text": {
              "value": "awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/ansible_install_awscliv2/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-10-15",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "AnsibleでAWS CLI v2をインストールする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Ansible", "matchLevel": "none", "matchedWords": [] },
              { "value": "AWS", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ansible_install_awscliv2/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
          "text": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 ms)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
          "date": "2021-07-19",
          "title": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
          "tags": ["Jest", "Gatsby", "TestingLibrary"],
          "description": "jsdom使う",
          "slug": "/entries/introduction_jest_and_testing_library_to_gatsby/",
          "timeToRead": 2,
          "objectID": "5c1576d2-2d90-5c9c-91e5-fe9d12f8d611",
          "_snippetResult": {
            "text": {
              "value": "感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-07-19",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Jest", "matchLevel": "none", "matchedWords": [] },
              { "value": "Gatsby", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "TestingLibrary",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "jsdom使う",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/wsl_docker_for_windows/",
          "text": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/bin/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker\n\n```bash\n#!/usr/bin/env sh\nbinary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port binding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
          "date": "2021-04-27",
          "title": "WSL2でDockerForWindowsのコマンドを叩く",
          "tags": ["WSL", "Docker"],
          "description": "/mnt/c経由のコマンドを叩く",
          "slug": "/entries/wsl_docker_for_windows/",
          "timeToRead": 2,
          "objectID": "83f1a1ec-789e-59e7-a6ee-9344bb2d4885",
          "_snippetResult": {
            "text": {
              "value": "くても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/wsl_docker_for_windows/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port __ais-highlight__bi__/ais-highlight__nding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-04-27",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "WSL2でDockerForWindowsのコマンドを叩く",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "WSL", "matchLevel": "none", "matchedWords": [] },
              { "value": "Docker", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "/mnt/c経由のコマンドを叩く",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/wsl_docker_for_windows/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 41,
      "page": 0,
      "nbPages": 3,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "exhaustive": { "nbHits": true, "typo": true },
      "query": "Bi",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&query=Bi&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 12,
      "processingTimingsMS": {
        "afterFetch": {
          "format": { "highlighting": 4, "snippeting": 6, "total": 10 },
          "total": 11
        },
        "total": 12
      }
    },
    {
      "hits": [
        {
          "url": "https://til.swfz.io//entries/bigquery_sa_permission_from_cli/",
          "text": "\n特定のデータセット、特定サービスアカウントにREADやWRITE権限を与える\n\n`bq show`で対象データセットの設定を出力、中身の`access`に対象サービスアカウントのメールアドレスをと権限を追加して`bq update`\n\n```shell\nbq show --format=prettyjson memo-111111:sample  > sample.json\n```\n\n- sample.json\n\n```json\n\"access\": [\n  ...\n  ...\n  ...\n    {\n      \"role\": \"READER\",\n      \"userByEmail\": \"github-actions-sample-nokey@memo-111111.iam.gserviceaccount.com\"\n    }\n]\n```\n\n```shell\nbq update --source sample.json sample\n```\n\n## 確認\n\n対象サービスアカウントで実行した\n\n- bq ls\n\n```txt\n  datasetId  \n ----------- \n  sample     \n```\n\n- クエリ\n\n```shell\nbq query --nouse_legacy_sql 'select * from sample.summary'\n```\n\n```\n+------+-------+----+\n| view | title | id |\n+------+-------+----+\n|    3 | fuga  |  2 |\n|    3 | foo   |  4 |\n|    4 | piyo  |  3 |\n|    5 | hoge  |  1 |\n|    5 | bar   |  5 |\n+------+-------+----+\n```\n\nできた\n\n最近GitHubActionsのOIDC認証でCI用のサービスアカウントに対してクエリできるようにする + データセット単位で権限を絞るところまで行ったのでメモ\n\n個人使用ならこれで問題ないかなーという感じ",
          "date": "2022-10-12",
          "title": "BigQueryで特定データセットに権限を付与する",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "bq show + bq update",
          "slug": "/entries/bigquery_sa_permission_from_cli/",
          "timeToRead": 1,
          "objectID": "dafae263-fb55-5d08-bf9f-17c62c276690",
          "_snippetResult": {
            "text": {
              "value": "\n特定のデータセット、特定サービスアカウントにREADやWRITE権限を与える\n\n`bq show`で対象データセットの設定を出力、中身",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_sa_permission_from_cli/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\n特定のデータセット、特定サービスアカウントにREADやWRITE権限を与える\n\n`bq show`で対象データセットの設定を出力、中身の`access`に対象サービスアカウントのメールアドレスをと権限を追加して`bq update`\n\n```shell\nbq show --format=prettyjson memo-111111:sample  > sample.json\n```\n\n- sample.json\n\n```json\n\"access\": [\n  ...\n  ...\n  ...\n    {\n      \"role\": \"READER\",\n      \"userByEmail\": \"github-actions-sample-nokey@memo-111111.iam.gserviceaccount.com\"\n    }\n]\n```\n\n```shell\nbq update --source sample.json sample\n```\n\n## 確認\n\n対象サービスアカウントで実行した\n\n- bq ls\n\n```txt\n  datasetId  \n ----------- \n  sample     \n```\n\n- クエリ\n\n```shell\nbq query --nouse_legacy_sql 'select * from sample.summary'\n```\n\n```\n+------+-------+----+\n| view | title | id |\n+------+-------+----+\n|    3 | fuga  |  2 |\n|    3 | foo   |  4 |\n|    4 | piyo  |  3 |\n|    5 | hoge  |  1 |\n|    5 | bar   |  5 |\n+------+-------+----+\n```\n\nできた\n\n最近GitHubActionsのOIDC認証でCI用のサービスアカウントに対してクエリできるようにする + データセット単位で権限を絞るところまで行ったのでメモ\n\n個人使用ならこれで問題ないかなーという感じ",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2022-10-12",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryで特定データセットに権限を付与する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "bq show + bq update",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_sa_permission_from_cli/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_empty_string_array/",
          "text": "\n[配列関数  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/array_functions?hl=ja)\n\nGENERATE_ARRAYで作るとINT64の空配列になってしまう\n\n```sql\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\nUNIONなどで文字列の配列と結合させようとすると型が合わなくなってしまう\n\n## 例\n\n```sql\nSELECT ['a','b'] AS tags\nUNION ALL\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\n- 結果\n\n```\n Column 1 in UNION ALL has incompatible types: ARRAY<STRING>, ARRAY<INT64> at [3:1] \n```\n\n[Create empty string array BigQuery - Stack Overflow](https://stackoverflow.com/questions/58504188/create-empty-string-array-bigquery)\n\nこまったときのstackoverflow、答えが書いてありました\n\n```sql\nSELECT ARRAY<STRING>[] AS tags\n```\n\nでSTRINGの空配列を生成できる\n\n解決！\n",
          "date": "2022-07-22",
          "title": "BigQueryでStringの空配列を生成する",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "ARRAY",
          "slug": "/entries/bigquery_empty_string_array/",
          "timeToRead": 1,
          "objectID": "94f95f4a-5e85-5917-a74f-84500c7a5783",
          "_snippetResult": {
            "text": {
              "value": "\n[配列関数  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/array_functions?hl=ja)\n\nGENERATE_ARRAYで作るとINT64の空配列になってしまう\n\n```sql\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\nUNIONな",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_empty_string_array/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\n[配列関数  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/array_functions?hl=ja)\n\nGENERATE_ARRAYで作るとINT64の空配列になってしまう\n\n```sql\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\nUNIONなどで文字列の配列と結合させようとすると型が合わなくなってしまう\n\n## 例\n\n```sql\nSELECT ['a','b'] AS tags\nUNION ALL\nSELECT GENERATE_ARRAY(1,0,1) AS tags\n```\n\n- 結果\n\n```\n Column 1 in UNION ALL has incompatible types: ARRAY<STRING>, ARRAY<INT64> at [3:1] \n```\n\n[Create empty string array __ais-highlight__Bi__/ais-highlight__gQuery - Stack Overflow](https://stackoverflow.com/questions/58504188/create-empty-string-array-__ais-highlight__bi__/ais-highlight__gquery)\n\nこまったときのstackoverflow、答えが書いてありました\n\n```sql\nSELECT ARRAY<STRING>[] AS tags\n```\n\nでSTRINGの空配列を生成できる\n\n解決！\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-07-22",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryでStringの空配列を生成する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "ARRAY",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_empty_string_array/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_cant_use_autodetect/",
          "text": "\nPocketのデータをAPIで取得してBigQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\nBigQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/bigquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、BigQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。BigQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
          "date": "2021-05-08",
          "title": "BigQueryのbq load時にautodetectを使えない場合",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "データにばらつきがありautodetectが使えないパターン",
          "slug": "/entries/bigquery_cant_use_autodetect/",
          "timeToRead": 3,
          "objectID": "6c49c87d-a92d-51b8-863d-7251544ccc40",
          "_snippetResult": {
            "text": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようと",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\nPocketのデータをAPIで取得して__ais-highlight__Bi__/ais-highlight__gQueryに突っ込もうとしたときの話\n\nGCSにJSONを置いてCLIから`bq load --autodetect`でデータをloadしようとしたらエラーで怒られた\n\n```\n__ais-highlight__Bi__/ais-highlight__gQuery error in load operation: Error processing job\n'project-111111:bqjob_r70118be7bda78ce4_000001793f9c2946_1': Error while reading\ndata, error message: JSON table encountered too many errors, giving up. Rows: 1;\nerrors: 1. Please look into the errors[] collection for more details.\nFailure details:\n- Error while reading data, error message: JSON processing\nencountered too many errors, giving up. Rows: 1; errors: 1; max\nbad: 0; error percent: 0\n- gs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json: Error\nwhile reading data, error message: JSON parsing error in row\nstarting at position 0: JSON object specified for non-record field:\nlist.videos\n```\n\n## 前提\n\n現状あるデータは次の3つ（bucket名はサンプル）\n\n```\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-03.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-04.json\ngs://sample-bucket/preprocessed_rawdata/month=2021-05-01/raw-05.json\n```\n\n## 原因の切り分け\n\n- raw-03.json\n- raw-04.json\n\nのときは問題なくloadできている\n\n`raw-05.json`\n\nが追加されてから上記エラーになってしまった\n\n05と03,04のJSONの中身を比べてみたところ05には`list.videos`がすべて`[]`になっていた\n\n03,04に関してはどこかのレコードでオブジェクトが入っていたので`RECORD`と判断された模様\n\nこのことから`--autodetect`は最初のファイルをautodetectで読み込んで順番にその他ファイルも読み込んでいると考えられる\n\n[スキーマの自動検出](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/schema-detect?hl=ja#auto-detect)\n\nここに説明が書いてあった\n\n> 自動検出を有効にすると、__ais-highlight__Bi__/ais-highlight__gQuery はデータソース内でランダムにファイルを選択します。ファイルの最大 100 行をスキャンして代表的なサンプルとして使用し、推定プロセスを開始します。__ais-highlight__Bi__/ais-highlight__gQuery は、各フィールドを検証し、そのサンプル内の値に基づいてそのフィールドにデータ型を割り当てようとします。\n\nランダムでファイルを読み込むとあるので全パターンを網羅したデータがあるファイルじゃないファイルがサンプルに選定されてしまった場合にこういうことが起きる\n\nそうなると`autodetect`は使えないのでテーブル作成→loadの手順を踏む必要がある\n\n- schemaの取り出し\n\nうまく行ったパターンで生成したテーブルのスキーマを取得する\n\n```\nbq show --schema --format=prettyjson pocket.rawdata > pocket-rawdata.json\n```\n\n- テーブル作成\n\n別のテーブルを用意して試してみる\n\n```\nbq mk --table --time_partitioning_field month --time_partitioning_type MONTH sample.pocket_rawdata pocket-rawdata.json\n```\n\n- load\n\n```\nbq load --source_format=NEWLINE_DELIMITED_JSON --replace sample.pocket_rawdata 'gs://sample-bucket/preprocessed_rawdata/*'\n```\n\n今のところこんな感じでなんとかなっている\n\n## まとめ\n\n取り込み対象のデータにばらつきがある（あるデータではRECORD、あるデータでは`[]`のようなとき）とサンプリング次第で取り込めない場合がある\n\nさらに`--autodetect`+`--replace`を用いると毎回ロード時に自動検出するので失敗する可能性がある\n\nそのためスキーマを定義してテーブルの作成+`bq load`と手順を踏む必要がある\n\n## 所感\n\n本来だったら`autodetect`で生成したスキーマからさらに精査して本当に`NULLABLE`?みたいな話も考えたほうが良いが今回は趣味プロジェクトなので…\n\nautodetectは便利だけどこういうパターンに対応できないのでやはりPOCやお試しのときくらいしか使えないよなーとあらためて感じた\n\nまぁでも気軽に試せるのはとても良いことなので使い分けが大事",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-05-08",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryのbq load時にautodetectを使えない場合",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "データにばらつきがありautodetectが使えないパターン",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_cant_use_autodetect/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_date_function/",
          "text": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
          "date": "2022-03-25",
          "title": "BigQueryの日付を扱う際のメモ",
          "tags": ["BigQuery", "GoogleCloudPlatform", "SQL"],
          "description": "スニペット的なやつ",
          "slug": "/entries/bigquery_date_function/",
          "timeToRead": 1,
          "objectID": "6539d73b-40f3-50ab-8340-44ae50b6b75b",
          "_snippetResult": {
            "text": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\nよく使うと思われるクエリをメモしておく\n\n```sql\nSELECT\nDATE_TRUNC(CURRENT_DATE(), MONTH) AS first_day, # 月初\nLAST_DAY(CURRENT_DATE(), MONTH) AS last_day, # 月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS first_day_of_yesterday, # 前日起算の月初\nLAST_DAY(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY), MONTH) AS last_day_of_yesterday, # 前日起算の月末\nDATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH), MONTH) AS first_day_of_last_three_month # 3ヶ月前の月初\n```\n\nDATE_TRUNC, LAST_DAYが便利",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2022-03-25",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryの日付を扱う際のメモ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "SQL", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "スニペット的なやつ",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_function/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_sample_data/",
          "text": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
          "date": "2020-12-09",
          "title": "BigQueryでサンプルデータをサクッと作る",
          "tags": ["BigQuery", "SQL"],
          "description": "WITH,UNNEST,ARRAY,STRUCTでやる",
          "slug": "/entries/bigquery_sample_data/",
          "timeToRead": 1,
          "objectID": "095f8841-166b-5319-8f30-c135a7d6b56b",
          "_snippetResult": {
            "text": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql",
              "matchLevel": "none"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\n簡易的にでもサンプルデータが欲しい場合、わざわざデータを入れ込まなくてもサンプルデータを生成できる\n\n```sql\nWITH sample AS(\n  SELECT * FROM UNNEST(ARRAY<STRUCT<start_date DATE, end_date DATE, item STRING, sales INT64>>\n    [\n      (\"2020-08-01\", \"2020-11-30\", \"hoge\", 100),\n      (\"2020-10-01\", \"2020-10-31\", \"fuga\", 200)\n    ]\n  )\n)\nSELECT * FROM sample\n```\n\n- 結果\n\n|start_date|end_date|item|sales|\n|---|---|---|---|\n|2020-08-01|2020-11-30|hoge|100|\n|2020-10-01|2020-10-31|fuga|200|\n\n\n記事書くときや説明とかに使える\n",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2020-12-09",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryでサンプルデータをサクッと作る",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              { "value": "SQL", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "WITH,UNNEST,ARRAY,STRUCTでやる",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_sample_data/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/bigquery_date_timezone/",
          "text": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\nBigQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
          "date": "2021-04-21",
          "title": "BigQueryで日付を扱うときはTimezoneを意識する",
          "tags": ["BigQuery", "GoogleCloudPlatform"],
          "description": "基本はUTCですねという話",
          "slug": "/entries/bigquery_date_timezone/",
          "timeToRead": 1,
          "objectID": "02883dc4-e742-5435-892c-a78e335fdde5",
          "_snippetResult": {
            "text": {
              "value": "ムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__bi__/ais-highlight__gquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\ndataformでsourceテーブルから中間テーブルを生成してassertionを書いていた\n\n検算したら件数が合わないなーということで調べた\n\n次のようなSQLで`from`,`to`を指定して単月分のレコードのみ抜き出すというパターン\n\n```sql\nSELECT\n  *,\n  'private' AS workspace\nFROM\n  `sample.rawdata-private`,\n  UNNEST(data) AS d\nWHERE\n  DATE(start) BETWEEN ${target_date.from}\n  AND ${target_date.to}\n```\n\n<!-- textlint-disable prh -->\nSQLXなので`target_date.to`と`target_date.from`はその時々によって変化する\n<!-- textlint-enable prh -->\n\n今回は`2021-04-01` ～ `2021-04-30`をという感じ\n\n`rawdata-private`はAPIのレスポンスをそのまま保存していて1行に`total_count`と`data`列に実際のレコードがあるので`UNNEST`してレコード数と比較することで確認している\n\n`rawdata-private`のレコードを追ってみると\n\n```json\n\"start\": \"2021-04-01T04:57:39+09:00\",\n```\n\nのデータが`DATE(start)`を通すことで`2021-03-31`になっていた\n\nなるほどUTC\n\n`DATE(start, 'Asia/Tokyo'),`でタイムゾーン指定の日付データに変換できるのでこれで対応\n\n__ais-highlight__Bi__/ais-highlight__gQueryがDATEでよしなにやってくれた結果UTCで解釈すると`2021-03-31`となってしまうためフィルタ対象から外れてしまい、件数が合わない状態になっていた\n\n正直assertion書いてなかったら気付かなかったのでassertion大事w",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-04-21",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__Bi__/ais-highlight__gQueryで日付を扱うときはTimezoneを意識する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "基本はUTCですねという話",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__bi__/ais-highlight__gquery_date_timezone/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/workflows_logging_bigquery_failed/",
          "text": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのままBigQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクでBigQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+BigQueryへloadってパターンがベターなのかな",
          "date": "2021-07-13",
          "title": "Workflowsで Memory usage limit exeeded",
          "tags": ["Workflows", "GoogleCloudPlatform"],
          "description": "失敗記録",
          "slug": "/entries/workflows_logging_bigquery_failed/",
          "timeToRead": 2,
          "objectID": "ac419206-6eea-559a-82a6-992344e0e64d",
          "_snippetResult": {
            "text": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライベート",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/workflows_logging___ais-highlight__bi__/ais-highlight__gquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "text": {
              "value": "\nはてなブログのAPIなど公開のAPIをたたいてそのレスポンスをそのまま__ais-highlight__Bi__/ais-highlight__gQueryに突っ込むみたいなやつ\n\nプライベートなのと規模感が小さいのでちょっと冒険的な感じでやってみようと次のような構成で試みた\n\n- Workflowsではてなブックマークの公開APIをたたく\n- WorkflowsのログにAPIのレスポンスをそのまま流す\n- Logging→集約シンクで__ais-highlight__Bi__/ais-highlight__gQueryにレコードを追加する\n\nFunctionsを新たに作らなくても良いしとりあえずの生データも保存できるしわりと省力で実現できるかと考えた\n\nある程度動作確認して問題なかったので自分のブログの全URLで実行したら次のようなエラーが出てしまった\n\n```shell\nExecution failed or cancelled.\nin step \"call_workflow_api\", routine \"call_workflow\", line: 88\nin step \"collect_hatena_bookmark_workflow\", routine \"main\", line: 35\n{\n  \"message\": \"Execution failed or cancelled.\",\n  \"operation\": {\n    \"argument\": \"{\\\"target_url\\\":\\\"https://swfz.hatenablog.com/entry/2018/12/22/080733\\\"}\",\n    \"endTime\": \"2021-07-10T12:01:03.749667278Z\",\n    \"error\": {\n      \"payload\": \"{\\\"message\\\":\\\"ResourceLimitError: Memory usage limit exceeded\\\",\\\"tags\\\":[\\\"ResourceLimitError\\\"]}\",\n      \"stackTrace\": {}\n    },\n    \"name\": \"projects/1111111111111/locations/us-central1/workflows/collect_hatena_bookmark_metrics/executions/c4a686eb-4d92-4e95-94f6-4257438131e0\",\n    \"startTime\": \"2021-07-10T12:01:02.693637032Z\",\n    \"state\": \"FAILED\",\n    \"workflowRevisionId\": \"000001-331\"\n  },\n  \"tags\": [\n    \"OperationError\"\n  ]\n}\n```\n\nバズって300前後のブックマークが付いたURLのレスポンスで発生した\n\n[割り当てと上限  |  ワークフロー  |  Google Cloud](https://cloud.google.com/workflows/quotas)\n\n変数のメモリ割り当てにも上限があり64KBまでらしい\n\nなのでAPIのレスポンスが64KB以上ある場合はエラーになってしまう…\n\nFunctionsは経由するがFunctionsからLoggingへ直接流すようにするか?と思ったが\n\n[割り当てと上限  |  Cloud Logging  |  Google Cloud](https://cloud.google.com/logging/quotas?hl=ja)\n\n同じようにLoggingにも割り当て上限があるのでこの辺も考慮できていないといけない\n\nこの辺まで調べて面倒になってきてしまいこの手法は諦めた\n\nメモリリミットに達してしまったため回避方法はなさそう…APIのレスポンスをそのままWorkflows上でよしなにやるパターンは厳しいという結論になりました\n\nWorkflowsはあくまで各処理のオーケストレーションなのでWorkflows内にあまり処理を持ち込むべきではないっていう考え方なのかなと推測\n\n結局こういうパターンはFunctionsでGCSにデータ置く+__ais-highlight__Bi__/ais-highlight__gQueryへloadってパターンがベターなのかな",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-07-13",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Workflowsで Memory usage limit exeeded",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "Workflows",
                "matchLevel": "none",
                "matchedWords": []
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "失敗記録",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/workflows_logging___ais-highlight__bi__/ais-highlight__gquery_failed/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/json_to_csv/",
          "text": "\n[Working with JSON data in Standard SQL  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/reference/standard-sql/json-data)\n\n先日BigQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
          "date": "2022-02-28",
          "title": "JSONファイルをBigQueryに読ませJSON型で扱うためにそのままCSVで保存する",
          "tags": ["jq", "BigQuery", "GoogleCloudPlatform"],
          "description": "jq",
          "slug": "/entries/json_to_csv/",
          "timeToRead": 1,
          "objectID": "2e780a6a-d216-545c-8eb0-c5db3e4301ef",
          "_snippetResult": {
            "text": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではload",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n[Working with JSON data in Standard SQL  |  __ais-highlight__Bi__/ais-highlight__gQuery  |  Google Cloud](https://cloud.google.com/__ais-highlight__bi__/ais-highlight__gquery/docs/reference/standard-sql/json-data)\n\n先日__ais-highlight__Bi__/ais-highlight__gQueryでnative JSON型がプレビューでサポートされた\n\n執筆時点ではloadはCSVしか対応していないようだったのでJSONのファイルはCSVに変換する必要がある\n\nとりあえず使ってみるためにJSONを返すAPIのレスポンスをまるまるCSVにして突っ込んでみることにした\n\n```\ncat hoge.json| jq -r '[.|tostring]|@csv' > hoge.csv\n```\n\n- schema.json\n\n```json\n[\n  {\n    \"mode\": \"NULLABLE\",\n    \"name\": \"data\",\n    \"type\": \"JSON\"\n  }\n]\n```\n\n### load\n\n```\nbq load --replace --source_format=CSV ${GOOGLE_PROJECT}:sample.content_text hoge.csv ./schema.json\n```\n\nこれでJSON型を使えるようになった\n\n1ファイル1レコードという力技だが扱う容量が多くなければこの方法でもいける\n\n何度かSQLたたいてみたけどSTRUCTやREPEATEDなど今まで型でサポートしてくれていた部分を考慮してあげないといけない\n\nなのでいったん特定のカラムを抜き出す工程みたいなのが必要\n\n配列も`JSON_QUERY_ARRAY`を挟んであげる必要があるなどまぁそうだよなという感じ\n\nload対象がJSONファイルで特定のキー以下をJSON型として扱うということができるようになってほしいと感じた\n\n現状だと上記のようにひと手間かけないといけないのでデータレイク的なところから一次整形処理を挟む必要が出てくるのでまだちょっと使いづらいなーという感じ",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-02-28",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "JSONファイルを__ais-highlight__Bi__/ais-highlight__gQueryに読ませJSON型で扱うためにそのままCSVで保存する",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "tags": [
              { "value": "jq", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "__ais-highlight__Bi__/ais-highlight__gQuery",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["bi"]
              },
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "jq",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/json_to_csv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/dataportal_experience_date/",
          "text": "\nただのメモ\n\nTogglからBigQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
          "date": "2021-04-10",
          "title": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
          "tags": ["GoogleCloudPlatform", "DataPortal"],
          "description": "if + parse_datetime + format_datetime",
          "slug": "/entries/dataportal_experience_date/",
          "timeToRead": 2,
          "objectID": "12505894-0414-5e44-8176-e3373bf7591f",
          "_snippetResult": {
            "text": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測し",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/dataportal_experience_date/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nただのメモ\n\nTogglから__ais-highlight__Bi__/ais-highlight__gQueryにデータを突っ込んでいてそれをDataPortal経由でグラフ化している\n\n`start: 2020-12-25 21:52:30 UTC`（実際計測している時刻UTCではなくAsia/TokyoだがToggl側のAPIが返す値は時刻+UTCという値が返ってきている）\n\n上記のようなフォーマットのカラムを午前9時を堺にグルーピングしたいという要件が出てきた\n\n## 経緯\n\n単にグラフ化した場合`start`を基準にして日付単位でグループ化すると\n\n睡眠時間によっては日の合計時間が24時間を超えてしまうためグラフを眺めていて違和感がある\n\nそのため現在は0時をまたいで睡眠をとった場合は0時を境に分割して記録している\n\n```\n睡眠: 2021-04-09 22:00:00 ～ 2021-04-10 07:00:00\nToggl上での記録: \n- 2021-04-09 22:00:00 ～ 2021-04-10 00:00:00\n- 2021-04-10 00:00:00 ～ 2021-04-10 07:00:00\n```\n\nそうすると正確な日付としては分割して結果を閲覧できるが自分の体感としての日の睡眠時間がずれてグラフ化されてしまう\n\nそこで、冒頭のように午前9時開始を堺に日付を分割して0-9時のデータは前日分としてグラフ上では扱えるようにする\n\nそのための計算フィールドの計算式が下記\n\n```sql\nif(\n  parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT%H\",start)\n  ) < parse_datetime(\n    \"%Y-%m-%dT%H\",\n    format_datetime(\"%Y-%m-%dT09\",start)\n  ),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", datetime_sub(start, INTERVAL 1 DAY))),\n  parse_date(\"%Y-%m-%d\" ,format_datetime(\"%Y-%m-%d\", start))\n)\n```\n\n## つまずきポイント\n- DataPortalで日付カラムとして扱う場合はDate型かDateTime型になっている必要があるので結果に`parse_date`などパース処理が必要\n- `start`自体も日付・時刻カラムだったのでまず`format_datetime`でフォーマットしてからさらに`parse_datetime`で比較させて上げる必要があった\n- よく考えれば分かるはずだったがDataPortal上のテーブルで可視化すると別のフォーマットで出力されてしまい若干混乱した\n\nこんな感じで午前9時を境に日付を変更できた\n\n![alt](dataportal_experience_date01.png)",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-04-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DataPortalで9時区切りの日付カラムを計算フィールドで作成する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              },
              {
                "value": "DataPortal",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "if + parse_datetime + format_datetime",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/dataportal_experience_date/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/zx_arguments/",
          "text": "\n```shell\nzx query.mjs hoge\n[\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/bin/node',\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/bin/zx',\n  'query.mjs',\n  'hoge'\n]\n```\n\n普通のnodeスクリプトだと`process.argv.slice(2)`でコマンドライン引数のリストを取得するが、zxの場合には`process.argv.slice(3)`になる\n",
          "date": "2022-06-21",
          "title": "zx使用時のコマンドライン引数のリスト",
          "tags": ["zx", "JavaScript"],
          "description": "process.argv",
          "slug": "/entries/zx_arguments/",
          "timeToRead": 1,
          "objectID": "cc6ab13d-d6cc-59dc-9f9c-047b85a1f480",
          "_snippetResult": {
            "text": {
              "value": "\n```shell\nzx query.mjs hoge\n[\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/node',\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/zx',\n  'query.mjs',\n  'hoge'\n]\n```\n\n普通のnodeスクリプトだと`process.argv.slice(2)`でコマン",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/zx_arguments/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n```shell\nzx query.mjs hoge\n[\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/node',\n  '/home/user/.anyenv/envs/nodenv/versions/16.13.0/__ais-highlight__bi__/ais-highlight__n/zx',\n  'query.mjs',\n  'hoge'\n]\n```\n\n普通のnodeスクリプトだと`process.argv.slice(2)`でコマンドライン引数のリストを取得するが、zxの場合には`process.argv.slice(3)`になる\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-06-21",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "zx使用時のコマンドライン引数のリスト",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "zx", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "JavaScript",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "process.argv",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/zx_arguments/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/svg2png_with_sharp/",
          "text": "\nSVG出力されたレスポンスをPNGに変換する\n\n```javascript\n#!/usr/bin/env zx\n\nconst sharp = require('sharp');\n\nconst svgText = await fetch('https://localhost:8081/sample.svg').then(res => res.text())\nsharp(Buffer.from(svgText, 'utf-8')).toFile('sample.png')\n```\n\nsharpという画像処理をやってくれるライブラリを使用した\n\n簡単\n\nただdenoやCloudFlare Workersで使おうとすると使えなさそうだった",
          "date": "2022-09-29",
          "title": "Nodeのsharpでsvgをpngへ変換する",
          "tags": ["Node", "SVG", "PNG"],
          "description": "",
          "slug": "/entries/svg2png_with_sharp/",
          "timeToRead": 1,
          "objectID": "94642794-755f-551f-a27f-3e2a33fe83fb",
          "_snippetResult": {
            "text": {
              "value": "\nSVG出力されたレスポンスをPNGに変換する\n\n```javascript\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env zx\n\nconst sharp = require('sharp');\n\nconst svgText = await fetch('https://localhost:8081/sample.svg').then(res => res.text())\nsharp(Buffer.from(svgText, 'utf-8')).toFile('sample.png",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/svg2png_with_sharp/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nSVG出力されたレスポンスをPNGに変換する\n\n```javascript\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env zx\n\nconst sharp = require('sharp');\n\nconst svgText = await fetch('https://localhost:8081/sample.svg').then(res => res.text())\nsharp(Buffer.from(svgText, 'utf-8')).toFile('sample.png')\n```\n\nsharpという画像処理をやってくれるライブラリを使用した\n\n簡単\n\nただdenoやCloudFlare Workersで使おうとすると使えなさそうだった",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2022-09-29",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Nodeのsharpでsvgをpngへ変換する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Node", "matchLevel": "none", "matchedWords": [] },
              { "value": "SVG", "matchLevel": "none", "matchedWords": [] },
              { "value": "PNG", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/svg2png_with_sharp/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/tfenv/",
          "text": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/bin\n$ ln -s ~/.tfenv/bin/* ~/.local/bin\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/bin:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
          "date": "2021-02-13",
          "title": "tfenvを使いTerraformのバージョンを切り替える",
          "tags": ["Terraform"],
          "description": "tfenv",
          "slug": "/entries/tfenv/",
          "timeToRead": 1,
          "objectID": "e729f978-b42d-5c56-aad5-ee7b793415ff",
          "_snippetResult": {
            "text": {
              "value": "めのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH\"\n```\n\n当たり前だ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/tfenv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n[tfutils/tfenv: Terraform version manager](https://github.com/tfutils/tfenv)\n\nTerraformのバージョンを切り替えて使用するためのツール\n\n### インストール\n\n```shell\n$ git clone https://github.com/tfutils/tfenv.git ~/.tfenv\n$ mkdir ~/.local/__ais-highlight__bi__/ais-highlight__n\n$ ln -s ~/.tfenv/__ais-highlight__bi__/ais-highlight__n/* ~/.local/__ais-highlight__bi__/ais-highlight__n\n```\n\n### PATHへの追加\n\n- .bashrc\n\n```\nexport PATH=\"$HOME/.tfenv/__ais-highlight__bi__/ais-highlight__n:$PATH\"\n```\n\n当たり前だが既存のパスより前にtfenvのパスが先にないと既存でterraformを使っている場合そっちが先に見つかってしまうのでtfenvのパスを先にする\n\n### 切り替え、使用\n\n```\n$ tfenv install 0.14.6\n$ tfenv use 0.14.6\n$ terraform --version\nTerraform v0.14.6\n```\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-02-13",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "tfenvを使いTerraformのバージョンを切り替える",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [{ "value": "Terraform", "matchLevel": "none", "matchedWords": [] }],
            "description": {
              "value": "tfenv",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/tfenv/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/s3_price_per_bucket/",
          "text": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/billing/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
          "date": "2020-07-18",
          "title": "S3利用料をバケット毎に詳細に出すための情報",
          "tags": ["AWS", "S3"],
          "description": "使用量レポートと合わせて計算する",
          "slug": "/entries/s3_price_per_bucket/",
          "timeToRead": 2,
          "objectID": "bdc0fa91-9ec4-5a0a-9c22-729b15d9b40d",
          "_snippetResult": {
            "text": {
              "value": "トをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/s3_price_per_bucket/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nかなり面倒で分かりづらかったのでメモ程度に残しておく\n\n## 手順\n### 使用状況レポートをDLする\n- [使用状況レポートのダウンロード](https://console.aws.amazon.com/__ais-highlight__bi__/ais-highlight__lling/home#/reports/usage)\n- 次の項目を指定する\n    - サービス\n    - 使用タイプ\n    - オペレーション\n    - 期間\n    - 詳細度（粒度）\n\n`Resource`列にバケット名が入ってくるので区別する\n\n### 次の3点に関してそれぞれ使用状況レポートから計算する\n- ストレージ容量\n    - `TimedStorage-ByteHrs`などを対象\n    - バイト時間を課金GB月に変換する\n- リクエストカウント\n    - `Requests-Tier2`などを対象\n        - Tier1\n        - Tier2\n    - リクエストのタイプにより料金が違うのでそれぞれ集計し、1000リクエストごとの料金を掛け合わせる\n- データ転送量\n    - 次の3点を考慮して計算する\n        - Outに関して料金が発生する\n        - 月の使用量によってレートが変わる\n        - インターネットかリージョンかでもレートが変わる\n            - インターネット -> `DataTransfer-Out-Bytes`\n            - リージョン間 -> `AWS-Out-Bytes`,`C3DataTransfer-Out-Bytes`\n            - `S3G-DataTransfer-Out-Bytes`はリージョン間に該当すると思われる\n            - Cloudfrontへの転送は料金がかからない\n                - `CloudFront-Out-Bytes`\n\n`使用レポート`の項目を読み込んで必要な項目だけ抜き出して計算する必要がある\n\n## 参考\n\n[AWS の Amazon S3 請求および使用状況レポートを理解する - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report-understand.html)\n\n[S3 バケットの請求および使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/BucketBilling.html)\n\n[Amazon S3 用の AWS 使用状況レポート - Amazon Simple Storage Service](https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/aws-usage-report.html)\n\n[料金 - Amazon S3 ｜AWS](https://aws.amazon.com/jp/s3/pricing/?nc1=h_ls)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-07-18",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "S3利用料をバケット毎に詳細に出すための情報",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "AWS", "matchLevel": "none", "matchedWords": [] },
              { "value": "S3", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "使用量レポートと合わせて計算する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/s3_price_per_bucket/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/ruby_rmagick_install/",
          "text": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/bin/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
          "date": "2020-07-15",
          "title": "CentOS7系でのrmagickのインストール",
          "tags": ["ImageMagick", "Ruby"],
          "description": "依存モジュールのインストールが必要",
          "slug": "/entries/ruby_rmagick_install/",
          "timeToRead": 3,
          "objectID": "cdbf8618-781e-5132-98ea-7304717c68b5",
          "_snippetResult": {
            "text": {
              "value": "2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/ruby_rmagick_install/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nサクッとrmagickインストールできなかったので覚え書き\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4/ext/RMagick\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-2470-bpwp3n.rb extconf.rb\nchecking for gcc... yes\nchecking for Magick-config... no\nchecking for pkg-config... yes\nPackage MagickCore was not found in the pkg-config search path.\nPerhaps you should add the directory containing `MagickCore.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'MagickCore' found\nchecking for outdated ImageMagick version (<= 6.4.9)... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/rmagick-2.15.4 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/rmagick-2.15.4/gem_make.out\n\nAn error occurred while installing rmagick (2.15.4), and Bundler cannot continue.\nMake sure that `gem install rmagick -v '2.15.4' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  rmagick\n```\n\nImageMagickインストールするだけではダメだった\n\nほかに`ImageMAgicka-c++`が必要みたい\n\n```\nsudo yum install ImageMagick-c++-devel\n```\n\nそれでもダメだった\n\n```\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\n    current directory: /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0/ext/filemagic\n/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/ruby -r ./siteconf20200715-5698-19exkam.rb extconf.rb\nchecking for -lgnurx... no\nchecking for magic_open() in -lmagic... no\n*** ERROR: missing required library to compile this module\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/lib\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/__ais-highlight__bi__/ais-highlight__n/$(RUBY_BASE_NAME)\n        --with-magic-dir\n        --without-magic-dir\n        --with-magic-include\n        --without-magic-include=${magic-dir}/include\n        --with-magic-lib\n        --without-magic-lib=${magic-dir}/lib\n        --with-gnurx-dir\n        --without-gnurx-dir\n        --with-gnurx-include\n        --without-gnurx-include=${gnurx-dir}/include\n        --with-gnurx-lib\n        --without-gnurx-lib=${gnurx-dir}/lib\n        --with-gnurxlib\n        --without-gnurxlib\n        --with-magiclib\n        --without-magiclib\n\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n\n  /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/mkmf.log\n\nextconf failed, exit code 1\n\nGem files will remain installed in /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/gems/ruby-filemagic-0.7.0 for inspection.\nResults logged to /home/vagrant/.anyenv/envs/rbenv/versions/2.5.7/lib/ruby/gems/2.5.0/extensions/x86_64-linux/2.5.0/ruby-filemagic-0.7.0/gem_make.out\n\nAn error occurred while installing ruby-filemagic (0.7.0), and Bundler cannot continue.\nMake sure that `gem install ruby-filemagic -v '0.7.0' --source 'https://rubygems.org/'` succeeds before bundling.\n\nIn Gemfile:\n  ruby-filemagic\n```\n\n`file-devel`というパッケージも必要だった\n\n```\nsudo yum install file-devel\n```\n\n- 参考\n\n[file-devel](https://en.it1352.com/article/e29b2d3fec8b45389fba33ad61ab0553.html)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-07-15",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "CentOS7系でのrmagickのインストール",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "ImageMagick",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "Ruby", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "依存モジュールのインストールが必要",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ruby_rmagick_install/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/vscode_terminal_profile/",
          "text": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/bin/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
          "date": "2021-11-30",
          "title": "VS Codeのターミナルプロファイル設定",
          "tags": ["VS Code"],
          "description": "profile",
          "slug": "/entries/vscode_terminal_profile/",
          "timeToRead": 1,
          "objectID": "07b63e0d-f818-5f47-b18d-4010b70fdd96",
          "_snippetResult": {
            "text": {
              "value": "16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかった",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/vscode_terminal_profile/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n- 前提のバージョン情報\n\n```\nバージョン: 1.62.3 (user setup)\nコミット: ccbaa2d27e38e5afa3e5c21c1c7bef4657064247\n日付: 2021-11-17T08:11:14.551Z\nElectron: 13.5.2\nChrome: 91.0.4472.164\nNode.js: 14.16.0\nV8: 9.1.269.39-electron.0\nOS: Windows_NT x64 10.0.19041\n```\n\n- settings.json\n\n```json\n    \"terminal.integrated.shell.linux\": \"/usr/local/__ais-highlight__bi__/ais-highlight__n/tmux\",\n```\n\n上記のようにlinuxの場合はdefaultでtmuxを起動させたかったのでそういう設定をしていた\n\nが、設定ファイル上で下線が出ていた\n\n![alt](vscode_terminal_profile01.png)\n\nと出てきた\n\n[Integrated Terminal in Visual Studio Code](https://code.visualstudio.com/docs/editor/integrated-terminal#_terminal-profiles)\n\nへ遷移すると\n\nprofilesを設定してdefaultProfileで指定するようにしてねとのこと\n\n直接指定する方法はそのうちなくなるようなので変更した\n\n```json\n    \"terminal.integrated.defaultProfile.linux\": \"tmux\",\n    \"terminal.integrated.profiles.osx\": {\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n    \"terminal.integrated.profiles.linux\": {\n        \"zsh_login\": {\n          \"path\": \"zsh\",\n          \"args\": [\"-l\"]\n        },\n        \"tmux\": {\n            \"path\": \"tmux\"\n        }\n    },\n```\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\nディストリビューションが違う場合はデフォルトも変えられる（osx, linux, Windows）、今の所WSL2とCodespaceはlinuxなのでCodespaceの方は個別スペースの設定をいじって`zsh_login`を適用させている（tmuxが入っていない場合があるため）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-11-30",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "VS Codeのターミナルプロファイル設定",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [{ "value": "VS Code", "matchLevel": "none", "matchedWords": [] }],
            "description": {
              "value": "profile",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/vscode_terminal_profile/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/lambda_diff/",
          "text": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/bin/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/bin/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
          "date": "2021-09-05",
          "title": "Lambdaのソースコード差分を取得する",
          "tags": ["AWS", "Lambda"],
          "description": "zipを解凍して差分を取る",
          "slug": "/entries/lambda_diff/",
          "timeToRead": 1,
          "objectID": "eb11dfa0-4401-5cc7-b04d-3f291192bbb4",
          "_snippetResult": {
            "text": {
              "value": "のも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/lambda_diff/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nプロダクションとステージングでコード差分がーとかそういうのを検知する目的でスクリプトを書いてた\n\nそういえばこんなものも書いたなと言うことで供養がてら残しておく\n\n- lambda-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-diff profile FunctionName1 FunctionName2\n\nget_lambda_zip(){\n  curl -o /tmp/$2.zip `aws --profile=$1 lambda get-function --function-name $2 | jq -r '.Code.Location'`\n}\n\nunzip_lambda_code(){\n  unzip -p /tmp/$1.zip | cat -\n}\n\nget_lambda_zip $1 $2\nget_lambda_zip $1 $3\n\ndiff -u -w <(unzip_lambda_code $2) <(unzip_lambda_code $3)\n```\n\nファイルが複数存在する場合の考慮はしていない（できるかもためしていない）\n\nNodeだとindex.jsだけで完結する場合に差分を検出できる\n\nLambdaの設定差分だけであればコマンド一発で書ける（当時は自動化するためにスクリプト化してた）\n\n- lambda-config-diff\n\n```shell\n#!/__ais-highlight__bi__/ais-highlight__n/bash\n\n# lambda-config-diff profile FunctionName1 FunctionName2\n\ndiff -u -w <(aws --profile=$1 lambda get-function-configuration --function-name $2) <(aws --profile=$1 lambda get-function-configuration --function-name $3)\n```\n\nこのスクリプトを定期的に実行して差分があればメールなりSlackなりに通知したりして差分が出た!みたいなのを検知できる",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-09-05",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Lambdaのソースコード差分を取得する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "AWS", "matchLevel": "none", "matchedWords": [] },
              { "value": "Lambda", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "zipを解凍して差分を取る",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/lambda_diff/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/docker_host/",
          "text": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/bin/dockerd -H unix://\n+ ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
          "date": "2020-07-14",
          "title": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
          "tags": ["Docker", "IntelliJ"],
          "description": "tcpで接続する",
          "slug": "/entries/docker_host/",
          "timeToRead": 1,
          "objectID": "972ad876-a35b-5497-bb5e-33cba66a3998",
          "_snippetResult": {
            "text": {
              "value": "serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/docker_host/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n## 前提環境\n- Windows 10\n- CentOS7\n- IntelliJ 2020.1.2\n\nホストのIntelliJでVM上のdockerを使って開発する場合\n\ndockerのAPIをたたくためにTCP接続を可能にする必要がある\n\nCentOSの場合、docker serviceの起動オプションを変える\n\n### 設定\n\n- /usr/lib/systemd/system/docker.service\n\n```diff\n[Service]\n- ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H unix://\n+ ExecStart=/usr/__ais-highlight__bi__/ais-highlight__n/dockerd -H tcp://0.0.0.0:2375\n```\n\n- リロード\n\n```shell\nsystemctl daemon-reload\nservice docker start\n```\n\n`Project Structure` -> `+` -> `Add Ruby SDK`\n\n![add sdk](docker_host02.png)\n\nDocker Composeを選んで`New`ボタンを押下\n\n![add sdk](docker_host01.png)\n\nAPI URLを指定する箇所があるのでVMのURLを設定する\n\n## VMからの操作\n\nそのままコマンド実行するとdocker daemonの起動オプションを変えたのでエラーが出る\n\n### エラー\n\n```\nERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?\n\nIf it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n```\n\n### 対応\n\n実行時に`DOCKER_HOST`の値を読みに行き、設定があれば問い合わせるようになっている\n\n```\nexport DOCKER_HOST=192.168.30.95:2375\n```\n\nこれでVMからのdockerコマンドの実行も問題なく実行できるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-07-14",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "DOCKER_HOSTを指定してVM外からdockerを操作できるようにする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Docker", "matchLevel": "none", "matchedWords": [] },
              { "value": "IntelliJ", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "tcpで接続する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/docker_host/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/ansible_install_awscliv2/",
          "text": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/bin:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
          "date": "2020-10-15",
          "title": "AnsibleでAWS CLI v2をインストールする",
          "tags": ["Ansible", "AWS"],
          "description": "",
          "slug": "/entries/ansible_install_awscliv2/",
          "timeToRead": 2,
          "objectID": "6223cafb-c96c-5937-ab87-4e069b55f0a0",
          "_snippetResult": {
            "text": {
              "value": "awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/ansible_install_awscliv2/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\ndotfilesをAnsibleで管理していてAWS CLI v2もインストールできるようにroleを追加した\n\n動作対象はCentOSやUbuntu\n\n- roles/awscli/vars/main.yml\n\n```yaml\n---\nawscli_version: 2.0.50\nawscli:\n  src: https://awscli.amazonaws.com/awscli-exe-linux-x86_64-{{ awscli_version }}.zip\n  zip: awscli-{{ awscli_version }}.zip\n```\n\n- roles/awscli/tasks/main.yml\n\n```yaml\n---\n- name: exist awscli v2\n  command: which aws\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: exist_awscli\n  changed_when: false\n  ignore_errors: true\n\n- name: get awscli version\n  shell: \"aws --version 2>&1 | grep -oP '(?<=aws-cli\\\\/)\\\\d+\\\\.\\\\d+\\\\.\\\\d+' \"\n  environment:\n    PATH: \"/usr/local/__ais-highlight__bi__/ais-highlight__n:{{ ansible_env.PATH }}\"\n  register: version_in_awscli\n  changed_when: false\n  ignore_errors: true\n  when:\n    exist_awscli.rc == 0\n\n- block:\n  - name: get zip\n    get_url:\n      url: \"{{ awscli.src }}\"\n      dest: \"/tmp/{{ awscli.zip }}\"\n\n  - name: unarchive zip\n    unarchive:\n      src: /tmp/{{ awscli.zip }}\n      dest: /tmp/\n      copy: no\n\n  - name: install\n    command:\n      cmd: ./aws/install --update\n      chdir: /tmp\n\n  when:\n    exist_awscli.rc != 0\n    or ( version_in_awscli is defined and version_in_awscli.stdout.find(awscli_version) == -1 )\n```\n\nここのコードをroleとして呼び出せば実行できる\n\nコマンドの存在確認だけでなくバージョンまで見て指定バージョンでなければ再度インストールするようにしている\n\nこのrole単体で使う場合は`unzip`がないはずなので別途どこかでインストールさせておく必要がある\n\n`aws --version`の出力先が標準エラーだったのでリダイレクトしてバージョン番号を抽出している\n\nまた次のサイトでgrepを使い特定の箇所だけを抜き出すというのをやった\n\n[grepの-oオプションと-Pオプションの組み合わせが便利 - Gre's Blog](http://greymd.hatenablog.com/entry/2014/09/27/154305)\n\nこういう感じの処理はよくやるので覚えておきたい\n\n実際の差分は次のPRにある\n\n[Feature/ansible awscli v2 by swfz · Pull Request #222 · swfz/dotfiles](https://github.com/swfz/dotfiles/pull/222/files)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2020-10-15",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "AnsibleでAWS CLI v2をインストールする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Ansible", "matchLevel": "none", "matchedWords": [] },
              { "value": "AWS", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ansible_install_awscliv2/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
          "text": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 ms)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
          "date": "2021-07-19",
          "title": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
          "tags": ["Jest", "Gatsby", "TestingLibrary"],
          "description": "jsdom使う",
          "slug": "/entries/introduction_jest_and_testing_library_to_gatsby/",
          "timeToRead": 2,
          "objectID": "5c1576d2-2d90-5c9c-91e5-fe9d12f8d611",
          "_snippetResult": {
            "text": {
              "value": "感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"__ais-highlight__Bi__/ais-highlight__o\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✕ renders correctly (2 ms)\n\n  ● __ais-highlight__Bi__/ais-highlight__o › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  __ais-highlight__Bi__/ais-highlight__o\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-07-19",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Jest", "matchLevel": "none", "matchedWords": [] },
              { "value": "Gatsby", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "TestingLibrary",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "jsdom使う",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/wsl_docker_for_windows/",
          "text": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/bin/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker\n\n```bash\n#!/usr/bin/env sh\nbinary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/bin/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port binding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
          "date": "2021-04-27",
          "title": "WSL2でDockerForWindowsのコマンドを叩く",
          "tags": ["WSL", "Docker"],
          "description": "/mnt/c経由のコマンドを叩く",
          "slug": "/entries/wsl_docker_for_windows/",
          "timeToRead": 2,
          "objectID": "83f1a1ec-789e-59e7-a6ee-9344bb2d4885",
          "_snippetResult": {
            "text": {
              "value": "くても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/wsl_docker_for_windows/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n`docker compose`がたたけるようになったらしいのでWSL2からもたたいてみようということで\n\n## 前提\n\n自分はWSL側からWindowsのコマンドを使うことはできるがPATHは読み込ませないようにしている（シェルの起動速度が遅かったため）\n\n- /etc/wsl.conf\n\n```ini\n[interop]\nenabled=true\nappendWindowsPath=false\n```\n\n## しらべた\n\nWSLからWindows側のDocker関連のコマンドをたたく場合\n\n`/mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/`以下にコマンド群がある\n\nしかし`docker-compose`は`docker-compose`,`docker-compose.exe`と両方あるのに`docker`に関しては`docker.exe`しかなかった\n\n`docker-compose`の中身を見たら環境によってたたくプログラムを変えているようだったので`docker`でも同じようなスクリプトを用意した\n\n参考にしたファイルはいくつか分岐があったが自分が使う環境は条件分岐しなくても良いので決め打ちにした\n\n- /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker\n\n```bash\n#!/usr/__ais-highlight__bi__/ais-highlight__n/env sh\n__ais-highlight__bi__/ais-highlight__nary=$(basename \"$0\")\n\"$binary.exe\" \"$@\"\n```\n\n- 実行してみる\n\n```\n$ /mnt/c/Program\\ Files/Docker/Docker/resources/__ais-highlight__bi__/ais-highlight__n/docker compose --help\nDocker Compose\n\nUsage:\n  docker compose [command]\n\nAvailable Commands:\n  build       Build or rebuild services\n  convert     Converts the compose file to platform's canonical format\n  create      Creates containers for a service.\n  down        Stop and remove containers, networks\n  events      Receive real time events from containers.\n  exec        Execute a command in a running container.\n  kill        Force stop service containers.\n  logs        View output from containers\n  ls          List running compose projects\n  pause       pause services\n  port        Print the public port for a port __ais-highlight__bi__/ais-highlight__nding.\n  ps          List containers\n  pull        Pull service images\n  push        Push service images\n  restart     Restart containers\n  rm          Removes stopped service containers\n  run         Run a one-off command on a service.\n  start       Start services\n  stop        Stop services\n  top         Display the running processes\n  unpause     unpause services\n  up          Create and start containers\n\nFlags:\n      --ansi string                Control when to print ANSI control characters (\"never\"|\"always\"|\"auto\") (default \"auto\")\n      --env-file string            Specify an alternate environment file.\n  -f, --file stringArray           Compose configuration files\n  -h, --help                       help for compose\n      --profile stringArray        Specify a profile to enable\n      --project-directory string   Specify an alternate working directory\n                                   (default: the path of the Compose file)\n  -p, --project-name string        Project name\n\nUse \"docker compose [command] --help\" for more information about a command.\n```\n\nこれでWSL2側からWindowsの`docker`コマンドをたたけるようになった\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["bi"]
            },
            "date": {
              "value": "2021-04-27",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "WSL2でDockerForWindowsのコマンドを叩く",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "WSL", "matchLevel": "none", "matchedWords": [] },
              { "value": "Docker", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "/mnt/c経由のコマンドを叩く",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/wsl_docker_for_windows/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 41,
      "page": 0,
      "nbPages": 3,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "exhaustive": { "nbHits": true, "typo": true },
      "query": "Bi",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&query=Bi&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 9,
      "processingTimingsMS": {
        "afterFetch": {
          "format": { "highlighting": 3, "snippeting": 5, "total": 8 },
          "total": 9
        },
        "total": 9
      }
    }
  ]
}
